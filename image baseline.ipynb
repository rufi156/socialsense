{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d72ee38c",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2560ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "DATASET_DIR = (Path(\"..\") / \"datasets\").resolve()\n",
    "DATASETS = [\"OFFICE-MANNERSDB\", \"MANNERSDBPlus\"]\n",
    "LABEL_COLS = [\n",
    "    \"Vaccum Cleaning\", \"Mopping the Floor\", \"Carry Warm Food\",\n",
    "    \"Carry Cold Food\", \"Carry Drinks\", \"Carry Small Objects\",\n",
    "    \"Carry Large Objects\", \"Cleaning\", \"Starting a conversation\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9da04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv(csv_path, dataset):\n",
    "    \"\"\"Process individual CSV files\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = df.drop(columns=df.columns[-1])\n",
    "    \n",
    "    # Extract metadata from first column\n",
    "    first_col = df.columns[0]\n",
    "    split_data = df[first_col].str.split('_', n=2, expand=True)\n",
    "    \n",
    "    df[\"robot\"] = split_data[0]\n",
    "    df[\"domain\"] = split_data[1]\n",
    "    df[\"image_ref\"] = split_data[2].astype(int)\n",
    "    df[\"dataset\"] = dataset\n",
    "\n",
    "    df = df.drop(columns=[first_col])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def consolidate_data(datasets):\n",
    "    \"\"\"Aggregate all CSVs\"\"\"\n",
    "    all_dfs = []\n",
    "    for dataset in datasets:\n",
    "        source_path = DATASET_DIR / dataset\n",
    "        \n",
    "        for robot in [\"NAO\", \"Pepper\", \"PR2\"]:\n",
    "            ann_dir = source_path / robot / \"Annotations\"\n",
    "            if not ann_dir.exists():\n",
    "                raise ValueError(f\"Labels csv file path ({ann_dir}) doesn't exist\")\n",
    "                \n",
    "            \n",
    "            for csv_file in ann_dir.glob(\"*.csv\"):\n",
    "                try:\n",
    "                    df = process_csv(csv_file, dataset)\n",
    "                    all_dfs.append(df)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {csv_file}: {str(e)}\")\n",
    "    \n",
    "    df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53657ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_raw_data(df):\n",
    "    \"\"\"Comprehensive data quality checks for raw annotation data\"\"\"\n",
    "    required_columns = {'robot', 'domain', 'image_ref', 'dataset'}\n",
    "\n",
    "    # Check for any missing columns\n",
    "    missing_cols = required_columns - set(df.columns)\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "\n",
    "    # Label value validation (should be between 1 and 5)\n",
    "    for col in LABEL_COLS:\n",
    "        if df[col].min() < 1 or df[col].max() > 5:\n",
    "            raise ValueError(f\"Label {col} has invalid range [{df[col].min()}, {df[col].max()}]\")\n",
    "\n",
    "    # Null values check\n",
    "    null_cols = df.columns[df.isnull().any()].tolist()\n",
    "    if null_cols:\n",
    "        raise ValueError(f\"Null values found in columns: {null_cols}\")\n",
    "\n",
    "    # Data type and value validation for image_ref\n",
    "    if not pd.api.types.is_integer_dtype(df['image_ref']):\n",
    "        raise TypeError(\"image_ref must be integer type\")\n",
    "    if (df['image_ref'] < 0).any():\n",
    "        raise ValueError(\"image_ref contains negative values, which is invalid\")\n",
    "\n",
    "    # Categorical value validation\n",
    "    valid_robots = {'NAO', 'Pepper', 'PR2'}\n",
    "    invalid_robots = set(df['robot']) - valid_robots\n",
    "    if invalid_robots:\n",
    "        raise ValueError(f\"Invalid robot values: {invalid_robots}\")\n",
    "\n",
    "    valid_sources = {'OFFICE-MANNERSDB', 'MANNERSDBPlus'}\n",
    "    invalid_sources = set(df['dataset']) - valid_sources\n",
    "    if invalid_sources:\n",
    "        raise ValueError(f\"Invalid source directories: {invalid_sources}\")\n",
    "\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb45d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_labels(df):\n",
    "    \"\"\"Aggregate multiple annotations per image by image path\"\"\"    \n",
    "    agg_dict = {\n",
    "        **{col: 'mean' for col in LABEL_COLS},\n",
    "        **{col: 'first' for col in df.columns.difference(LABEL_COLS).tolist()},\n",
    "    }\n",
    "    \n",
    "    return df.groupby('image_path', as_index=False).agg(agg_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e53d64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_image_path(row):\n",
    "    \"\"\"Robust path resolution with validation\"\"\"\n",
    "    base_dir = DATASET_DIR / row['dataset'] / row['robot'] / \"Images\"\n",
    "    \n",
    "    if row['dataset'] == \"OFFICE-MANNERSDB\":\n",
    "        target = base_dir / f\"{row['domain']}_{row['image_ref']}.png\"\n",
    "    else:\n",
    "        target = next(base_dir.glob(f\"{row['image_ref']}_*.png\"), None)\n",
    "    \n",
    "    if target and target.exists():\n",
    "        return target.resolve()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37acfe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageLabelDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = str(self.df.at[idx, \"image_path\"])\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error loading {img_path}: {str(e)}\")\n",
    "        \n",
    "        raw_labels = self.df.iloc[idx][LABEL_COLS].values.astype(np.float32)\n",
    "        scaled_labels = (raw_labels - 1) / 4  # Convert 1-5 → 0-1\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, torch.from_numpy(scaled_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f915a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(df, batch_sizes=(32, 64, 64)):\n",
    "    \"\"\"Create train/val/test dataloaders using image_path as unique key\"\"\"\n",
    "    \n",
    "    # Get image paths as indexing for split\n",
    "    unique_images = df[['image_path']].reset_index(drop=True)\n",
    "    \n",
    "    # Split using image_path as key #TODO is is spliting based on index or path strings? index faster\n",
    "    train_paths, temp_paths = train_test_split(\n",
    "        unique_images['image_path'], \n",
    "        test_size=0.3, \n",
    "        random_state=42\n",
    "    )\n",
    "    val_paths, test_paths = train_test_split(\n",
    "        temp_paths,\n",
    "        test_size=0.5, \n",
    "        random_state=42\n",
    "    )\n",
    "   \n",
    "    # Create subsets\n",
    "    train_df = df[df['image_path'].isin(train_paths)].reset_index(drop=True)\n",
    "    val_df = df[df['image_path'].isin(val_paths)].reset_index(drop=True)\n",
    "    test_df = df[df['image_path'].isin(test_paths)].reset_index(drop=True)\n",
    "    \n",
    "    #TODO add coordinate values for spacialy aware CNN Uber's CoordNav\n",
    "    # Define transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((384, 216)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                            std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = ImageLabelDataset(train_df, transform)\n",
    "    val_dataset = ImageLabelDataset(val_df, transform)\n",
    "    test_dataset = ImageLabelDataset(test_df, transform)\n",
    "    \n",
    "    # Create loaders\n",
    "    num_workers = 4\n",
    "    loaders = {\n",
    "        'train': DataLoader(train_dataset, batch_size=batch_sizes[0], shuffle=True, num_workers=num_workers, pin_memory=torch.cuda.is_available()),\n",
    "        'val': DataLoader(val_dataset, batch_size=batch_sizes[1], shuffle=False, num_workers=num_workers, pin_memory=torch.cuda.is_available()),\n",
    "        'test': DataLoader(test_dataset, batch_size=batch_sizes[2], shuffle=False, num_workers=num_workers, pin_memory=torch.cuda.is_available())\n",
    "    }\n",
    "    \n",
    "    return loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9668e590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_final_data(df):\n",
    "    \"\"\"Final validation after aggregation\"\"\"\n",
    "    # Missing image paths\n",
    "    missing = df[df['image_path'].isnull()]\n",
    "    if not missing.empty:\n",
    "        raise FileNotFoundError(\n",
    "            f\"{len(missing)} images missing after aggregation. Examples:\\n\"\n",
    "            f\"{missing[['robot', 'domain', 'image_ref']].head()}\"\n",
    "        )\n",
    "    \n",
    "    # Null values check\n",
    "    null_cols = df.columns[df.isnull().any()].tolist()\n",
    "    if null_cols:\n",
    "        raise ValueError(f\"Null values found in columns: {null_cols}\")\n",
    "\n",
    "    # Duplicate image paths\n",
    "    duplicates = df[df.duplicated('image_path', keep=False)]\n",
    "    if not duplicates.empty:\n",
    "        raise RuntimeError(\n",
    "            f\"Duplicate image paths after aggregation:\\n\"\n",
    "            f\"{duplicates['image_path'].unique()}\"\n",
    "        )\n",
    "\n",
    "    # Label validity (1-5)\n",
    "    for col in LABEL_COLS:\n",
    "        if df[col].min() < 1 or df[col].max() > 5:\n",
    "            raise ValueError(\n",
    "                f\"Aggregated label {col} out of range: \"\n",
    "                f\"[{df[col].min()}, {df[col].max()}]\"\n",
    "            )\n",
    "\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50f29e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    raw_df = consolidate_data(DATASETS)\n",
    "    validate_raw_data(raw_df)\n",
    "    raw_df['image_path'] = raw_df.apply(resolve_image_path, axis=1)   \n",
    "    aggregated_df = aggregate_labels(raw_df)\n",
    "    validate_final_data(aggregated_df) \n",
    "except Exception as e:\n",
    "    print(f\"Pipeline failed: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "aggregated_df.to_pickle(\"processed_all_data.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb27a27f",
   "metadata": {},
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4262ef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    raw_df = consolidate_data(DATASETS)\n",
    "    validate_raw_data(raw_df)\n",
    "except Exception as e:\n",
    "    print(f\"Pipeline failed: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0b514e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "entries_per_image = raw_df.groupby(['robot', 'domain', 'image_ref']).size().reset_index(name='num_entries')\n",
    "domain_counts = entries_per_image.groupby(['domain', 'num_entries']).size().reset_index(name='count')\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "ax = sns.barplot(\n",
    "    data=domain_counts,\n",
    "    x='num_entries',\n",
    "    y='count',\n",
    "    hue='domain',\n",
    "    hue_order = ['Home', 'BigOffice-2', 'BigOffice-3', 'Hallway', 'MeetingRoom',\n",
    "       'SmallOffice'],\n",
    "    palette='viridis'\n",
    ")\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    if height > 0:\n",
    "        ax.text(\n",
    "            p.get_x() + p.get_width() / 2.,\n",
    "            height + 0.5,  # Slightly above the bar\n",
    "            int(height),\n",
    "            ha='center',\n",
    "            va='bottom',\n",
    "            fontsize=11\n",
    "        )\n",
    "ax.set_ylim(0, domain_counts['count'].sum())\n",
    "\n",
    "plt.xlabel('Number of Entries per Image')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Distribution of Number of Entries per Image by Domain')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28016faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "duplicated_rows = raw_df.duplicated(keep=False)\n",
    "duplicates_per_index = duplicated_rows.groupby([raw_df['robot'], raw_df['domain'], raw_df['image_ref']]).sum()\n",
    "duplicates_per_index = duplicates_per_index.apply(lambda x: max(x - 1, 0))\n",
    "\n",
    "duplicates_per_index = duplicates_per_index.reset_index(name='num_duplicates')\n",
    "domain_counts = duplicates_per_index.groupby(['domain', 'num_duplicates']).size().reset_index(name='count')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.barplot(\n",
    "    data=domain_counts,\n",
    "    x='num_duplicates',\n",
    "    y='count',\n",
    "    hue='domain',\n",
    "    hue_order = ['Home', 'BigOffice-2', 'BigOffice-3', 'Hallway', 'MeetingRoom',\n",
    "       'SmallOffice'],\n",
    "    palette='viridis'\n",
    ")\n",
    "\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    if height > 0:\n",
    "        ax.text(\n",
    "            p.get_x() + p.get_width() / 2.,\n",
    "            height + 0.5,\n",
    "            int(height),\n",
    "            ha='center',\n",
    "            va='bottom',\n",
    "            fontsize=11\n",
    "        )\n",
    "\n",
    "# Set y-axis max to total number of duplicates\n",
    "ax.set_ylim(0, domain_counts['count'].sum())\n",
    "\n",
    "plt.xlabel('Number of Duplicates per Image')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Distribution of Number of Duplicates per Image by Domain')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90680d01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a43ca986",
   "metadata": {},
   "source": [
    "## CL Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b327a539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import random\n",
    "import time\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca1a5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SocialContinualModel(nn.Module):\n",
    "    def __init__(self, num_tasks=9):\n",
    "        super().__init__()\n",
    "        # Initialize the ResNet50 architecture with Places365 configuration\n",
    "        self.backbone = models.resnet50(num_classes=365)\n",
    "        \n",
    "        # get Places365 weights and fix their naming leftover from troch saving convention\n",
    "        places365_weights = torch.load('resnet50_places365.pth.tar', weights_only=True)\n",
    "        state_dict = places365_weights['state_dict']\n",
    "        state_dict = {k.replace('module.', ''): v \n",
    "                     for k, v in state_dict.items()}\n",
    "        \n",
    "        # Load weights\n",
    "        self.backbone.load_state_dict(state_dict)\n",
    "        \n",
    "        # Remove classification head\n",
    "        self.backbone.fc = nn.Identity()\n",
    "\n",
    "        #Freeze all params except last layer\n",
    "        for name, param in self.backbone.named_parameters():\n",
    "            if 'layer4' not in name:\n",
    "                param.requires_grad_(False)\n",
    "        \n",
    "        #TODO human mask average, std, quadrants, human in realtion to robot std\n",
    "        \n",
    "\n",
    "\n",
    "        # Shared layers #TODO deeper shared space?\n",
    "        self.shared_fc = nn.Sequential(\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        # Task-specific heads with more expensive but finegrained GELU\n",
    "        self.heads = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(1024, 512),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(512, 1),\n",
    "                nn.Sigmoid()\n",
    "            ) for _ in range(num_tasks)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        shared = self.shared_fc(features)\n",
    "        outputs = [head(shared) for head in self.heads]\n",
    "        return torch.cat(outputs, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a7176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReservoirBuffer:\n",
    "    def __init__(self, capacity=1000):\n",
    "        self.capacity = capacity\n",
    "        self.buffer = []\n",
    "        self.added_samples = 0\n",
    "\n",
    "    def add(self, new_data):\n",
    "        for sample in new_data:\n",
    "            if len(self.buffer) < self.capacity:\n",
    "                self.buffer.append(sample)\n",
    "            else:\n",
    "                j = random.randint(0, self.added_samples)\n",
    "                if j < self.capacity:\n",
    "                    self.buffer[j] = sample\n",
    "            self.added_samples += 1\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        if not self.buffer:\n",
    "            return []\n",
    "        \n",
    "        actual_size = min(batch_size, len(self.buffer))\n",
    "        indices = np.random.choice(len(self.buffer), actual_size, replace=False)\n",
    "        return [self.buffer[i] for i in indices]\n",
    "    \n",
    "    def get_domain_distribution(self):\n",
    "        return pd.Series([s[2] for s in self.buffer]).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3355abf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device, dtype=torch.float32)\n",
    "            labels = labels.to(device, dtype=torch.float32)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e871f944",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a453cfb",
   "metadata": {},
   "source": [
    "## Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dc27f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"processed_all_data.pkl\")\n",
    "\n",
    "# Create domain-specific dataloaders\n",
    "domains = df['domain'].unique()\n",
    "domain_dataloaders = {}\n",
    "for domain in domains:\n",
    "    domain_df = df[df['domain'] == domain]\n",
    "    #domain_df = domain_df.sample(frac=0.5, random_state=42)\n",
    "    loaders = create_dataloaders(domain_df, batch_sizes=(32, 64, 64))\n",
    "    domain_dataloaders[domain] = loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f1f92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model and buffer\n",
    "model = SocialContinualModel()\n",
    "buffer = ReservoirBuffer(capacity=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8caf0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3) #3e-4?\n",
    "\n",
    "#TODO separate optimisers for shared and heads?\n",
    "criterion = F.mse_loss #nn.MSELoss()\n",
    "#TODO potential loss optimisations like unccertainty loss, \n",
    "\n",
    "num_epochs=5\n",
    "replay_ratio=0.2 #this % of batches will have replay samples added e.g. out of 100 batches 20 will have added replay samples\n",
    "\n",
    "metrics = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'test_loss': [],\n",
    "    'domain_performance': {domain: [] for domain in domains}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bcdfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for domain_idx, domain in enumerate(domains):\n",
    "    start_time = time.time()\n",
    "    print(f\"\\n=== Training Domain {domain_idx+1}/{len(domains)}: {domain} ===\")\n",
    "    \n",
    "    train_loader = domain_dataloaders[domain]['train']\n",
    "    total_batches = len(train_loader)\n",
    "\n",
    "    print(f\"Training on {str(device).upper()} | Batch Size: {train_loader.batch_size}\")\n",
    "    print(f\"Total Batches per Epoch: {total_batches}\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start = time.time()\n",
    "        print(f\"\\n--- Epoch {epoch+1}/{num_epochs} ---\")\n",
    "        \n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            batch_start = time.time()\n",
    "            batch_size = inputs.size(0)\n",
    "\n",
    "            inputs = inputs.to(device, dtype=torch.float32)\n",
    "            labels = labels.to(device, dtype=torch.float32)\n",
    "\n",
    "            # Sample the buffer and add replay samples to training\n",
    "            if buffer and random.random() < replay_ratio:\n",
    "                replay_batch = buffer.sample(int(batch_size * 0.25))\n",
    "                if replay_batch:\n",
    "                    replay_inputs, replay_labels, _ = zip(*replay_batch)\n",
    "                    replay_inputs = torch.stack(replay_inputs).to(device, dtype=torch.float32)\n",
    "                    replay_labels = torch.stack(replay_labels).to(device, dtype=torch.float32)\n",
    "                    inputs = torch.cat([inputs, replay_inputs])\n",
    "                    labels = torch.cat([labels, replay_labels])\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Add current batch to buffer\n",
    "            with torch.no_grad():\n",
    "                samples = [(img.cpu(), label.cpu(), domain) for img, label in zip(inputs, labels)]\n",
    "                buffer.add(samples)\n",
    "            \n",
    "            batch_time = time.time() - batch_start\n",
    "                \n",
    "            running_loss += loss.item()\n",
    "            if batch_idx % 10 == 9:\n",
    "                print(\"\\nBuffer Status:\")\n",
    "                print(f\"Total samples: {len(buffer.buffer)}\")\n",
    "                print(\"Domain distribution:\")\n",
    "                print(buffer.get_domain_distribution())\n",
    "                \n",
    "                avg_loss = running_loss / 10\n",
    "                batch_time = time.time() - batch_start  # ← Keep this\n",
    "                print(\n",
    "                    f\"Domain: {domain} | Epoch: {epoch+1} | \"\n",
    "                    f\"Batch: {batch_idx+1}/{total_batches} | \"\n",
    "                    f\"Avg Loss: {avg_loss:.4f} | \"  # Changed to Avg Loss\n",
    "                    f\"Time/batch: {batch_time:.2f}s\"\n",
    "                )\n",
    "                running_loss = 0.0\n",
    "    \n",
    "        # Epoch summary\n",
    "        epoch_time = time.time() - epoch_start\n",
    "        print(f\"Epoch {epoch+1} Time: {epoch_time//60:.0f}m {epoch_time%60:.0f}s\")\n",
    "        print(f\"Training Loss: {running_loss / (batch_idx+1):.4f}\")\n",
    "        \n",
    "        # Validation\n",
    "        val_loss = evaluate_model(model, domain_dataloaders[domain]['val'], criterion, device)\n",
    "        metrics['val_loss'].append(val_loss)\n",
    "        print(f\"Domain {domain} | Epoch {epoch+1} | Val Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    # Evaluate on all domains\n",
    "    for eval_domain in domains:\n",
    "        domain_loss = evaluate_model(model, domain_dataloaders[eval_domain]['val'], criterion, device)\n",
    "        metrics['domain_performance'][eval_domain].append(domain_loss)\n",
    "        print(f\"Performance on {eval_domain} after {domain}: {domain_loss:.4f}\")\n",
    "\n",
    "    # return model, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562d2898",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'base_modelv1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f011d46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6678f170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(metrics['val_loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.title('Validation Loss Over Epochs')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1960d6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for domain, losses in metrics['domain_performance'].items():\n",
    "    plt.plot(losses, label=domain)\n",
    "plt.xlabel('Domain Training Step')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Domain Performance Over Training')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d878b1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for domain, losses in metrics['domain_performance'].items():\n",
    "    print(f\"{domain}: Initial = {losses[0]:.4f}, Final = {losses[-1]:.4f}, Change = {losses[-1] - losses[0]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895de6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After model output\n",
    "outputs = model(inputs)  # Should be in [1,5]\n",
    "print(f\"Output range: {outputs.min().item()}–{outputs.max().item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b8e494",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "socialsense",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
