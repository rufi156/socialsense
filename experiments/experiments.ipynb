{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5d63d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38cb05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../FedLGR_SocRob/models/mod0.pkl', 'rb') as f:\n",
    "    weights = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a4ee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Set this to your images directory\n",
    "folder_path = 'Rafal_MSc_Thesis/IMAGES/'  # Change this if needed\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.lower().endswith('.png'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        try:\n",
    "            with Image.open(file_path) as img:\n",
    "                width, height = img.size\n",
    "            file_size_kb = os.path.getsize(file_path) / 1024\n",
    "            print(f\"{width}x{height} pixels, {file_size_kb:.2f} KB\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d63abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Set this to your images folder (or '.' for current directory)\n",
    "folder_path = 'Rafal_MSc_Thesis/IMAGES/'\n",
    "size_threshold_kb = 3000  # 3 MB\n",
    "resize_factor = 0.8  # Resize to 50% (half width, half height)\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    # Check for PNG, JPG, JPEG files (case-insensitive)\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        try:\n",
    "            file_size_kb = os.path.getsize(file_path) / 1024\n",
    "            if file_size_kb > size_threshold_kb:\n",
    "                with Image.open(file_path) as img:\n",
    "                    width, height = img.size\n",
    "                    new_size = (int(width * resize_factor), int(height * resize_factor))\n",
    "                    img_resized = img.resize(new_size, Image.LANCZOS)  # High quality\n",
    "                    output_path = os.path.join('Rafal_MSc_Thesis/newimg' ,filename)\n",
    "                    img_resized.save(output_path)\n",
    "                    print(f\"Resized {filename} ({file_size_kb:.2f} KB) to {new_size[0]}x{new_size[1]} and saved as {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1e8b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loaded weights type: {type(weights)}\")\n",
    "\n",
    "if isinstance(weights, list):\n",
    "    print(f\"Number of weight arrays saved: {len(weights)}\")\n",
    "    # Optionally print shape of each weight array\n",
    "    for i, arr in enumerate(weights):\n",
    "        print(f\"Weight[{i}] shape: {arr.shape}\")\n",
    "elif isinstance(weights, dict):\n",
    "    print(f\"Dict keys: {list(weights.keys())}\")\n",
    "else:\n",
    "    print(\"Saved weights are neither a list nor dict, raw object:\")\n",
    "    print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8bd87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Paths to the weight files\n",
    "gpu_weights_path = \"../../FedLGR_SocRob/models/gpu/MobileNet.pkl\"\n",
    "cpu_weights_path = \"../../FedLGR_SocRob/models/cpu/MobileNet.pkl\"\n",
    "\n",
    "# Load weights mapping both to CPU\n",
    "weights_gpu = torch.load(gpu_weights_path, map_location=torch.device('cpu'))\n",
    "weights_cpu = torch.load(cpu_weights_path, map_location=torch.device('cpu'))\n",
    "\n",
    "# Function to compare two state_dicts\n",
    "def compare_state_dicts(sd1, sd2):\n",
    "    if sd1.keys() != sd2.keys():\n",
    "        print(\"Different parameter sets\")\n",
    "        return False\n",
    "    for key in sd1.keys():\n",
    "        if not torch.equal(sd1[key], sd2[key]):\n",
    "            print(f\"Parameter differs: {key}\")\n",
    "            print(f\" - GPU shape: {sd1[key].shape}, CPU shape: {sd2[key].shape}\")\n",
    "            diff = torch.norm(sd1[key] - sd2[key])\n",
    "            print(f\" - Norm of difference: {diff.item()}\")\n",
    "            return False\n",
    "    print(\"All parameters match\")\n",
    "    return True\n",
    "\n",
    "# Assuming the files contain state_dicts (dict mapping param names to tensors)\n",
    "compare_state_dicts(weights_gpu, weights_cpu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb981fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "\n",
    "def load_pickle_as_state_dict(pkl_path):\n",
    "    with open(pkl_path, 'rb') as f:\n",
    "        state_dict = pickle.load(f)\n",
    "\n",
    "    # Convert all numpy arrays in state_dict to torch tensors\n",
    "    for key in state_dict:\n",
    "        if isinstance(state_dict[key], (list, tuple)):\n",
    "            # Sometimes parameters can be list or tuple\n",
    "            state_dict[key] = torch.tensor(state_dict[key])\n",
    "        elif hasattr(state_dict[key], 'shape'):  # numpy ndarray\n",
    "            state_dict[key] = torch.tensor(state_dict[key])\n",
    "        else:\n",
    "            # Could already be tensor or scalar\n",
    "            pass\n",
    "    return state_dict\n",
    "\n",
    "# Example usage\n",
    "cpu_weights_path = \"../../FedLGR_SocRob/models/cpu/MobileNet.pkl\"\n",
    "gpu_weights_path = \"../../FedLGR_SocRob/models/gpu/MobileNet.pkl\"\n",
    "\n",
    "cpu_sd = load_pickle_as_state_dict(cpu_weights_path)\n",
    "gpu_sd = load_pickle_as_state_dict(gpu_weights_path)\n",
    "\n",
    "def compare_state_dicts(sd1, sd2):\n",
    "    keys1 = set(sd1.keys())\n",
    "    keys2 = set(sd2.keys())\n",
    "    if keys1 != keys2:\n",
    "        print(\"Different parameter keys found:\")\n",
    "        print(\"In sd1 but not in sd2:\", keys1 - keys2)\n",
    "        print(\"In sd2 but not in sd1:\", keys2 - keys1)\n",
    "        return False\n",
    "\n",
    "    all_close = True\n",
    "    for key in sd1.keys():\n",
    "        tensor1 = sd1[key]\n",
    "        tensor2 = sd2[key]\n",
    "\n",
    "        # Move both tensors to CPU before comparison\n",
    "        if tensor1.device != torch.device('cpu'):\n",
    "            tensor1 = tensor1.to('cpu')\n",
    "        if tensor2.device != torch.device('cpu'):\n",
    "            tensor2 = tensor2.to('cpu')\n",
    "\n",
    "        if not torch.allclose(tensor1, tensor2, atol=1e-6):\n",
    "            diff = (tensor1 - tensor2).abs().max()\n",
    "            print(f\"Parameter '{key}' differs, max abs diff = {diff}\")\n",
    "            all_close = False\n",
    "\n",
    "    if all_close:\n",
    "        print(\"All parameters match closely!\")\n",
    "    return all_close\n",
    "\n",
    "\n",
    "compare_state_dicts(cpu_sd, gpu_sd)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "socialsense",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
