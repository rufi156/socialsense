{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0ea227a",
   "metadata": {},
   "source": [
    "### Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fb6d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import pickle\n",
    "import datetime\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# DATASET_DIR = (Path(\"..\") / \"..\" / \"datasets\").resolve()\n",
    "# DATASETS = [\"OFFICE-MANNERSDB\", \"MANNERSDBPlus\"]\n",
    "# LABEL_COLS = [\n",
    "#     \"Vaccum Cleaning\", \"Mopping the Floor\", \"Carry Warm Food\",\n",
    "#     \"Carry Cold Food\", \"Carry Drinks\", \"Carry Small Objects\",\n",
    "#     \"Carry Large Objects\", \"Cleaning\", \"Starting a conversation\"\n",
    "# ]\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from data_processing.data_processing import ImageLabelDataset,DualImageDataset,create_dataloaders,create_crossvalidation_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585cbb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../data/pepper_data.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4d4f14",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7f5dd7",
   "metadata": {},
   "source": [
    "### files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e9961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# different cos 1-abs fixed residual - fixedred_fixedcos_dualbranchmodel_20250604_014811_history\n",
    "#fixed res but old cosine ^2 - fixedred_dualbranchmodel_20250604_002951_history\n",
    "#broken baseline - baselinemodel_20250603_200948_history\n",
    "# recent dualbranch - dualbranchmodel_20250603_135728_history\n",
    "#normalised and standarised residual - dualbranchmodel_20250609_013632_history\n",
    "#standarised residual - nonorm_dualbranchmodel_20250609_131820_history\n",
    "#no residual connection - nores_dualbranchmodel_20250609_232842_history\n",
    "#same plus gradient clipping - nores_gradclip_dualbranchmodel_20250610_010647_history\n",
    "#same, no graidient clipping, weights initialisation and normalisation - nores_winit_wnorm_dualbranchmodel_20250610_024401_history\n",
    "#same, gradient clipping and weights optimisation - nores_gradclip_winit_wnorm_dualbranchmodel_20250610_042118_history\n",
    "#deeper invariant network - deep_norm_dualbranchmodel_20250610_223350_history\n",
    "#same but with weiths normalisation - deep_dualbranchmodel_20250610_205411_history\n",
    "\n",
    "with open('../checkpoints/nonorm_dualbranchmodel_20250609_131820_history.pkl', 'rb') as f:\n",
    "    nonorm = pickle.load(f)\n",
    "\n",
    "with open('../checkpoints/nores_dualbranchmodel_20250609_232842_history.pkl', 'rb') as f:\n",
    "    lnorm_nores = pickle.load(f)\n",
    "\n",
    "with open('../checkpoints/nores_gradclip_dualbranchmodel_20250610_010647_history.pkl', 'rb') as f:\n",
    "    lnorm_nores_gradclip = pickle.load(f)\n",
    "\n",
    "with open('../checkpoints/dualbranchmodel_20250609_013632_history.pkl', 'rb') as f:\n",
    "    lnorm = pickle.load(f)\n",
    "\n",
    "with open('../checkpoints/nores_winit_wnorm_dualbranchmodel_20250610_024401_history.pkl', 'rb') as f:\n",
    "    wnorm_nores = pickle.load(f)\n",
    "\n",
    "with open('../checkpoints/nores_gradclip_winit_wnorm_dualbranchmodel_20250610_042118_history.pkl', 'rb') as f:\n",
    "    wnorm_nores_gradclip = pickle.load(f)\n",
    "\n",
    "with open('../checkpoints/deep_norm_dualbranchmodel_20250610_223350_history.pkl', 'rb') as f:\n",
    "    wnorm_gradclip_deep = pickle.load(f)\n",
    "\n",
    "with open('../checkpoints/deep_dualbranchmodel_20250610_205411_history.pkl', 'rb') as f:\n",
    "    lnorm_gradclip_deep = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d06af5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all have gradient clipping\n",
    "# Either detach and skip connect base -> head\n",
    "# - detach reference - how does detachement work? can backbone learn through skip connection?\n",
    "# - detach smaller batch effect?\n",
    "# - detach how partial freeze backbone learns?\n",
    "# or\n",
    "# freeze backbone\n",
    "# - frozen backbone doesn't learn, branches learn solo\n",
    "# - frozen, branches solo learn but binary?\n",
    "# - frozen branches solo learn binary but explicit gradient reverse function rather than layer?\n",
    "# - add full replay? \n",
    "\n",
    "files = [\n",
    "    'bbdetach_deep_dualbranchmodel_20250613_155613_history',                 #deep weights_init=False, detach_base=True, - base for below  experiments\n",
    "    'bdetach_batch16_dualbranchmodel_20250615_025032_history', # deep unfrozen bb, detached bb, smaller 16 batch - did smaller batch improve stability, did skip connection improve head loss and total training/val loss?\n",
    "    'bdetach_pfrozen_dualbranchmodel_20250615_040906_history', # deep pfrozen bb, detached bb - training branches+last layer bb - did partially frozen pretrained backbone improve skip head connection?\n",
    "   \n",
    "    'ffrozen_dualbranchmodel_20250615_133027_history',                       #deep weights_init=False, detach_base=False, -how do deep linear branches train on their own?\n",
    "    'ffrozen_binary_dualbranchmodel_20250615_153755_history',                      #weights_init=False, detach_base=False, explicit_grl=False, full_replay = False - does binary improve anything?\n",
    "    'ffrozen_binary_explicitgrl_dualbranchmodel_20250615_162820_history',          #weights_init=False, detach_base=False, explicit_grl=False, full_replay = False - does the gradient reversal layer work better or function?\n",
    "    'freplay_ffrozen_binary_explicitgrl_dualbranchmodel_20250615_174623_history'  #weights_init=True,  detach_base=False, explicit_grl=True,  full_replay = True - does full repaly help the branches on their own?\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785c31bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    # 'CNN_pretrained_simple_simple_dualbranchmodel_20250616_032555_history',  # 'pretrained_backbone_cnn_branch': ('pretrained', 'simple', 'simple'), \n",
    "    # 'CNN_diy_backbone_linear_branch_dualbranchmodel_20250616_105211_history', # (2layer convolution backbone, 'linear', 'simple'),\n",
    "    # 'CNN_linear_branch_dualbranchmodel_20250616_172252_history',  # 'linear_branch': ('3conv', 'linear', 'simple'),\n",
    "    'CNN_cnn_branch_dualbranchmodel_20250616_190434_history',      # 'cnn_branch': ('3conv', 'simple', 'simple'),\n",
    "    'CNN_adversarial_dualbranchmodel_20250616_201008_history',      # 'adversarial': ('2conv', 'adversarial', 'adversarial'),\n",
    "    'CNN_cnn_specialised_branches_dualbranchmodel_20250616_232330_history',      # 'cnn_specialised_branches': ('3conv', 'special', 'simple')\n",
    "    'CNN_pretrained_simple_0.25branches_dualbranchmodel_20250617_230422_history',\n",
    "    'CNN_pretrained_special_dualbranchmodel_20250617_032445_history'\n",
    "]\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56068d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['CNN_pretrained_simple_dualbranchmodel_20250617_022356_history', #'pretrained_simple': ('pretrained', 'simple', '3linear', detach_base=False), \n",
    "'CNN_pretrained_special_dualbranchmodel_20250617_032445_history', #    'pretrained_special': ('pretrained', 'special', '3linear', False),\n",
    "'CNN_3conv_simple_dualbranchmodel_20250617_042555_history', #    '3conv_simple': ('3conv', 'simple', '3linear', True),\n",
    "'CNN_3conv_special_dualbranchmodel_20250617_052951_history' #    '3conv_special': ('3conv', 'special', '3linear', True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626e1ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['CNN_pretrained_simple_dualbranchmodel_20250617_022356_history',\n",
    "'CNN_pretrained_simple_0.25branches_dualbranchmodel_20250617_230422_history' #change the loss proportions\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d226029",
   "metadata": {},
   "outputs": [],
   "source": [
    "files =['5foldcrossval_fold4_CNN_3conv_adversarial_dualbranchmodel_20250618_121607_history',\n",
    "'5foldcrossval_fold4_CNN_pretrained_simple_dualbranchmodel_20250618_064848_history'\n",
    "]\n",
    "files = [\n",
    "    'CNN_pretrained_simple_0.25branches_dualbranchmodel_20250617_230422_history',\n",
    "    'CNN_adversarial_dualbranchmodel_20250616_201008_history'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69492950",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['DANN_dualbranchmodel_20250618_152753_history',\n",
    "         'DANN_dynamicalpha_notrain1dom_20250620_201349_history',\n",
    "         'DANN_dynamicalpha_notrain1dom_20250620_232330_history'\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcc7458",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "'baselinemodel_20250618_195623_history',\n",
    "'minimal_simple_dualbranchmodel_20250618_213930_history',\n",
    "'minimal_simple_buffer05_dualbranchmodel_20250618_224113_history',\n",
    "'minimal_special_dualbranchmodel_20250618_233832_history'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9455dfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "files=[\n",
    "'baselinemodel_20250603_200948_history',\n",
    "'baselinemodel_20250603_034233_history',\n",
    "'baselinemodel_20250618_195623_history'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f03084",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    'baselinemodel_20250603_200948_history',\n",
    "    'minimal_absurd_buff500_20250619_121348_history',\n",
    "    'minimal_simple_buffer05_dualbranchmodel_20250618_224113_history',\n",
    "    'DANN_dualbranchmodel_20250618_152753_history',\n",
    "    'CNN_pretrained_simple_0.25branches_dualbranchmodel_20250617_230422_history'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2410daec",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "'DANN_dynamicalpha_notrain1dom_20250620_232330_history',\n",
    "'DANN_notrain1dom_20250621_005208_history',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2152ec0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "'dualbranch_CNN_dynamicalpha_20250621_015610_history',\n",
    "'CNN_adversarial_dualbranchmodel_20250616_201008_history',\n",
    "'CNN_cnn_branch_dualbranchmodel_20250616_190434_history'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3211f001",
   "metadata": {},
   "outputs": [],
   "source": [
    "files =[\n",
    "'dualbranch_CNN_1epoch_20250621_014841_history',\n",
    "'CNN_pretrained_simple_025branches_dualbranchmodel_20250617_230422_history',\n",
    "'CNN_pretrained_simple_dualbranchmodel_20250617_022356_history',\n",
    "'CNN_adversarial_dualbranchmodel_20250616_201008_history'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03ccd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "'3conv_simple_3linear_bnorm_nogradclip_20250621_130858_history',\n",
    "'3conv_simple_simple_bnorm_20250621_121437_history',\n",
    "'3conv_simple_simple_bnorm_nogradclip_20250621_102634_history',\n",
    "'3conv_simple_simple_nogradclip_20250621_112040_history',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faa73ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "files =['mobinev2_dann_20250621_204449_history',\n",
    "        'deeplabv3mobilenetv3_dann_20250621_223924_history',\n",
    "        'deeplabv3mobilenetv3_dann_20250624_000526_history'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9897dd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    # ('dann', 'dann_mobilenet_20250630_014020_history'), #smoother, stable disentagnlement but not significantly better results\n",
    "    # ('dann_old', 'mobinev2_dann_20250621_204449_history'), #old mobilenet dann\n",
    "    ('detached', 'dual_2conv_adversarial_3linear_detach_20250630_045130_history'),\n",
    "    ('detached_old', 'CNN_3conv_simple_dualbranchmodel_20250617_042555_history'), #detached old\n",
    "    ('trainable_old', 'CNN_adversarial_dualbranchmodel_20250616_201008_history'), #trainable backbone pretrained adv adv old\n",
    "    ('frozen', 'dual_mobilenet_simple_3linear_20250630_081954_history'),\n",
    "    ('frozen_old', 'CNN_pretrained_simple_dualbranchmodel_20250617_022356_history'), #pretrained simple, 3linear old\n",
    "    # 'dual_mobilenet_linear_simple_20250630_111817_history',  #performs poorly, no surprise taht linear layer canot extract meaningfull features from frozen backbone\n",
    "    # ('baseline', 'baseline_20250630_161803_history'), #more stable, similar results\n",
    "    # ('baseline_old', 'baselinemodel_20250618_195623_history'), #old baseline\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92ab0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "('linear', 'dual_mobilenet_linear_simple_20250630_111817_history'),\n",
    "('linear_b120', 'dual_mobilenet_linear_simple_buff120_20250704_081958_history'), \n",
    "('base', 'baseline_20250630_161803_history'),\n",
    "('base_b500', 'baseline_buff500_20250704_085427_history'), \n",
    "('base_b120', 'baseline_buff120_20250704_113155_history'), \n",
    "('dann', 'dann_mobilenet_20250630_014020_history'),\n",
    "('dann_b500', 'dann_mobilenet_buff500_20250704_003743_history'), \n",
    "('dann_b120', 'dann_mobilenet_buff120_20250704_031423_history'), \n",
    "('detach', 'dual_2conv_adversarial_3linear_detach_20250630_045130_history'),\n",
    "('detach_b500', 'dual_2conv_adversarial_3linear_detach_buff500_20250704_041620_history'), \n",
    "('detach_b120', 'dual_2conv_adversarial_3linear_detach_buff120_20250704_054532_history'),\n",
    "('frozen', 'dual_mobilenet_simple_3linear_20250630_081954_history'), \n",
    "('frozen_b500', 'dual_mobilenet_simple_3linear_buff500_20250704_062411_history'), \n",
    "('frozen_b120', 'dual_mobilenet_simple_3linear_buff120_20250704_074516_history'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ff03de",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "('base_b500', 'baseline_buff500_20250704_085427_history'), \n",
    "('base_b120', 'baseline_buff120_20250704_113155_history'), \n",
    "('new_b500','heuristic_dualbranch_buff500_20250704_213101_history'),\n",
    "('new_b120','heuristic_dualbranch_buff120_20250705_031333_history'),\n",
    "('frozen_b500', 'dual_mobilenet_simple_3linear_buff500_20250704_062411_history'), \n",
    "('frozen_b120', 'dual_mobilenet_simple_3linear_buff120_20250704_074516_history'),\n",
    "\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b674730",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    ('base_b120', 'baseline_buff120_20250704_113155_history'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c6e7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "('base_b500', 'baseline_buff500_20250704_085427_history'), \n",
    "('base_b120', 'baseline_buff120_20250704_113155_history'), \n",
    "('new_b500','heuristic_dualbranch_buff500_20250704_213101_history'),\n",
    "('new_b120','heuristic_dualbranch_buff120_20250705_031333_history'),\n",
    "('frozen_b500', 'dual_mobilenet_simple_3linear_buff500_20250704_062411_history'), \n",
    "('frozen_b120', 'dual_mobilenet_simple_3linear_buff120_20250704_074516_history'),\n",
    "('old_b500', 'CNN_pretrained_simple_dualbranchmodel_20250617_022356_history'), \n",
    "('linear_b1000', 'dual_mobilenet_linear_simple_20250630_111817_history'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79270ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    ('base','heuristic_dualbranch_buff120_20250705_031333_history'),\n",
    "    # ('small_env','heuristic_small_env_20250722_222924_history'),\n",
    "    # ('square','heuristic_square_img_20250722_233743_history'),\n",
    "    ('eval_buffer','heuristic_eval_buffer_20250723_144515_history'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1800d8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    ('base','heuristic_dualbranch_buff120_20250705_031333_history'),\n",
    "    ('small','heuristic__small_imgs_20250729_151705_history'),\n",
    "    ('small_env','heuristic_small_env_20250722_222924_history'),\n",
    "    \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbd0e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "pkl_files = [f for f in os.listdir('../checkpoints/') if f.endswith('.pkl')]\n",
    "for file in pkl_files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a9d0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "models = {}\n",
    "for i, file in enumerate(files):\n",
    "    file_name = ''\n",
    "    if isinstance(file, tuple):\n",
    "        file_name, file = file\n",
    "    with open(f'../checkpoints/{file}.pkl', 'rb') as f:\n",
    "        model_name = file_name or '_'.join(file.split('_')[:-3])+str(i)\n",
    "        models[model_name] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cc8a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For fold histories\n",
    "for k,m in models.items():\n",
    "    models[k] = combine_fold_histories(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fdd1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "models2 = models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524386b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.update(models2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ffbe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../checkpoints/bbdetach_deep_dualbranchmodel_20250613_155613_history.pkl', 'rb') as f:\n",
    "    bbdetach_deep = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36362dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_file = torch.load('../checkpoints/dualbranchmodel_20250609_013632_domainSmallOffice_epoch9_step1300.pt')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "domains = df['domain'].unique()\n",
    "model = DualBranchNet(num_domains=len(domains)).to(device)\n",
    "model.load_state_dict(pt_file['model_state_dict'])\n",
    "history = pt_file['history']\n",
    "tsne_data = pt_file['tsne']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cdde86",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models.keys():\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e02d59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(models.keys())[1:]:\n",
    "    for j in models[i]['cross_domain_val']:\n",
    "        for key in j:\n",
    "            j[key] = j[key][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c788a5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(models.keys())[1:]:\n",
    "    models[i]['val_epoch_loss'] = [j[0] for j in models[i]['val_epoch_loss']]\n",
    "    models[i]['val_buffer_epoch_loss'] = [j[0] for j in models[i]['val_buffer_epoch_loss']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c26fde",
   "metadata": {},
   "source": [
    "### plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87b7d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b936bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'bbdetach_deep':bbdetach_deep}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1816fad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "'nonorm': nonorm,\n",
    "'lnorm': lnorm,\n",
    "'lnorm_nores': lnorm_nores,\n",
    "'lnorm_nores_gradclip': lnorm_nores_gradclip,\n",
    "'wnorm_nores': wnorm_nores,\n",
    "'wnorm_nores_gradclip': wnorm_nores_gradclip,\n",
    "'wnorm_gradclip_deep': wnorm_gradclip_deep,\n",
    "'lnorm_gradclip_deep': lnorm_gradclip_deep\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c752ecaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,m in models.items():\n",
    "#     filtered = [x for i, x in enumerate(m['cross_domain_val']) if i in [9, 19, 29, 39, 49, 58]]\n",
    "#     m['cross_domain_val'] = filtered\n",
    "\n",
    "for i,m in models.items():\n",
    "    print(len(m['cross_domain_val']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2277428",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickvals=[0, 10, 20, 30, 40, 50]\n",
    "np.multiply(np.array(tickvals), 2).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba7fc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "traces = []\n",
    "for model_name, history in models.items():\n",
    "    traces.append(go.Scatter(\n",
    "        x=list(range(len(history['train_epoch_loss']))),\n",
    "        y=history['train_epoch_loss'],\n",
    "        mode='lines',\n",
    "        name=f'{model_name} Train Loss',\n",
    "        visible=False\n",
    "    ))\n",
    "    traces.append(go.Scatter(\n",
    "        x=list(range(len(history['val_epoch_loss']))),\n",
    "        y=history['val_epoch_loss'],\n",
    "        mode='lines',\n",
    "        name=f'{model_name} Val Loss',\n",
    "        visible=False\n",
    "    ))\n",
    "\n",
    "# Make the first model visible by default\n",
    "for i in range(2):\n",
    "    traces[i].visible = True\n",
    "\n",
    "buttons = []\n",
    "for i, model_name in enumerate(models.keys()):\n",
    "    visible = [False] * len(traces)\n",
    "    visible[2*i] = True\n",
    "    visible[2*i + 1] = True\n",
    "    buttons.append(dict(\n",
    "        label=model_name,\n",
    "        method='update',\n",
    "        args=[{'visible': visible}, {'title': f'Training and Validation Loss - {model_name}'}]\n",
    "    ))\n",
    "\n",
    "fig = go.Figure(data=traces)\n",
    "fig.update_layout(\n",
    "    updatemenus=[dict(\n",
    "        active=0,\n",
    "        buttons=buttons,\n",
    "        x=0.1,\n",
    "        y=1.15,\n",
    "        xanchor='left',\n",
    "        yanchor='top'\n",
    "    )],\n",
    "    title='Training and Validation Loss - Model A',\n",
    "    xaxis_title='Epochs',\n",
    "    yaxis_title='MSE Loss',\n",
    "    template='plotly_white',\n",
    "    yaxis=dict(range=[0, 1])\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b046a9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for model_name, history in models.items():\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=list(range(len(history['train_epoch_loss']))),\n",
    "        y=history['train_epoch_loss'],\n",
    "        mode='lines',\n",
    "        name=f'{model_name} Train Loss'\n",
    "    ))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=list(range(len(history['val_epoch_loss']))),\n",
    "        y=history['val_epoch_loss'],\n",
    "        mode='lines',\n",
    "        name=f'{model_name} Val Loss'\n",
    "    ))\n",
    "    try:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=list(range(len(history['val_buffer_epoch_loss']))),\n",
    "            y=history['val_buffer_epoch_loss'],\n",
    "            mode='lines',\n",
    "            name=f'{model_name} Buffer Val Loss'\n",
    "        ))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Training and Validation Loss',\n",
    "    xaxis_title='Epochs',\n",
    "    yaxis_title='MSE Loss',\n",
    "    template='plotly_white',\n",
    "    yaxis=dict(range=[-0.0, 1]),\n",
    ")\n",
    "fig.update_xaxes(\n",
    "    tickvals=[0, 10, 20, 30, 40, 50],\n",
    "    # tickvals = np.multiply(np.array([0, 10, 20, 30, 40, 50]), 3).tolist(),\n",
    "    ticktext=list(df['domain'].unique())\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008f246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt\n",
    "plt.figure(figsize=(20,7))\n",
    "for name, model in models.items():\n",
    "    plt.plot(model['train_epoch_loss'], label=f'{name} Train Loss')\n",
    "    plt.plot(model['val_epoch_loss'], label=f'{name} Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "# plt.ylim(-0.01, 1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ac6692",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,m in models.items():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786326cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = []\n",
    "for name, model in models.items():\n",
    "    for i in range(6):\n",
    "        final += list(model['cross_domain_val'][i].values())\n",
    "max_loss = max(final)\n",
    "min_loss = min(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfedc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt\n",
    "history = models['history']['cross_domain_val']\n",
    "\n",
    "# Extract domain names\n",
    "domains = list(history[0].keys())\n",
    "\n",
    "# Prepare accuracy per domain over time\n",
    "domain_scores = {domain: [] for domain in domains}\n",
    "for snapshot in history:\n",
    "    for domain in domains:\n",
    "        domain_scores[domain].append(snapshot[domain])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "for domain, scores in domain_scores.items():\n",
    "    plt.plot(domains[:len(scores)], scores, label=domain, marker='o')\n",
    "\n",
    "plt.xlabel(\"After training on domain X\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Domain-wise Accuracy Over Time\")\n",
    "# plt.ylim(min(-0.1, min_loss), max_loss)\n",
    "# plt.ylim(-0.05, 0.1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381414ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Prepare data structure\n",
    "domain_data = {}\n",
    "for model_name, model_history in models.items():\n",
    "    history = model_history['cross_domain_val']\n",
    "    domains = list(history[0].keys())\n",
    "    domain_data[model_name] = {\n",
    "        domain: [snapshot[domain] for snapshot in history]\n",
    "        for domain in domains\n",
    "    }\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Color palette for domains\n",
    "domain_colors = {\n",
    "    domain: color for domain, color in zip(\n",
    "        domains, \n",
    "        ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', \"#05ffee\"]\n",
    "    )\n",
    "}\n",
    "\n",
    "# Add traces for each model and domain\n",
    "for model_idx, (model_name, domains) in enumerate(domain_data.items()):\n",
    "    for domain, scores in domains.items():\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=list(range(len(scores))),\n",
    "            y=scores,\n",
    "            mode='lines+markers',\n",
    "            name=domain,\n",
    "            line=dict(color=domain_colors[domain], width=2),\n",
    "            marker=dict(size=8, symbol=model_idx+1),  # Unique symbol per model\n",
    "            legendgroup=model_name,\n",
    "            legendgrouptitle_text=model_name,\n",
    "            visible=True if model_idx == 0 else 'legendonly'  # Show first model by default\n",
    "        ))\n",
    "\n",
    "# Create model selection buttons\n",
    "buttons = [\n",
    "    dict(\n",
    "        label=model_name,\n",
    "        method='update',\n",
    "        args=[\n",
    "            {'visible': [m == model_name for m in domain_data.keys() for _ in domains]},\n",
    "            {'title': f'Domain Losses: {model_name}'}\n",
    "        ]\n",
    "    ) for model_name in domain_data.keys()\n",
    "]\n",
    "\n",
    "# Layout configuration\n",
    "fig.update_layout(\n",
    "    title='Validation Loss of Domain X After Training on Domain Y',\n",
    "    xaxis_title='After Training on Domain Y',\n",
    "    yaxis_title='MSE Loss',\n",
    "    legend=dict(\n",
    "        title='Domain X',\n",
    "        groupclick=\"toggleitem\",  # Allows group toggling while preserving individual control\n",
    "        itemsizing='constant'\n",
    "    ),\n",
    "    updatemenus=[{\n",
    "        'type': 'dropdown',\n",
    "        'direction': 'down',\n",
    "        'showactive': True,\n",
    "        'buttons': buttons,\n",
    "        'x': 1,\n",
    "        'xanchor': 'left',\n",
    "        'y': 1.1,\n",
    "        'yanchor': 'top'\n",
    "    }],\n",
    "    template='plotly_white',\n",
    "    # width=1200,\n",
    "    # height=700\n",
    "    yaxis=dict(range=[min(-0.01, min_loss), max_loss]),\n",
    "    # yaxis=dict(range=[-0.0, 0.8]),\n",
    "    \n",
    ")\n",
    "fig.update_xaxes(\n",
    "    tickvals=[0, 1, 2, 3, 4, 5],\n",
    "    ticktext=list(df['domain'].unique())\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1042f8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca845ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt similarity\n",
    "h = models['deep_norm']\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot([m['similarity'] for m in h['train_epoch_metrics']])\n",
    "plt.xticks(np.arange(0, 60, step=1))\n",
    "plt.title('cosine similarity of two branches')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db02bb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt\n",
    "h = models['history']\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "for metric in ['inv_acc', 'spec_acc']:\n",
    "    plt.plot([m[metric] for m in h['train_epoch_metrics']], label=metric)\n",
    "plt.title('Branch accuracies and their similarity')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Metric Value')\n",
    "plt.xticks(np.arange(0, 60, step=1))\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac727bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for model_name, history in models.items():\n",
    "    for metric in ['inv_acc', 'spec_acc']:\n",
    "        try:\n",
    "            y_values = [m[metric] for m in history['train_epoch_metrics']]\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=list(range(len(y_values))),\n",
    "                y=y_values,\n",
    "                mode='lines+markers',\n",
    "                name=f'{model_name} - {metric}'\n",
    "            ))\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Branch Accuracies',\n",
    "    xaxis_title='Epoch',\n",
    "    yaxis_title='Accuracy',\n",
    "    # xaxis=dict(tickmode='linear', tick0=0, dtick=1),\n",
    "    template='plotly_white',\n",
    "    # width=1000,\n",
    "    # height=400\n",
    "    yaxis=dict(range=[-0.0, 1]),\n",
    ")\n",
    "fig.update_xaxes(\n",
    "    tickvals=[0, 10, 20, 30, 40, 50],\n",
    "    ticktext=list(df['domain'].unique())\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0431a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt\n",
    "h = models['history']\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "for metric in ['inv_domain', 'spec_domain', 'task_loss']:\n",
    "    plt.plot([m[metric] for m in h['train_epoch_metrics']], label=metric)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Metric Value')\n",
    "plt.ylim(-0.01, 1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12705d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for model_name, history in models.items():\n",
    "    for metric in ['inv_domain', 'spec_domain', 'task_loss']:\n",
    "        try:\n",
    "            y_values = [m[metric] for m in history['train_epoch_metrics']]\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=list(range(len(y_values))),\n",
    "                y=y_values,\n",
    "                mode='lines+markers',\n",
    "                name=f'{model_name} - {metric}'\n",
    "            ))\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "fig.update_layout(\n",
    "    title='CE loss - inv_domain, spec_domain, and MSE task_loss',\n",
    "    xaxis_title='Epoch',\n",
    "    yaxis_title='Loss',\n",
    "    template='plotly_white',\n",
    "    # width=1000,\n",
    "    # height=400\n",
    "    yaxis=dict(range=[-0.01, 0.12]),\n",
    ")\n",
    "fig.update_xaxes(\n",
    "    tickvals=[0, 10, 20, 30, 40, 50],\n",
    "    ticktext=list(df['domain'].unique())\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deef2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = models['history']\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "for metric in ['replay_count', 'current_count']:\n",
    "    plt.plot([m[metric]/32*100 for m in h['train_epoch_metrics']], label=metric)\n",
    "plt.title('Type of samples in batch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('% of batch')\n",
    "# plt.axhline(32, color='r')\n",
    "# plt.xticks(np.arange(0, 60, step=1))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38e8bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "# for module in ['invariant', 'specific_residual', 'domain_classifier']:\n",
    "for module in h['grad_norms'][0].keys():\n",
    "    plt.plot([m[f'{module}'] for m in h['grad_norms']], label=module)\n",
    "plt.title('Gradient Norms by Module')\n",
    "# plt.ylim(-0.001, 1)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c755d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Collect all module names across all models\n",
    "all_modules = set()\n",
    "for model_name, history in models.items():\n",
    "    if 'grad_norms' in history and len(history['grad_norms']) > 0:\n",
    "        for grad_dict in history['grad_norms']:\n",
    "            all_modules.update(grad_dict.keys())\n",
    "all_modules = sorted(all_modules)\n",
    "# all_modules = ['invariant', 'specific', 'head']\n",
    "\n",
    "\n",
    "# Add traces for each model and module, only show the first model by default\n",
    "trace_visibility = []\n",
    "for model_idx, (model_name, history) in enumerate(models.items()):\n",
    "    if 'grad_norms' not in history or len(history['grad_norms']) == 0:\n",
    "        continue\n",
    "    for grad_dict in history['grad_norms']:\n",
    "        for key in all_modules:\n",
    "            grad_dict.setdefault(key, 0)\n",
    "    for module in all_modules:\n",
    "        y_values = [m[module] for m in history['grad_norms']]\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=list(range(len(y_values))),\n",
    "            y=y_values,\n",
    "            mode='lines+markers',\n",
    "            name=f'{model_name} - {module}',\n",
    "            # visible=(model_idx == 0)\n",
    "        ))\n",
    "    trace_visibility.append((model_name, len(all_modules)))\n",
    "\n",
    "# Create dropdown buttons for each model\n",
    "buttons = []\n",
    "start_idx = 0\n",
    "for model_name, n_traces in trace_visibility:\n",
    "    visible = [False] * len(fig.data)\n",
    "    for i in range(start_idx, start_idx + n_traces):\n",
    "        visible[i] = True\n",
    "    buttons.append(dict(\n",
    "        label=model_name,\n",
    "        method='update',\n",
    "        args=[{'visible': visible}, {'title': f'Gradient Norms by Module - {model_name}'}]\n",
    "    ))\n",
    "    start_idx += n_traces\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'Gradient Norms by Module - {list(models.keys())[0]}',\n",
    "    xaxis_title='Epoch',\n",
    "    yaxis_title='Gradient Norm',\n",
    "    template='plotly_white',\n",
    "    # width=1000,\n",
    "    # height=400,\n",
    "    updatemenus=[{\n",
    "        'buttons': buttons,\n",
    "        'direction': 'down',\n",
    "        'showactive': True,\n",
    "        'x': 1,\n",
    "        'xanchor': 'left',\n",
    "        'y': 1.2,\n",
    "        'yanchor': 'top'\n",
    "    }],\n",
    "    yaxis=dict(range=[-0.0, 0.2]),\n",
    ")\n",
    "fig.update_xaxes(\n",
    "    tickvals=[0, 10, 20, 30, 40, 50],\n",
    "    ticktext=list(df['domain'].unique())\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93af0c29",
   "metadata": {},
   "source": [
    "### tsne projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca35a6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "\n",
    "# 1. Gather all checkpoint files\n",
    "checkpoint_files = glob.glob(\"../checkpoints/dualbranchmodel_20250609_013632_*.pt\")\n",
    "\n",
    "# 2. Parse out the step value and sort\n",
    "pattern = re.compile(r\"_step(\\d+)\\.pt\")\n",
    "files_with_steps = []\n",
    "for f in checkpoint_files:\n",
    "    match = pattern.search(f)\n",
    "    if match:\n",
    "        step = int(match.group(1))\n",
    "        files_with_steps.append((step, f))\n",
    "files_with_steps.sort()  # Sort by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3fc5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cf6cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Precompute t-SNE for all checkpoints (0-59)\n",
    "tsne_projections = []\n",
    "for idx, (step, ckpt_file) in enumerate(tqdm(files_with_steps, desc=\"Processing checkpoints\")):\n",
    "    ckpt = torch.load(ckpt_file, map_location='cpu')\n",
    "    data = ckpt['tsne']\n",
    "    inv_feats = np.array(data['inv_feats'])\n",
    "    spec_feats = np.array(data['spec_feats'])\n",
    "    domain_labels = np.array(data['domain_labels'])\n",
    "\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    inv_2d = tsne.fit_transform(inv_feats)\n",
    "    spec_2d = tsne.fit_transform(spec_feats)\n",
    "\n",
    "    tsne_projections.append({\n",
    "        'timeline_idx': idx,  # 0 to 59\n",
    "        'inv_2d': inv_2d,\n",
    "        'spec_2d': spec_2d,\n",
    "        'domains': domain_labels,\n",
    "        'filename': ckpt_file\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622438e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# State variable for current index\n",
    "current_idx = 0\n",
    "\n",
    "# Output widget for the plot\n",
    "out = widgets.Output()\n",
    "\n",
    "# Buttons\n",
    "button_prev = widgets.Button(description=\"Previous\")\n",
    "button_next = widgets.Button(description=\"Next\")\n",
    "\n",
    "# Precompute limits\n",
    "all_x = np.concatenate([d['inv_2d'][:,0] for d in tsne_projections] + [d['spec_2d'][:,0] for d in tsne_projections])\n",
    "all_y = np.concatenate([d['inv_2d'][:,1] for d in tsne_projections] + [d['spec_2d'][:,1] for d in tsne_projections])\n",
    "x_min, x_max = all_x.min(), all_x.max()\n",
    "y_min, y_max = all_y.min(), all_y.max()\n",
    "\n",
    "def plot_epoch(timeline_idx):\n",
    "    data = tsne_projections[timeline_idx]\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6), constrained_layout=True)\n",
    "    domain_to_int = {name: i for i, name in enumerate(domains)}\n",
    "    domain_ints = np.array([domain_to_int[name] for name in data['domains']])\n",
    "    scatter1 = ax1.scatter(data['inv_2d'][:,0], data['inv_2d'][:,1], \n",
    "                          c=domain_ints, cmap='tab10', alpha=0.7, vmin=0, vmax=len(domains)-1)\n",
    "    ax1.set_title(f\"Invariant Features - Timeline {timeline_idx}\")\n",
    "    ax1.set_xlim(x_min, x_max)\n",
    "    ax1.set_ylim(y_min, y_max)\n",
    "    scatter2 = ax2.scatter(data['spec_2d'][:,0], data['spec_2d'][:,1],\n",
    "                          c=domain_ints, cmap='tab10', alpha=0.7, vmin=0, vmax=len(domains)-1)\n",
    "    ax2.set_title(f\"Specific Features - Timeline {timeline_idx}\")\n",
    "    ax2.set_xlim(x_min, x_max)\n",
    "    ax2.set_ylim(y_min, y_max)\n",
    "    cbar = fig.colorbar(scatter1, ax=[ax1, ax2], label='Domain', \n",
    "                        ticks=np.arange(len(domains)), boundaries=np.arange(len(domains)+1)-0.5)\n",
    "    cbar.set_ticks(np.arange(len(domains)))\n",
    "    cbar.set_ticklabels(domains)\n",
    "    plt.show()\n",
    "\n",
    "def on_prev_clicked(b):\n",
    "    global current_idx\n",
    "    if current_idx > 0:\n",
    "        current_idx -= 1\n",
    "        with out:\n",
    "            clear_output(wait=True)\n",
    "            plot_epoch(current_idx)\n",
    "\n",
    "def on_next_clicked(b):\n",
    "    global current_idx\n",
    "    if current_idx < len(tsne_projections) - 1:\n",
    "        current_idx += 1\n",
    "        with out:\n",
    "            clear_output(wait=True)\n",
    "            plot_epoch(current_idx)\n",
    "\n",
    "button_prev.on_click(on_prev_clicked)\n",
    "button_next.on_click(on_next_clicked)\n",
    "\n",
    "# Display everything\n",
    "display(widgets.HBox([button_prev, button_next]))\n",
    "display(out)\n",
    "\n",
    "# Initial plot\n",
    "with out:\n",
    "    plot_epoch(current_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fbd146",
   "metadata": {},
   "source": [
    "### single batch overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef28985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After model output\n",
    "outputs = model(inputs)  # Should be in [1,5]\n",
    "print(f\"Output range: {outputs.min().item()}–{outputs.max().item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d65d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = LGRBaseline().to(device)\n",
    "test_optimizer = optim.Adam(test_model.parameters(), lr=1e-3)\n",
    "buffer = NaiveRehearsalBuffer(0)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "first_domain = domains[0]\n",
    "train_loader = domain_dataloaders[first_domain]['train']\n",
    "single_batch = next(iter(train_loader))\n",
    "inputs, labels, _ = single_batch\n",
    "inputs = inputs.to(device, dtype=torch.float32)\n",
    "labels = labels.to(device, dtype=torch.float32)\n",
    "\n",
    "# %%\n",
    "num_test_epochs = 400\n",
    "for epoch in range(num_test_epochs):\n",
    "    test_optimizer.zero_grad()\n",
    "\n",
    "    outputs = test_model(inputs)\n",
    "    loss = criterion(outputs['output'], labels)\n",
    "    \n",
    "    loss.backward()\n",
    "    test_optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0 or epoch == 0:\n",
    "        print(f\"Overfit Epoch {epoch+1}/{num_test_epochs} | Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77ffaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# device = torch.device('cpu')torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "domains = df['domain'].unique()\n",
    "\n",
    "writer = SummaryWriter(\"visualisation/\")\n",
    "model = DualBranchNet().to(device)\n",
    "first_domain = domains[0]\n",
    "train_loader = domain_dataloaders[first_domain]['train']\n",
    "single_batch = next(iter(train_loader))\n",
    "inputs, labels, _ = single_batch\n",
    "inputs = inputs.to(device, dtype=torch.float32)\n",
    "labels = labels.to(device, dtype=torch.float32)\n",
    "# writer.add_graph(model, inputs)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4443f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_names = [\"image\"]\n",
    "output_names = [\"appropriateness scores\"]\n",
    "\n",
    "torch.onnx.export(model, inputs, \"model.onnx\", input_names=input_names, output_names=output_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8284523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "y = model(inputs)\n",
    "make_dot(y.mean(), params=dict(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99f5767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1. Get a single batch from any domain's train loader\n",
    "domain = domains[0]\n",
    "single_batch = next(iter(domain_dataloaders[domain]['train']))\n",
    "\n",
    "\n",
    "buffer = NaiveRehearsalBuffer(0)\n",
    "\n",
    "# 4. Overfit loop for both models\n",
    "def overfit_model(\n",
    "    model, optimizer, batch_fn, batch_kwargs, device, num_epochs=100, exp_name=\"overfit\"\n",
    "):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        loss, metrics = batch_fn(model, single_batch, device, **batch_kwargs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.6f}\")\n",
    "    return losses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04454a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Baseline model overfit\n",
    "baseline_model = LGRBaseline().to(device)\n",
    "optimizer = torch.optim.Adam(baseline_model.parameters(), lr=1e-3)\n",
    "baseline_losses = overfit_model(\n",
    "    baseline_model, optimizer, baseline_batch, {'mse_criterion': torch.nn.MSELoss()}, device\n",
    ")\n",
    "\n",
    "# 6. DualBranch model overfit\n",
    "dual_model = DualBranchNet(num_domains=len(domains)).to(device)\n",
    "optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "dualbranch_kwargs = {\n",
    "    'mse_criterion': torch.nn.MSELoss(),\n",
    "    'ce_criterion': torch.nn.CrossEntropyLoss(),\n",
    "    'cos_criterion': lambda a, b: (torch.nn.CosineSimilarity()(a, b) ** 2).mean(),\n",
    "    'domain_to_idx': domain_to_idx,\n",
    "    'current_domain': domain\n",
    "}\n",
    "dualbranch_losses = overfit_model(\n",
    "    dual_model, optimizer, dualbranch_batch, dualbranch_kwargs, device\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1130c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Plot the loss curves (optional)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(baseline_losses, label='Baseline')\n",
    "plt.plot(dualbranch_losses, label='DualBranch')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Overfitting to a Single Batch')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd90861",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "socialsense",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
