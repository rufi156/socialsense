{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d72ee38c",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2560ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "DATASET_DIR = (Path(\"..\") / \"..\" / \"datasets\").resolve()\n",
    "DATASETS = [\"OFFICE-MANNERSDB\", \"MANNERSDBPlus\"]\n",
    "LABEL_COLS = [\n",
    "    \"Vaccum Cleaning\", \"Mopping the Floor\", \"Carry Warm Food\",\n",
    "    \"Carry Cold Food\", \"Carry Drinks\", \"Carry Small Objects\",\n",
    "    \"Carry Large Objects\", \"Cleaning\", \"Starting a conversation\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9da04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv(csv_path, dataset):\n",
    "    \"\"\"Process individual CSV files\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = df.drop(columns=df.columns[-1])\n",
    "    \n",
    "    # Extract metadata from first column\n",
    "    first_col = df.columns[0]\n",
    "    split_data = df[first_col].str.split('_', n=2, expand=True)\n",
    "    \n",
    "    df[\"robot\"] = split_data[0]\n",
    "    df[\"domain\"] = split_data[1]\n",
    "    df[\"image_ref\"] = split_data[2].astype(int)\n",
    "    df[\"dataset\"] = dataset\n",
    "\n",
    "    df = df.drop(columns=[first_col])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def consolidate_data(datasets):\n",
    "    \"\"\"Aggregate all CSVs\"\"\"\n",
    "    all_dfs = []\n",
    "    for dataset in datasets:\n",
    "        source_path = DATASET_DIR / dataset\n",
    "        \n",
    "        for robot in [\"NAO\", \"Pepper\", \"PR2\"]:\n",
    "            ann_dir = source_path / robot / \"Annotations\"\n",
    "            if not ann_dir.exists():\n",
    "                raise ValueError(f\"Labels csv file path ({ann_dir}) doesn't exist\")\n",
    "                \n",
    "            \n",
    "            for csv_file in ann_dir.glob(\"*.csv\"):\n",
    "                try:\n",
    "                    df = process_csv(csv_file, dataset)\n",
    "                    all_dfs.append(df)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {csv_file}: {str(e)}\")\n",
    "    \n",
    "    df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53657ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_raw_data(df):\n",
    "    \"\"\"Comprehensive data quality checks for raw annotation data\"\"\"\n",
    "    required_columns = {'robot', 'domain', 'image_ref', 'dataset'}\n",
    "\n",
    "    # Check for any missing columns\n",
    "    missing_cols = required_columns - set(df.columns)\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "\n",
    "    # Label value validation (should be between 1 and 5)\n",
    "    for col in LABEL_COLS:\n",
    "        if df[col].min() < 1 or df[col].max() > 5:\n",
    "            raise ValueError(f\"Label {col} has invalid range [{df[col].min()}, {df[col].max()}]\")\n",
    "\n",
    "    # Null values check\n",
    "    null_cols = df.columns[df.isnull().any()].tolist()\n",
    "    if null_cols:\n",
    "        raise ValueError(f\"Null values found in columns: {null_cols}\")\n",
    "\n",
    "    # Data type and value validation for image_ref\n",
    "    if not pd.api.types.is_integer_dtype(df['image_ref']):\n",
    "        raise TypeError(\"image_ref must be integer type\")\n",
    "    if (df['image_ref'] < 0).any():\n",
    "        raise ValueError(\"image_ref contains negative values, which is invalid\")\n",
    "\n",
    "    # Categorical value validation\n",
    "    valid_robots = {'NAO', 'Pepper', 'PR2'}\n",
    "    invalid_robots = set(df['robot']) - valid_robots\n",
    "    if invalid_robots:\n",
    "        raise ValueError(f\"Invalid robot values: {invalid_robots}\")\n",
    "\n",
    "    valid_sources = {'OFFICE-MANNERSDB', 'MANNERSDBPlus'}\n",
    "    invalid_sources = set(df['dataset']) - valid_sources\n",
    "    if invalid_sources:\n",
    "        raise ValueError(f\"Invalid source directories: {invalid_sources}\")\n",
    "\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb45d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_labels(df):\n",
    "    \"\"\"Aggregate multiple annotations per image by image path\"\"\"    \n",
    "    agg_dict = {\n",
    "        **{col: 'mean' for col in LABEL_COLS},\n",
    "        **{col: 'first' for col in df.columns.difference(LABEL_COLS).tolist()},\n",
    "    }\n",
    "    \n",
    "    return df.groupby('image_path', as_index=False).agg(agg_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e53d64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_image_path(row):\n",
    "    \"\"\"Robust path resolution with validation\"\"\"\n",
    "    base_dir = DATASET_DIR / row['dataset'] / row['robot'] / \"Images\"\n",
    "    \n",
    "    if row['dataset'] == \"OFFICE-MANNERSDB\":\n",
    "        target = base_dir / f\"{row['domain']}_{row['image_ref']}.png\"\n",
    "    else:\n",
    "        target = next(base_dir.glob(f\"{row['image_ref']}_*.png\"), None)\n",
    "    \n",
    "    if target and target.exists():\n",
    "        return str(target.resolve())\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37acfe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageLabelDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, torch.Tensor):\n",
    "            idx = idx.item()\n",
    "            \n",
    "        img_path = str(self.df.at[idx, \"image_path\"])\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error loading {img_path}: {str(e)}\")\n",
    "        \n",
    "        raw_labels = self.df.iloc[idx][LABEL_COLS].values.astype(np.float32)\n",
    "        scaled_labels = (raw_labels - 1) / 4  # Convert 1-5 → 0-1\n",
    "        domain_labels = self.df.at[idx, 'domain']\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, torch.from_numpy(scaled_labels), domain_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f915a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(df, batch_sizes=(32, 64, 64), resize_img_to=(128, 128)):\n",
    "    \"\"\"Create train/val/test dataloaders using image_path as unique key\"\"\"\n",
    "    \n",
    "    # Get image paths as indexing for split\n",
    "    unique_images = df[['image_path']].reset_index(drop=True)\n",
    "    \n",
    "    # Split using image_path as key\n",
    "    train_paths, temp_paths = train_test_split(\n",
    "        unique_images['image_path'], \n",
    "        test_size=0.3, \n",
    "        random_state=42\n",
    "    )\n",
    "    val_paths, test_paths = train_test_split(\n",
    "        temp_paths,\n",
    "        test_size=0.5, \n",
    "        random_state=42\n",
    "    )\n",
    "   \n",
    "    # Create subsets\n",
    "    train_df = df[df['image_path'].isin(train_paths)].reset_index(drop=True)\n",
    "    val_df = df[df['image_path'].isin(val_paths)].reset_index(drop=True)\n",
    "    test_df = df[df['image_path'].isin(test_paths)].reset_index(drop=True)\n",
    "    \n",
    "    #TODO add coordinate values for spacialy aware CNN Uber's CoordNav\n",
    "    # Define transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(resize_img_to),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                            std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = ImageLabelDataset(train_df, transform)\n",
    "    val_dataset = ImageLabelDataset(val_df, transform)\n",
    "    test_dataset = ImageLabelDataset(test_df, transform)\n",
    "    \n",
    "    # Create loaders\n",
    "    num_workers = 0\n",
    "    loaders = {\n",
    "        'train': DataLoader(train_dataset, batch_size=batch_sizes[0], shuffle=True, num_workers=num_workers, pin_memory=torch.cuda.is_available()),\n",
    "        'val': DataLoader(val_dataset, batch_size=batch_sizes[1], shuffle=False, num_workers=num_workers, pin_memory=torch.cuda.is_available()),\n",
    "        'test': DataLoader(test_dataset, batch_size=batch_sizes[2], shuffle=False, num_workers=num_workers, pin_memory=torch.cuda.is_available())\n",
    "    }\n",
    "    \n",
    "    return loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9668e590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_final_data(df):\n",
    "    \"\"\"Final validation after aggregation\"\"\"\n",
    "    # Missing image paths\n",
    "    missing = df[df['image_path'].isnull()]\n",
    "    if not missing.empty:\n",
    "        raise FileNotFoundError(\n",
    "            f\"{len(missing)} images missing after aggregation. Examples:\\n\"\n",
    "            f\"{missing[['robot', 'domain', 'image_ref']].head()}\"\n",
    "        )\n",
    "    \n",
    "    # Null values check\n",
    "    null_cols = df.columns[df.isnull().any()].tolist()\n",
    "    if null_cols:\n",
    "        raise ValueError(f\"Null values found in columns: {null_cols}\")\n",
    "\n",
    "    # Duplicate image paths\n",
    "    duplicates = df[df.duplicated('image_path', keep=False)]\n",
    "    if not duplicates.empty:\n",
    "        raise RuntimeError(\n",
    "            f\"Duplicate image paths after aggregation:\\n\"\n",
    "            f\"{duplicates['image_path'].unique()}\"\n",
    "        )\n",
    "\n",
    "    # Label validity (1-5)\n",
    "    for col in LABEL_COLS:\n",
    "        if df[col].min() < 1 or df[col].max() > 5:\n",
    "            raise ValueError(\n",
    "                f\"Aggregated label {col} out of range: \"\n",
    "                f\"[{df[col].min()}, {df[col].max()}]\"\n",
    "            )\n",
    "\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfd34a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac2a2a2b",
   "metadata": {},
   "source": [
    "## --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f66130",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    raw_df = consolidate_data(DATASETS)\n",
    "    validate_raw_data(raw_df)\n",
    "    raw_df['image_path'] = raw_df.apply(resolve_image_path, axis=1)   \n",
    "    aggregated_df = aggregate_labels(raw_df)\n",
    "    validate_final_data(aggregated_df) \n",
    "except Exception as e:\n",
    "    print(f\"Pipeline failed: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "aggregated_df.to_pickle(\"../data/processed_all_data.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43ca986",
   "metadata": {},
   "source": [
    "## CL Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b327a539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import random\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Subset, ConcatDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca1a5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SocialContinualModel(nn.Module):\n",
    "    def __init__(self, num_tasks=9):\n",
    "        super().__init__()\n",
    "        # Initialize the ResNet50 architecture with Places365 configuration\n",
    "        self.backbone = models.resnet50(num_classes=365)\n",
    "        \n",
    "        # get Places365 weights and fix their naming leftover from troch saving convention\n",
    "        places365_weights = torch.load('resnet50_places365.pth.tar', weights_only=True)\n",
    "        state_dict = places365_weights['state_dict']\n",
    "        state_dict = {k.replace('module.', ''): v \n",
    "                     for k, v in state_dict.items()}\n",
    "        \n",
    "        # Load weights\n",
    "        self.backbone.load_state_dict(state_dict)\n",
    "        \n",
    "        # Remove classification head\n",
    "        self.backbone.fc = nn.Identity()\n",
    "\n",
    "        #Freeze all params except last layer\n",
    "        for name, param in self.backbone.named_parameters():\n",
    "            if 'layer4' not in name:\n",
    "                param.requires_grad_(False)\n",
    "        \n",
    "        #TODO human mask average, std, quadrants, human in realtion to robot std\n",
    "        \n",
    "\n",
    "\n",
    "        # Shared layers #TODO deeper shared space?\n",
    "        self.shared_fc = nn.Sequential(\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        # Task-specific heads with more expensive but finegrained GELU\n",
    "        self.heads = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(1024, 512),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(512, 1),\n",
    "                nn.Sigmoid()\n",
    "            ) for _ in range(num_tasks)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        shared = self.shared_fc(features)\n",
    "        outputs = [head(shared) for head in self.heads]\n",
    "        return torch.cat(outputs, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971efe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "class LGRBaseline(nn.Module):\n",
    "    \"\"\"\n",
    "    @misc{churamani_feature_2024,\n",
    "\t\ttitle = {Feature Aggregation with Latent Generative Replay for Federated Continual Learning of Socially Appropriate Robot Behaviours},\n",
    "\t\turl = {http://arxiv.org/abs/2405.15773},\n",
    "\t\tdoi = {10.48550/arXiv.2405.15773},\n",
    "\t\tnumber = {{arXiv}:2405.15773},\n",
    "\t\tpublisher = {{arXiv}},\n",
    "\t\tauthor = {Churamani, Nikhil and Checker, Saksham and Chiang, Hao-Tien Lewis and Gunes, Hatice},\n",
    "\t\turldate = {2025-01-30},\n",
    "\t\tdate = {2024-03-16},\n",
    "\t}\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=9):\n",
    "        super(LGRBaseline, self).__init__()\n",
    "        \n",
    "        # MobileNetV2 backbone\n",
    "        self.backbone = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1).features\n",
    "        \n",
    "        # Backbone feature processing\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # Regression head\n",
    "        self.fc1_bn = nn.BatchNorm1d(1280)\n",
    "        self.fc2 = nn.Linear(1280, 32)\n",
    "        # self.fc2_bn = nn.BatchNorm1d(128)\n",
    "\t\t# self.fc3 = nn.Linear(128, 32)\n",
    "        self.fc4 = nn.Linear(32, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Feature extraction\n",
    "        x = self.backbone(x)\n",
    "        \n",
    "        # Spatial reduction\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        # Regression\n",
    "        x = self.fc1_bn(x)\n",
    "        x = self.fc2(x)\n",
    "        # x = self.fc2_bn(x)\n",
    "\t\t# x = self.fc3(x)\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return {'output': x}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a7176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "class ReservoirBuffer:\n",
    "    def __init__(self, capacity=1000, replay_ratio=0.2, input_shape=(3, 384, 216), label_shape=(9,), device=torch.device('cpu')):\n",
    "        self.capacity = capacity\n",
    "        self.inputs = torch.empty((capacity, *input_shape), dtype=torch.float32, device=device)\n",
    "        self.labels = torch.empty((capacity, *label_shape), dtype=torch.float32, device=device)\n",
    "        self.domains = [None] * capacity\n",
    "        self.size = 0          # Number of samples currently in buffer\n",
    "        self.num_seen = 0      # Total samples seen\n",
    "        self.replay_ratio = replay_ratio\n",
    "\n",
    "    def add(self, new_samples):\n",
    "        for sample in new_samples:\n",
    "            self.num_seen += 1\n",
    "            if self.size < self.capacity:\n",
    "                idx = self.size\n",
    "                self.size += 1\n",
    "            else:\n",
    "                idx = random.randint(0, self.num_seen - 1)\n",
    "                if idx >= self.capacity:\n",
    "                    continue\n",
    "            self.inputs[idx].copy_(sample[0])\n",
    "            self.labels[idx].copy_(sample[1])\n",
    "            self.domains[idx] = sample[2]\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        if self.size == 0:\n",
    "            return []\n",
    "        indices = torch.randint(0, self.size, (batch_size,))\n",
    "        return [(self.inputs[i], self.labels[i], self.domains[i]) for i in indices]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def get_domain_distribution(self):\n",
    "        return pd.Series(self.domains[:self.size]).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb2f843",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveRehearsalBuffer:\n",
    "    \"\"\"\n",
    "    @inproceedings{Hsu18_EvalCL,\n",
    "        title={Re-evaluating Continual Learning Scenarios: A Categorization and Case for Strong Baselines},\n",
    "        author={Yen-Chang Hsu and Yen-Cheng Liu and Anita Ramasamy and Zsolt Kira},\n",
    "        booktitle={NeurIPS Continual learning Workshop },\n",
    "        year={2018},\n",
    "        url={https://arxiv.org/abs/1810.12488}\n",
    "    }\n",
    "    \"\"\"\n",
    "    def __init__(self, buffer_size=1000):\n",
    "        self.buffer_size = buffer_size\n",
    "        self.domain_buffer = {}\n",
    "\n",
    "    def update_buffer(self, domain, dataset):\n",
    "        # Add/overwrite current domain\n",
    "        self.domain_buffer[domain] = Subset(dataset, torch.arange(len(dataset)))\n",
    "        \n",
    "        # Recalculate quota - even for each domain\n",
    "        num_domains = len(self.domain_buffer)\n",
    "        buffer_quota_per_domain = self.buffer_size // num_domains\n",
    "        \n",
    "        # Reduce all domains (including current)\n",
    "        for domain in self.domain_buffer:\n",
    "            subset = self.domain_buffer[domain]\n",
    "            max_safe_samples_to_overwrite = min(buffer_quota_per_domain, len(subset.dataset))\n",
    "            rand_indices = torch.randperm(len(dataset))[:max_safe_samples_to_overwrite].numpy()\n",
    "            self.domain_buffer[domain] = Subset(dataset, rand_indices)\n",
    "\n",
    "    def get_loader_with_replay(self, current_domain, current_loader):\n",
    "        current_dataset = current_loader.dataset\n",
    "        replay_datasets = [dataset for domain, dataset in self.domain_buffer.items() if domain != current_domain]\n",
    "\n",
    "        #Enforces 1:1 ratio when current ≥ buffer\n",
    "        total_replay = sum(len(dataset) for dataset in replay_datasets)\n",
    "        if total_replay > 0:\n",
    "            K = max(len(current_dataset) // total_replay, 1)\n",
    "            replay_datasets = replay_datasets * K\n",
    "\n",
    "        combined_dataset =  ConcatDataset(replay_datasets + [current_dataset])\n",
    "        combined_dataset = DataLoader(\n",
    "            combined_dataset,\n",
    "            batch_size=current_loader.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=current_loader.num_workers,\n",
    "            pin_memory=current_loader.pin_memory,\n",
    "            drop_last=current_loader.drop_last\n",
    "        )\n",
    "        return combined_dataset\n",
    "    \n",
    "    def get_domain_distribution(self):\n",
    "        \"\"\"Returns {domain: num_samples} without needing Storage\"\"\"\n",
    "        return {domain: len(subset) for domain, subset in self.domain_buffer.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7c71f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientReversalFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        ctx.alpha = alpha\n",
    "        return x.view_as(x)\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        output = grad_output.neg() * ctx.alpha\n",
    "        return output, None\n",
    "\n",
    "class GradientReversal(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return GradientReversalFunction.apply(x, 1.0)\n",
    "\n",
    "\n",
    "class DualBranchNet(nn.Module):\n",
    "    def __init__(self, num_outputs=9, num_domains=6, weights_init=False, weights_norm=False, layer_norm=False, detach_base=True, freeze_base=''):\n",
    "        super().__init__()\n",
    "\n",
    "        self.detach_base = detach_base\n",
    "\n",
    "        def linear(in_f, out_f):\n",
    "            layer = nn.Linear(in_f, out_f)\n",
    "            return torch.nn.utils.parametrizations.weight_norm(layer, dim=0) if weights_norm else layer \n",
    "        \n",
    "        def layer_norm(dim):\n",
    "            return nn.LayerNorm(dim) if layer_norm else nn.Identity()\n",
    "\n",
    "        self.backbone = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1).features\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.feature_dim = 1280\n",
    "\n",
    "        if freeze_base in ('full', 'partial'):\n",
    "            for param in self.backbone.parameters():\n",
    "                param.requires_grad = False\n",
    "        if freeze_base == 'partial':\n",
    "            last_layer = list(self.backbone.children())[-1]\n",
    "            for param in last_layer.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "        self.invariant = nn.Sequential(\n",
    "            linear(self.feature_dim, 256),\n",
    "            GradientReversal(),\n",
    "            layer_norm(256),\n",
    "            nn.ReLU(),\n",
    "            linear(256, 256)\n",
    "        )\n",
    "\n",
    "        self.invariant_domain_classifier = nn.Sequential(\n",
    "            layer_norm(256),\n",
    "            nn.Linear(256, num_domains)\n",
    "        )\n",
    "        \n",
    "        self.specific = nn.Sequential(\n",
    "            linear(self.feature_dim, 256),\n",
    "            layer_norm(256), \n",
    "            nn.ReLU(),\n",
    "            linear(256, 256)\n",
    "        )\n",
    "        \n",
    "        self.specific_domain_classifier = nn.Sequential(\n",
    "            layer_norm(256),\n",
    "            nn.Linear(256, num_domains)\n",
    "        )\n",
    "\n",
    "        head_in = 512 + self.feature_dim if self.detach_base else 512\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(head_in, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_outputs)\n",
    "        )\n",
    "\n",
    "        if weights_init:\n",
    "            self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        custom_modules = [\n",
    "            'invariant',\n",
    "            'invariant_domain_classifier',\n",
    "            'specific',\n",
    "            'specific_domain_classifier',\n",
    "            'head'\n",
    "        ]\n",
    "        for name in custom_modules:\n",
    "            module = getattr(self, name, None)\n",
    "            for m in module.modules():\n",
    "                if isinstance(m, nn.Linear):\n",
    "                    nn.init.orthogonal_(m.weight)\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        base = self.backbone(x)\n",
    "        base = self.pool(base).view(x.size(0), -1)\n",
    "\n",
    "        if self.detach_base:\n",
    "            invariant_feats = self.invariant(base.detach())\n",
    "            specific_feats = self.specific(base.detach())\n",
    "            combined = torch.cat([invariant_feats, specific_feats, base], dim=1)\n",
    "        else:\n",
    "            invariant_feats = self.invariant(base)\n",
    "            specific_feats = self.specific(base)\n",
    "            combined = torch.cat([invariant_feats, specific_feats], dim=1)\n",
    "        \n",
    "        invariant_domain_pred = self.invariant_domain_classifier(invariant_feats)\n",
    "        specific_domain_pred = self.specific_domain_classifier(specific_feats)\n",
    "        \n",
    "        scores = self.head(combined)      \n",
    "        \n",
    "        return {\n",
    "            'output': scores,\n",
    "            'invariant_domain': invariant_domain_pred,\n",
    "            'specific_domain': specific_domain_pred,\n",
    "            'invariant_feats': invariant_feats,\n",
    "            'specific_feats': specific_feats\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7e4cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualBranchNet_deep(DualBranchNet):\n",
    "    \"\"\"thicker invariant network to learn features instead of realying on the backbone\"\"\"\n",
    "    def __init__(self, num_outputs=9, num_domains=6, weights_init=True, weights_norm=False, layer_norm=False, detach_base=True, freeze_base=''):\n",
    "        super().__init__(num_outputs, num_domains, weights_init, weights_norm, layer_norm, detach_base, freeze_base)\n",
    "\n",
    "        def linear(in_f, out_f):\n",
    "            layer = nn.Linear(in_f, out_f)\n",
    "            return torch.nn.utils.parametrizations.weight_norm(layer, dim=0) if weights_norm else layer \n",
    "\n",
    "        self.invariant = nn.Sequential(\n",
    "            linear(self.feature_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            linear(256, 256)\n",
    "        )\n",
    "\n",
    "        self.specific = nn.Sequential(\n",
    "            linear(self.feature_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            linear(256, 256)\n",
    "        )\n",
    "\n",
    "        self.invariant_domain_classifier = nn.Sequential(\n",
    "            GradientReversal(),\n",
    "            nn.Linear(256, num_domains)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457558f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualBranchNet_binary(DualBranchNet_deep):\n",
    "    \"\"\"binary classifier for the invariant branch\"\"\"\n",
    "    def __init__(self, num_outputs=9, num_domains=6, weights_init=True, weights_norm=False, layer_norm=False, detach_base=False, freeze_base='', explicit_grl=False):\n",
    "        super().__init__(num_outputs, num_domains, weights_init, weights_norm, layer_norm, detach_base, freeze_base)\n",
    "\n",
    "        self.explicit_grl = explicit_grl\n",
    "        \n",
    "        def gradient_layer():\n",
    "            return nn.Identity() if explicit_grl else GradientReversal()\n",
    "\n",
    "        self.invariant_domain_classifier = nn.Sequential(\n",
    "            gradient_layer(),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        base = self.backbone(x)\n",
    "        base = self.pool(base).view(x.size(0), -1)\n",
    "\n",
    "        if self.detach_base:\n",
    "            invariant_feats = self.invariant(base.detach())\n",
    "            specific_feats = self.specific(base.detach())\n",
    "            combined = torch.cat([invariant_feats, specific_feats, base], dim=1)\n",
    "        else:\n",
    "            invariant_feats = self.invariant(base)\n",
    "            specific_feats = self.specific(base)\n",
    "            combined = torch.cat([invariant_feats, specific_feats], dim=1)\n",
    "        \n",
    "        if self.explicit_grl:\n",
    "            invariant_domain_pred = self.invariant_domain_classifier(GradientReversalFunction.apply(invariant_feats, 1.0))\n",
    "        else:\n",
    "            invariant_domain_pred = self.invariant_domain_classifier(invariant_feats)\n",
    "            \n",
    "        specific_domain_pred = self.specific_domain_classifier(specific_feats)\n",
    "        \n",
    "        scores = self.head(combined)      \n",
    "        \n",
    "        return {\n",
    "            'output': scores,\n",
    "            'invariant_domain': invariant_domain_pred,\n",
    "            'specific_domain': specific_domain_pred,\n",
    "            'invariant_feats': invariant_feats,\n",
    "            'specific_feats': specific_feats\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1450b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualBranchCNNNet(nn.Module):\n",
    "    def __init__(self, num_outputs=9, num_domains=6, backbone_type='3conv', branch_type='special', end_type='simple', batch_norm=False):\n",
    "        super().__init__()\n",
    "        self.backbone_type = backbone_type\n",
    "        self.branch_type = branch_type\n",
    "        self.end_type = end_type\n",
    "        \n",
    "        def BatchNorm(in_channels):\n",
    "            return nn.BatchNorm2d(in_channels) if batch_norm else nn.Identity()\n",
    "\n",
    "        #Input resized to 512,288\n",
    "\n",
    "        if self.backbone_type == 'none':\n",
    "            self.backbone = nn.Identity()\n",
    "            self.backbone_channels = 3\n",
    "\n",
    "        elif self.backbone_type == '2conv':\n",
    "            self.backbone = nn.Sequential(\n",
    "                nn.Conv2d(3, 32, 3, padding=1),\n",
    "                BatchNorm(32),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(32, 64, 3, padding=1),\n",
    "                BatchNorm(64),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2)\n",
    "            )\n",
    "            self.backbone_channels = 64\n",
    "\n",
    "        elif self.backbone_type == '3conv':\n",
    "            self.backbone = nn.Sequential(\n",
    "                nn.Conv2d(3, 32, 3, padding=1),\n",
    "                BatchNorm(32),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(32, 64, 3, padding=1),\n",
    "                BatchNorm(64),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(64, 128, 3, padding=1),\n",
    "                BatchNorm(128),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2)\n",
    "            )\n",
    "            self.backbone_channels = 128\n",
    "\n",
    "        elif self.backbone_type == 'pretrained':\n",
    "            self.backbone = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1).features\n",
    "            for param in self.backbone.parameters():\n",
    "                param.requires_grad = False\n",
    "            self.backbone_channels = 1280\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"backbone must be 'none' | '2conv' | '3conv' | 'pretrained'\")\n",
    "\n",
    "        if self.branch_type == 'linear':\n",
    "            self.social_branch = nn.Sequential(\n",
    "                nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(self.backbone_channels, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(512, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(256, 256)\n",
    "            )\n",
    "            self.room_branch = nn.Sequential(\n",
    "                nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(self.backbone_channels, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(512, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(256, 256)\n",
    "            )\n",
    "            self.branch_channels = 256\n",
    "\n",
    "        elif self.branch_type == 'simple':\n",
    "            self.room_branch = nn.Sequential(\n",
    "                nn.Conv2d(self.backbone_channels, 128, 3, padding=1),\n",
    "                BatchNorm(128),\n",
    "                nn.ReLU(),\n",
    "                nn.AdaptiveAvgPool2d((4,4)),\n",
    "                nn.Flatten()\n",
    "            )\n",
    "            self.social_branch = nn.Sequential(\n",
    "                nn.Conv2d(self.backbone_channels, 128, 3, dilation=2, padding=2),\n",
    "                BatchNorm(128),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(128, 128, 3, padding=1),\n",
    "                BatchNorm(128),\n",
    "                nn.ReLU(),\n",
    "                nn.AdaptiveAvgPool2d((4,4)),\n",
    "                nn.Flatten()\n",
    "            )\n",
    "            self.branch_channels = 128*4*4\n",
    "\n",
    "        elif self.branch_type == 'special':\n",
    "            self.room_branch = nn.Sequential(\n",
    "                CoordConv(self.backbone_channels, 128, 3),\n",
    "                BatchNorm(128),\n",
    "                nn.ReLU(),\n",
    "                nn.AdaptiveAvgPool2d((4,4)),\n",
    "                nn.Flatten()\n",
    "            )\n",
    "            self.social_branch = nn.Sequential(\n",
    "                nn.Conv2d(self.backbone_channels, 128, 3, dilation=2, padding=2),\n",
    "                BatchNorm(128),\n",
    "                nn.ReLU(),\n",
    "                SpatialMultiheadAttention(128, 4),\n",
    "                nn.Conv2d(128, 128, 3, padding=1),\n",
    "                BatchNorm(128),\n",
    "                nn.ReLU(),\n",
    "                nn.AdaptiveAvgPool2d((4,4)),\n",
    "                nn.Flatten()\n",
    "            )\n",
    "            self.branch_channels = 128*4*4\n",
    "\n",
    "        elif self.branch_type == 'adapted_adversarial':\n",
    "            self.social_branch = nn.Sequential(\n",
    "                nn.Conv2d(self.backbone_channels, 256, 5, padding=2),\n",
    "                BatchNorm(256),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(256, 512, 5, padding=2),\n",
    "                BatchNorm(512),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Flatten()\n",
    "            )\n",
    "            self.room_branch = nn.Sequential(\n",
    "                nn.Conv2d(self.backbone_channels, 256, 5, padding=2),\n",
    "                BatchNorm(256),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(256, 512, 5, padding=2),\n",
    "                BatchNorm(512),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Flatten()\n",
    "            )\n",
    "            # Calculate output dimensions based on backbone output            \n",
    "            adversarial_channels = {\n",
    "                'none': 512 * 128 * 72,       # 4,718,592\n",
    "                '2conv': 512 * 32 * 18,       # 294,912\n",
    "                '3conv': 512 * 16 * 9,        # 73,728\n",
    "                'pretrained': 512 * 4 * 2     # 4,096\n",
    "            }\n",
    "            self.branch_channels = adversarial_channels[self.backbone_type]\n",
    "\n",
    "        elif self.branch_type == 'adversarial':\n",
    "            self.social_branch = nn.Sequential(\n",
    "                nn.Conv2d(self.backbone_channels, 96, 5, padding=2),\n",
    "                BatchNorm(96),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(96, 144, 3, padding=1),\n",
    "                BatchNorm(144),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(144, 256, 5, padding=2),\n",
    "                BatchNorm(256),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Flatten()\n",
    "            )\n",
    "            self.room_branch = nn.Sequential(\n",
    "                nn.Conv2d(self.backbone_channels, 96, 5, padding=2),\n",
    "                BatchNorm(96),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(96, 144, 3, padding=1),\n",
    "                BatchNorm(144),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(144, 256, 5, padding=2),\n",
    "                BatchNorm(256),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Flatten()\n",
    "            )\n",
    "            # Calculate output dimensions based on backbone output\n",
    "            adversarial_channels = {\n",
    "                'none': 256 * 64 * 36,        # 589,824\n",
    "                '2conv': 256 * 16 * 9,        # 36,864 \n",
    "                '3conv': 256 * 8 * 4,         # 8,192\n",
    "                'pretrained': 256 * 2 * 1     # 512\n",
    "            }\n",
    "            self.branch_channels = adversarial_channels[self.backbone_type]\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"branch must be 'linear' | 'simple' | 'special' | 'adversarial' | 'adapted_adversarial'\")\n",
    "\n",
    "        if self.end_type == 'simple':\n",
    "            self.room_domain_cls = nn.Linear(self.branch_channels, num_domains)\n",
    "            self.social_domain_cls = nn.Linear(self.branch_channels, 1)\n",
    "            self.head = nn.Sequential(\n",
    "                nn.Linear(self.branch_channels*2, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(256, num_outputs)\n",
    "            )\n",
    "        elif self.end_type == 'adversarial':\n",
    "            self.room_domain_cls = nn.Sequential(\n",
    "                nn.Linear(self.branch_channels, 1024),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(1024, 1024),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(1024, num_domains)\n",
    "            )\n",
    "            self.social_domain_cls = nn.Sequential(\n",
    "                nn.Linear(self.branch_channels, 1024),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(1024, 1024),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(1024, 1)\n",
    "            )\n",
    "            self.head = nn.Sequential(\n",
    "                nn.Linear(self.branch_channels*2, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(512, num_outputs)\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"end must be 'simple' | 'adversarial'\")\n",
    "\n",
    "    def forward(self, x, alpha=1.0):\n",
    "        x = self.backbone(x)\n",
    "        room_feat = self.room_branch(x)\n",
    "        social_feat = self.social_branch(x)\n",
    "        scores = self.head(torch.cat([room_feat, social_feat], 1))\n",
    "        room_domain_cls = self.room_domain_cls(room_feat)\n",
    "        social_domain_cls = self.social_domain_cls(GradientReversalFunction.apply(social_feat, alpha))\n",
    "        \n",
    "        # return {\n",
    "        #     'output': scores,\n",
    "        #     'room_domain_cls': room_domain_cls,\n",
    "        #     'social_domain_cls': social_domain_cls\n",
    "        # }\n",
    "        return {\n",
    "                'output': scores,\n",
    "                'invariant_domain': social_domain_cls,\n",
    "                'specific_domain': room_domain_cls,\n",
    "                'invariant_feats': social_feat,\n",
    "                'specific_feats': room_feat\n",
    "            }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519205fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoordConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels + 2, \n",
    "                             out_channels, \n",
    "                             kernel_size, \n",
    "                             padding=kernel_size//2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch, _, h, w = x.shape\n",
    "        \n",
    "        # Create coordinate grids (range [-1, 1])\n",
    "        x_coord = torch.linspace(-1, 1, w).repeat(h, 1)\n",
    "        y_coord = torch.linspace(-1, 1, h).repeat(w, 1).t()\n",
    "        coords = torch.stack([x_coord, y_coord], dim=0)\n",
    "        coords = coords.unsqueeze(0).repeat(batch, 1, 1, 1).to(x.device)\n",
    "        x = torch.cat([x, coords], dim=1)\n",
    "        \n",
    "        return self.conv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419135e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialMultiheadAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool2d((8, 8))\n",
    "        self.mha = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        x_small = self.pool(x)\n",
    "        # Reshape to sequence format\n",
    "        x_flat = x_small.flatten(2).permute(0, 2, 1)\n",
    "        attn_output, _ = self.mha(x_flat, x_flat, x_flat)\n",
    "        # Reshape back to spatial format\n",
    "        attn_reshaped = attn_output.permute(0, 2, 1).view(B, C, 8, 8)\n",
    "        return F.interpolate(attn_reshaped, size=(H, W), mode='bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81aab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the CNN model\n",
    "# import torch\n",
    "# from itertools import product\n",
    "\n",
    "# # Test parameters\n",
    "# backbone_types = ['none', '2conv', '3conv', 'pretrained'][1:]\n",
    "# branch_types = ['linear', 'simple', 'special', 'adversarial', 'adapted_adversarial']\n",
    "# end_types = ['simple', 'adversarial']\n",
    "# batch_size = 32\n",
    "# input_size = (512, 288)  # (width, height)\n",
    "\n",
    "\n",
    "\n",
    "# # Dummy input\n",
    "# dummy_input = torch.randn(batch_size, 3, input_size[1], input_size[0])  # (B,C,H,W)\n",
    "\n",
    "# for backbone, branch, end in product(backbone_types, branch_types, end_types):\n",
    "    \n",
    "#     try:\n",
    "#         print(f\"\\nTesting: {backbone} + {branch} + {end}\")\n",
    "#         model = DualBranchCNNNet(\n",
    "#             backbone_type=backbone,\n",
    "#             branch_type=branch,\n",
    "#             end_type=end,\n",
    "#             batch_norm=True\n",
    "#         )\n",
    "        \n",
    "#         # Forward pass\n",
    "#         # print(f\"Input shapes: {dummy_input.shape}\")\n",
    "#         # bb = model.backbone(dummy_input)\n",
    "#         # print(f\"Backbone output shapes: {bb.shape}\")\n",
    "#         # room_feat = model.room_branch(bb)\n",
    "#         # print(f\"Room branch output shapes: {room_feat.shape}\")\n",
    "#         # social_feat = model.social_branch(bb)\n",
    "#         # print(f\"Social branch output shapes: {social_feat.shape}\")\n",
    "#         # outputs = model.head(torch.cat([room_feat, social_feat], 1))\n",
    "#         # print(f\"Head output shapes: {outputs.shape}\")\n",
    "#         output = model(dummy_input)\n",
    "\n",
    "#         # print(output['invariant_domain'].shape)\n",
    "#         # print(output['invariant_domain'].squeeze().shape)\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"❌ Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5849e928",
   "metadata": {},
   "source": [
    "## ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79536968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def extract_data_subset(df, robot_name='Pepper'):\n",
    "    # Modify the saving section at the end\n",
    "    # Create the required directory structure\n",
    "    project_root = Path.cwd().parent  # Goes up from experiments/ to project/\n",
    "    data_dir = project_root / \"data\"\n",
    "    images_dir = data_dir / \"images\"\n",
    "\n",
    "    images_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Filter for Pepper first\n",
    "    pepper_df = df[df['robot'] == robot_name].copy()\n",
    "    pepper_df = pepper_df.reset_index(drop=True)\n",
    "\n",
    "    # Copy images and update paths\n",
    "    def copy_and_update_path(row):\n",
    "        src_path = Path(row['image_path'])\n",
    "        dst_path = images_dir / src_path.name\n",
    "        \n",
    "        if not dst_path.exists():\n",
    "            shutil.copy2(src_path, dst_path)\n",
    "        \n",
    "        return str(dst_path.relative_to(project_root))\n",
    "\n",
    "    pepper_df['image_path'] = pepper_df.apply(copy_and_update_path, axis=1)\n",
    "\n",
    "    # Save the filtered dataframe\n",
    "    pepper_df.to_pickle(data_dir / \"pepper_data.pkl\")\n",
    "    return pepper_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965dd01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../data/pepper_data.pkl\")\n",
    "df['image_path'] = '../' + df['image_path']\n",
    "\n",
    "# Create domain-specific dataloaders\n",
    "domains = df['domain'].unique()\n",
    "domain_dataloaders = {}\n",
    "for domain in domains:\n",
    "    domain_df = df[df['domain'] == domain]\n",
    "    #domain_df = domain_df.sample(frac=0.5, random_state=42)\n",
    "    loaders = create_dataloaders(domain_df, batch_sizes=(32, 64, 64), resize_img_to=(512, 288))  #LGR had 128,128 MobileNetv2 had 224, 224\n",
    "    domain_dataloaders[domain] = loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f961279",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b80d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b327ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For LGRBaseline\n",
    "def baseline_batch(model, batch, device, **kwargs):\n",
    "    inputs, labels, _ = batch\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    outputs = model(inputs)['output']\n",
    "    loss = kwargs['mse_criterion'](outputs, labels)\n",
    "    metrics = {}\n",
    "    return loss, metrics\n",
    "\n",
    "# For DualBranchNet\n",
    "def dualbranch_batch(model, batch, device, detach_base, binary, full_replay, **kwargs):\n",
    "    inputs, labels, domain_labels = batch\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    domain_to_idx = kwargs['domain_to_idx']\n",
    "    domain_labels = torch.tensor([domain_to_idx[d] for d in domain_labels], device=device)\n",
    "    mse_criterion = kwargs['mse_criterion']\n",
    "    ce_criterion = kwargs['ce_criterion']\n",
    "    cos_criterion = kwargs['cos_criterion']\n",
    "    if binary:\n",
    "        bce_criterion = kwargs['bce_criterion']\n",
    "\n",
    "    # Split batch\n",
    "    current_domain = kwargs['current_domain']\n",
    "    current_binary_labels = (domain_labels == domain_to_idx[current_domain]).float()\n",
    "    current_mask = (domain_labels == domain_to_idx[current_domain])\n",
    "\n",
    "    if full_replay:\n",
    "        current_mask = torch.ones_like(current_mask, dtype=torch.bool)\n",
    "\n",
    "    replay_mask = ~current_mask\n",
    "\n",
    "    # 1. Current samples: update all parameters\n",
    "    if current_mask.any():\n",
    "        inputs_current = inputs[current_mask]\n",
    "        labels_current = labels[current_mask]\n",
    "        domain_labels_current = domain_labels[current_mask]\n",
    "\n",
    "        outputs_current = model(inputs_current)\n",
    "        inv_feats = outputs_current['invariant_feats']\n",
    "        spec_feats = outputs_current['specific_feats']\n",
    "\n",
    "        task_loss = mse_criterion(outputs_current['output'], labels_current)\n",
    "        if binary:\n",
    "            inv_domain_loss = bce_criterion(outputs_current['invariant_domain'].squeeze(), current_binary_labels[current_mask])\n",
    "        else:\n",
    "            inv_domain_loss = ce_criterion(outputs_current['invariant_domain'], domain_labels_current)\n",
    "        spec_domain_loss = ce_criterion(outputs_current['specific_domain'], domain_labels_current)\n",
    "        similarity_loss = cos_criterion(inv_feats, spec_feats)\n",
    "        \n",
    "        total_loss = (task_loss +\n",
    "                      0.5 * inv_domain_loss +\n",
    "                      0.2 * spec_domain_loss)\n",
    "                    # + 0.1 * similarity_loss)\n",
    "\n",
    "        total_loss.backward(retain_graph= not full_replay)\n",
    "        \n",
    "        if binary:\n",
    "            # Threshold at 0 (sigmoid(0) = 0.5)\n",
    "            preds = (outputs_current['invariant_domain'].squeeze() > 0).float()\n",
    "            inv_acc = (preds == current_binary_labels[current_mask]).float().mean().item()\n",
    "        else:\n",
    "            inv_acc = (outputs_current['invariant_domain'].argmax(1) == domain_labels_current).float().mean().item()\n",
    "        spec_acc = (outputs_current['specific_domain'].argmax(1) == domain_labels_current).float().mean().item()\n",
    "    else:\n",
    "        total_loss = torch.tensor(0.0, device=device)\n",
    "        inv_acc = 0.0\n",
    "        spec_acc = 0.0\n",
    "        task_loss = torch.tensor(0.0, device=device)\n",
    "        inv_domain_loss = torch.tensor(0.0, device=device)\n",
    "        spec_domain_loss = torch.tensor(0.0, device=device)\n",
    "        similarity_loss = torch.tensor(0.0, device=device)\n",
    "\n",
    "    # 2. Replay samples: update only specific branch + head\n",
    "    if replay_mask.any():\n",
    "        inputs_replay = inputs[replay_mask]\n",
    "        labels_replay = labels[replay_mask]\n",
    "        domain_labels_replay = domain_labels[replay_mask]\n",
    "\n",
    "        #no_grad, unlike requires_grad=False, detaches all elements from the gradient computation graph\n",
    "        with torch.no_grad():\n",
    "            base_replay = model.backbone(inputs_replay)\n",
    "            base_replay = model.pool(base_replay).flatten(1)\n",
    "            inv_feats_replay = model.invariant(base_replay)\n",
    "\n",
    "        specific_feats = model.specific(base_replay)\n",
    "        spec_domain_pred = model.specific_domain_classifier(specific_feats)\n",
    "        \n",
    "        if detach_base:\n",
    "            combined = torch.cat([inv_feats_replay, specific_feats, base_replay], dim=1)\n",
    "        else:\n",
    "            combined = torch.cat([inv_feats_replay, specific_feats], dim=1)  \n",
    "        \n",
    "        scores = model.head(combined)\n",
    "        \n",
    "        task_loss_replay = mse_criterion(scores, labels_replay)\n",
    "        spec_domain_loss_replay = ce_criterion(spec_domain_pred, domain_labels_replay)\n",
    "        total_loss_replay = task_loss_replay + 0.2 * spec_domain_loss_replay\n",
    "        \n",
    "        total_loss_replay.backward()\n",
    "    \n",
    "    metrics = {\n",
    "        'task_loss': task_loss.item(),\n",
    "        'inv_domain': inv_domain_loss.item(),\n",
    "        'spec_domain': spec_domain_loss.item(),\n",
    "        'similarity': similarity_loss.item(),\n",
    "        'inv_acc': inv_acc,\n",
    "        'spec_acc': spec_acc,\n",
    "        'replay_count': replay_mask.sum().item(),\n",
    "        'current_count': current_mask.sum().item()\n",
    "    }\n",
    "    return total_loss, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6df3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, _ in dataloader:\n",
    "\n",
    "            inputs = inputs.to(device, dtype=torch.float32)\n",
    "            labels = labels.to(device, dtype=torch.float32)\n",
    "            outputs = model(inputs)['output']\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            total_samples += inputs.size(0)\n",
    "    return total_loss / total_samples\n",
    "\n",
    "def cross_domain_validation(model, domain_dataloaders, criterion, device):\n",
    "    results = {}\n",
    "    for domain, loaders in domain_dataloaders.items():\n",
    "        val_loader = loaders['val']\n",
    "        val_loss = evaluate_model(model, val_loader, criterion, device)\n",
    "        results[domain] = val_loss\n",
    "    return results\n",
    "\n",
    "def average_metrics(metrics_list):\n",
    "    # metrics_list: list of dicts, each dict contains metrics for a batch\n",
    "    if not metrics_list:\n",
    "        return {}\n",
    "    keys = metrics_list[0].keys()\n",
    "    avg_metrics = {}\n",
    "    for k in keys:\n",
    "        avg_metrics[k] = float(np.mean([m[k] for m in metrics_list if k in m]))\n",
    "    return avg_metrics\n",
    "\n",
    "def collect_tsne_features(model, loader, device):\n",
    "    model.eval()\n",
    "    all_inv, all_spec, all_domains = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for domain, loaders in domain_dataloaders.items():\n",
    "            loader = loaders['val']\n",
    "            for x, _, d in loader:\n",
    "                x = x.to(device)\n",
    "                out = model(x)\n",
    "                all_inv.append(out['invariant_feats'].cpu())\n",
    "                all_spec.append(out['specific_feats'].cpu())\n",
    "                all_domains += list(d)\n",
    "    inv_feats = torch.cat(all_inv, dim=0).numpy()\n",
    "    spec_feats = torch.cat(all_spec, dim=0).numpy()\n",
    "    return inv_feats, spec_feats, all_domains\n",
    "\n",
    "def collect_gradients(model):\n",
    "    grad_norms = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.grad is not None and not name.startswith(\"backbone\"):\n",
    "            module = name.split('.')[0]\n",
    "            norm = param.grad.norm(2).item()\n",
    "            if module not in grad_norms:\n",
    "                grad_norms[module] = []\n",
    "            grad_norms[module].append(norm)\n",
    "    # Take mean per module\n",
    "    grad_norms = {k: float(np.mean(v)) for k, v in grad_norms.items()}\n",
    "    return grad_norms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcbbc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "def unified_train_loop(\n",
    "    model, domains, domain_dataloaders, buffer, optimizer, writer, device,\n",
    "    batch_fn, batch_kwargs, num_epochs=5, exp_name=\"exp\", gradient_clipping=False, detach_base=False, binary=False, full_replay=False\n",
    "):\n",
    "    global_step = 0\n",
    "    history = {\n",
    "        'train_epoch_loss': [],\n",
    "        'val_epoch_loss': [],\n",
    "        'train_epoch_metrics': [],\n",
    "        'cross_domain_val': [],\n",
    "        'grad_norms': [],\n",
    "    }\n",
    "    for domain_idx, current_domain in enumerate(domains):\n",
    "        print(buffer.get_domain_distribution())\n",
    "        train_loader = buffer.get_loader_with_replay(current_domain, domain_dataloaders[current_domain]['train'])\n",
    "        \n",
    "        for epoch in trange(num_epochs, desc=f\"Domain {current_domain} Epochs\"):\n",
    "            model.train()\n",
    "            epoch_loss = 0.0\n",
    "            samples = 0\n",
    "            batch_metrics_list = []\n",
    "            \n",
    "            # for batch_idx, batch in enumerate(train_loader):\n",
    "            for batch_idx, batch in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} Batches\", leave=False)):\n",
    "                optimizer.zero_grad()\n",
    "                loss, metrics = batch_fn(model, batch, device, detach_base, binary, full_replay, **{**batch_kwargs, 'current_domain': current_domain})\n",
    "                if gradient_clipping:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "                batch_size = batch[0].size(0)\n",
    "                epoch_loss += loss.item() * batch_size\n",
    "                samples += batch_size\n",
    "                global_step += 1\n",
    "                batch_metrics_list.append(metrics)\n",
    "                # TensorBoard logging (every 10 batches)\n",
    "                if writer and batch_idx % 10 == 0:\n",
    "                    writer.add_scalar(f'{exp_name}/train_loss', loss.item(), global_step)\n",
    "                    for k, v in metrics.items():\n",
    "                        writer.add_scalar(f'{exp_name}/train_{k}', v, global_step)\n",
    "            avg_epoch_loss = epoch_loss / samples\n",
    "            writer.add_scalar(f'{exp_name}/train_epoch_loss', avg_epoch_loss, global_step)\n",
    "            history['train_epoch_loss'].append(avg_epoch_loss)\n",
    "            # Average batch metrics for this epoch\n",
    "            avg_metrics = average_metrics(batch_metrics_list)\n",
    "            history['train_epoch_metrics'].append(avg_metrics)\n",
    "\n",
    "            # Collect gradients\n",
    "            grad_norms = collect_gradients(model)\n",
    "            history['grad_norms'].append(grad_norms)\n",
    "\n",
    "            # Validation on current domain\n",
    "            val_loss = evaluate_model(model, domain_dataloaders[current_domain]['val'], batch_kwargs['mse_criterion'], device)\n",
    "            writer.add_scalar(f'{exp_name}/val_epoch_loss', val_loss, global_step)\n",
    "            history['val_epoch_loss'].append(val_loss)\n",
    "\n",
    "            # Collect data for t-SNE domain separation graphs\n",
    "            inv_feats, spec_feats, domain_labels = collect_tsne_features(model, domain_dataloaders, device)\n",
    "            tsne_data = {\n",
    "                'inv_feats': inv_feats,\n",
    "                'spec_feats': spec_feats,\n",
    "                'domain_labels': domain_labels\n",
    "            }\n",
    "\n",
    "            # Cross-domain validation (after each domain)\n",
    "            if epoch == num_epochs-1:\n",
    "                cross_val = cross_domain_validation(model, domain_dataloaders, batch_kwargs['mse_criterion'], device)\n",
    "                history['cross_domain_val'].append(cross_val)\n",
    "\n",
    "            # Save model and metrics\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'history': history,\n",
    "                'tsne' : tsne_data,\n",
    "            }, f\"../checkpoints/{exp_name}_domain{current_domain}_epoch{epoch}_step{global_step}.pt\")\n",
    "            with open(f\"../checkpoints/{exp_name}_history.pkl\", \"wb\") as f:\n",
    "                pickle.dump(history, f)\n",
    "            \n",
    "        buffer.update_buffer(current_domain, domain_dataloaders[current_domain]['train'].dataset)\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973cdbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "domains = df['domain'].unique()\n",
    "domain_to_idx = {d: i for i, d in enumerate(domains)}\n",
    "\n",
    "# # For baseline model\n",
    "# baseline_model = LGRBaseline().to(device)\n",
    "# optimizer = torch.optim.Adam(baseline_model.parameters(), lr=1e-3)\n",
    "# buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "# exp_name = f\"baselinemodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "# writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "# baseline_kwargs = {'mse_criterion': nn.MSELoss()}\n",
    "# unified_train_loop(\n",
    "#     model=baseline_model,\n",
    "#     domains=domains,\n",
    "#     domain_dataloaders=domain_dataloaders,\n",
    "#     buffer=buffer,\n",
    "#     optimizer=optimizer,\n",
    "#     writer=writer,\n",
    "#     device=device,\n",
    "#     batch_fn=baseline_batch,\n",
    "#     batch_kwargs=baseline_kwargs,\n",
    "#     num_epochs=10,\n",
    "#     exp_name=exp_name\n",
    "# )\n",
    "\n",
    "# For DualBranchNet\n",
    "dual_model = DualBranchNet(num_domains=len(domains)).to(device)\n",
    "optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "\n",
    "def cos_criterion(a, b):\n",
    "    return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "    # return (nn.CosineSimilarity()(a, b) ** 2).mean()\n",
    "\n",
    "exp_name = f\"nores_dualbranchmodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "dualbranch_kwargs = {\n",
    "    'mse_criterion': nn.MSELoss(),\n",
    "    'ce_criterion': nn.CrossEntropyLoss(),\n",
    "    'cos_criterion': cos_criterion,\n",
    "    'domain_to_idx': domain_to_idx\n",
    "}\n",
    "unified_train_loop(\n",
    "    model=dual_model,\n",
    "    domains=domains,\n",
    "    domain_dataloaders=domain_dataloaders,\n",
    "    buffer=buffer,\n",
    "    optimizer=optimizer,\n",
    "    writer=writer,\n",
    "    device=device,\n",
    "    batch_fn=dualbranch_batch,\n",
    "    batch_kwargs=dualbranch_kwargs,\n",
    "    num_epochs=10,\n",
    "    exp_name=exp_name,\n",
    "    gradient_clipping=False\n",
    ")\n",
    "\n",
    "\n",
    "# For DualBranchNet\n",
    "dual_model = DualBranchNet(num_domains=len(domains)).to(device)\n",
    "optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "\n",
    "def cos_criterion(a, b):\n",
    "    return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "    # return (nn.CosineSimilarity()(a, b) ** 2).mean()\n",
    "\n",
    "exp_name = f\"nores_gradclip_dualbranchmodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "dualbranch_kwargs = {\n",
    "    'mse_criterion': nn.MSELoss(),\n",
    "    'ce_criterion': nn.CrossEntropyLoss(),\n",
    "    'cos_criterion': cos_criterion,\n",
    "    'domain_to_idx': domain_to_idx\n",
    "}\n",
    "unified_train_loop(\n",
    "    model=dual_model,\n",
    "    domains=domains,\n",
    "    domain_dataloaders=domain_dataloaders,\n",
    "    buffer=buffer,\n",
    "    optimizer=optimizer,\n",
    "    writer=writer,\n",
    "    device=device,\n",
    "    batch_fn=dualbranch_batch,\n",
    "    batch_kwargs=dualbranch_kwargs,\n",
    "    num_epochs=10,\n",
    "    exp_name=exp_name,\n",
    "    gradient_clipping=True\n",
    ")\n",
    "\n",
    "# For DualBranchNet\n",
    "dual_model = DualBranchNet(weights_init=True, weights_norm=True).to(device)\n",
    "optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "\n",
    "def cos_criterion(a, b):\n",
    "    return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "    # return (nn.CosineSimilarity()(a, b) ** 2).mean()\n",
    "\n",
    "exp_name = f\"nores_winit_wnorm_dualbranchmodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "dualbranch_kwargs = {\n",
    "    'mse_criterion': nn.MSELoss(),\n",
    "    'ce_criterion': nn.CrossEntropyLoss(),\n",
    "    'cos_criterion': cos_criterion,\n",
    "    'domain_to_idx': domain_to_idx\n",
    "}\n",
    "unified_train_loop(\n",
    "    model=dual_model,\n",
    "    domains=domains,\n",
    "    domain_dataloaders=domain_dataloaders,\n",
    "    buffer=buffer,\n",
    "    optimizer=optimizer,\n",
    "    writer=writer,\n",
    "    device=device,\n",
    "    batch_fn=dualbranch_batch,\n",
    "    batch_kwargs=dualbranch_kwargs,\n",
    "    num_epochs=10,\n",
    "    exp_name=exp_name,\n",
    "    gradient_clipping=False\n",
    ")\n",
    "\n",
    "# For DualBranchNet\n",
    "dual_model = DualBranchNet(weights_init=True, weights_norm=True).to(device)\n",
    "optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "\n",
    "def cos_criterion(a, b):\n",
    "    return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "    # return (nn.CosineSimilarity()(a, b) ** 2).mean()\n",
    "\n",
    "exp_name = f\"nores_gradclip_winit_wnorm_dualbranchmodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "dualbranch_kwargs = {\n",
    "    'mse_criterion': nn.MSELoss(),\n",
    "    'ce_criterion': nn.CrossEntropyLoss(),\n",
    "    'cos_criterion': cos_criterion,\n",
    "    'domain_to_idx': domain_to_idx\n",
    "}\n",
    "unified_train_loop(\n",
    "    model=dual_model,\n",
    "    domains=domains,\n",
    "    domain_dataloaders=domain_dataloaders,\n",
    "    buffer=buffer,\n",
    "    optimizer=optimizer,\n",
    "    writer=writer,\n",
    "    device=device,\n",
    "    batch_fn=dualbranch_batch,\n",
    "    batch_kwargs=dualbranch_kwargs,\n",
    "    num_epochs=10,\n",
    "    exp_name=exp_name,\n",
    "    gradient_clipping = True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9dfd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "domains = df['domain'].unique()\n",
    "domain_to_idx = {d: i for i, d in enumerate(domains)}\n",
    "\n",
    "dual_model = DualBranchNet_deep(weights_init=True, weights_norm=False).to(device)\n",
    "optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "\n",
    "def cos_criterion(a, b):\n",
    "    return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "    # return (nn.CosineSimilarity()(a, b) ** 2).mean()\n",
    "\n",
    "exp_name = f\"deep_dualbranchmodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "dualbranch_kwargs = {\n",
    "    'mse_criterion': nn.MSELoss(),\n",
    "    'ce_criterion': nn.CrossEntropyLoss(),\n",
    "    'cos_criterion': cos_criterion,\n",
    "    'domain_to_idx': domain_to_idx\n",
    "}\n",
    "unified_train_loop(\n",
    "    model=dual_model,\n",
    "    domains=domains,\n",
    "    domain_dataloaders=domain_dataloaders,\n",
    "    buffer=buffer,\n",
    "    optimizer=optimizer,\n",
    "    writer=writer,\n",
    "    device=device,\n",
    "    batch_fn=dualbranch_batch,\n",
    "    batch_kwargs=dualbranch_kwargs,\n",
    "    num_epochs=10,\n",
    "    exp_name=exp_name,\n",
    "    gradient_clipping=True\n",
    ")\n",
    "\n",
    "\n",
    "dual_model = DualBranchNet_deep(weights_init=True, weights_norm=True).to(device)\n",
    "optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "\n",
    "def cos_criterion(a, b):\n",
    "    return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "    # return (nn.CosineSimilarity()(a, b) ** 2).mean()\n",
    "\n",
    "exp_name = f\"deep_norm_dualbranchmodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "dualbranch_kwargs = {\n",
    "    'mse_criterion': nn.MSELoss(),\n",
    "    'ce_criterion': nn.CrossEntropyLoss(),\n",
    "    'cos_criterion': cos_criterion,\n",
    "    'domain_to_idx': domain_to_idx\n",
    "}\n",
    "unified_train_loop(\n",
    "    model=dual_model,\n",
    "    domains=domains,\n",
    "    domain_dataloaders=domain_dataloaders,\n",
    "    buffer=buffer,\n",
    "    optimizer=optimizer,\n",
    "    writer=writer,\n",
    "    device=device,\n",
    "    batch_fn=dualbranch_batch,\n",
    "    batch_kwargs=dualbranch_kwargs,\n",
    "    num_epochs=10,\n",
    "    exp_name=exp_name,\n",
    "    gradient_clipping=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86449b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "domains = df['domain'].unique()\n",
    "domain_to_idx = {d: i for i, d in enumerate(domains)}\n",
    "\n",
    "dual_model = DualBranchNet_deep(weights_init=False, weights_norm=False, layer_norm=False, detach_base=True).to(device)\n",
    "optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "\n",
    "def cos_criterion(a, b):\n",
    "    return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "    # return (nn.CosineSimilarity()(a, b) ** 2).mean()\n",
    "\n",
    "exp_name = f\"bbdetach_deep_dualbranchmodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "dualbranch_kwargs = {\n",
    "    'mse_criterion': nn.MSELoss(),\n",
    "    'ce_criterion': nn.CrossEntropyLoss(),\n",
    "    'cos_criterion': cos_criterion,\n",
    "    'domain_to_idx': domain_to_idx\n",
    "}\n",
    "unified_train_loop(\n",
    "    model=dual_model,\n",
    "    domains=domains,\n",
    "    domain_dataloaders=domain_dataloaders,\n",
    "    buffer=buffer,\n",
    "    optimizer=optimizer,\n",
    "    writer=writer,\n",
    "    device=device,\n",
    "    batch_fn=dualbranch_batch,\n",
    "    batch_kwargs=dualbranch_kwargs,\n",
    "    num_epochs=10,\n",
    "    exp_name=exp_name,\n",
    "    gradient_clipping=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41678456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "domains = df['domain'].unique()\n",
    "domain_to_idx = {d: i for i, d in enumerate(domains)}\n",
    "\n",
    "dual_model = DualBranchNet_deep(weights_init=True, weights_norm=False, layer_norm=False, detach_base=True).to(device)\n",
    "optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "\n",
    "def cos_criterion(a, b):\n",
    "    return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "    # return (nn.CosineSimilarity()(a, b) ** 2).mean()\n",
    "\n",
    "exp_name = f\"bdetach_batch16_dualbranchmodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "dualbranch_kwargs = {\n",
    "    'mse_criterion': nn.MSELoss(),\n",
    "    'ce_criterion': nn.CrossEntropyLoss(),\n",
    "    'cos_criterion': cos_criterion,\n",
    "    'domain_to_idx': domain_to_idx\n",
    "}\n",
    "\n",
    "domain_dataloaders = {}\n",
    "for domain in domains:\n",
    "    domain_df = df[df['domain'] == domain]\n",
    "    loaders = create_dataloaders(domain_df, batch_sizes=(16, 64, 64), resize_img_to=(128, 128))  #TODO should be (384, 216) to retain scale or (224, 224) for best performance on MobileNet\n",
    "    domain_dataloaders[domain] = loaders\n",
    "\n",
    "unified_train_loop(\n",
    "    model=dual_model,\n",
    "    domains=domains,\n",
    "    domain_dataloaders=domain_dataloaders,\n",
    "    buffer=buffer,\n",
    "    optimizer=optimizer,\n",
    "    writer=writer,\n",
    "    device=device,\n",
    "    batch_fn=dualbranch_batch,\n",
    "    batch_kwargs=dualbranch_kwargs,\n",
    "    num_epochs=10,\n",
    "    exp_name=exp_name,\n",
    "    gradient_clipping=True,\n",
    "    detach_base=True\n",
    ")\n",
    "\n",
    "domain_dataloaders = {}\n",
    "for domain in domains:\n",
    "    domain_df = df[df['domain'] == domain]\n",
    "    loaders = create_dataloaders(domain_df, batch_sizes=(32, 64, 64), resize_img_to=(128, 128))  #TODO should be (384, 216) to retain scale or (224, 224) for best performance on MobileNet\n",
    "    domain_dataloaders[domain] = loaders\n",
    "\n",
    "\n",
    "dual_model = DualBranchNet_deep(weights_init=False, weights_norm=False, layer_norm=False, detach_base=True, freeze_base='partial').to(device)\n",
    "optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "\n",
    "def cos_criterion(a, b):\n",
    "    return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "    # return (nn.CosineSimilarity()(a, b) ** 2).mean()\n",
    "\n",
    "exp_name = f\"bdetach_pfrozen_dualbranchmodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "dualbranch_kwargs = {\n",
    "    'mse_criterion': nn.MSELoss(),\n",
    "    'ce_criterion': nn.CrossEntropyLoss(),\n",
    "    'cos_criterion': cos_criterion,\n",
    "    'domain_to_idx': domain_to_idx\n",
    "}\n",
    "unified_train_loop(\n",
    "    model=dual_model,\n",
    "    domains=domains,\n",
    "    domain_dataloaders=domain_dataloaders,\n",
    "    buffer=buffer,\n",
    "    optimizer=optimizer,\n",
    "    writer=writer,\n",
    "    device=device,\n",
    "    batch_fn=dualbranch_batch,\n",
    "    batch_kwargs=dualbranch_kwargs,\n",
    "    num_epochs=10,\n",
    "    exp_name=exp_name,\n",
    "    gradient_clipping=True,\n",
    "    detach_base=True\n",
    ")\n",
    "\n",
    "dual_model = DualBranchNet_deep(weights_init=False, weights_norm=False, layer_norm=False, detach_base=False, freeze_base='full').to(device)\n",
    "optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "\n",
    "def cos_criterion(a, b):\n",
    "    return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "    # return (nn.CosineSimilarity()(a, b) ** 2).mean()\n",
    "\n",
    "exp_name = f\"ffrozen_dualbranchmodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "dualbranch_kwargs = {\n",
    "    'mse_criterion': nn.MSELoss(),\n",
    "    'ce_criterion': nn.CrossEntropyLoss(),\n",
    "    'cos_criterion': cos_criterion,\n",
    "    'domain_to_idx': domain_to_idx\n",
    "}\n",
    "unified_train_loop(\n",
    "    model=dual_model,\n",
    "    domains=domains,\n",
    "    domain_dataloaders=domain_dataloaders,\n",
    "    buffer=buffer,\n",
    "    optimizer=optimizer,\n",
    "    writer=writer,\n",
    "    device=device,\n",
    "    batch_fn=dualbranch_batch,\n",
    "    batch_kwargs=dualbranch_kwargs,\n",
    "    num_epochs=10,\n",
    "    exp_name=exp_name,\n",
    "    gradient_clipping=True,\n",
    "    detach_base=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f63e81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "domains = df['domain'].unique()\n",
    "domain_to_idx = {d: i for i, d in enumerate(domains)}\n",
    "\n",
    "dual_model = DualBranchNet_binary(weights_init=False, weights_norm=False, layer_norm=False, detach_base=False, freeze_base='full', explicit_grl=False).to(device)\n",
    "optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "\n",
    "def cos_criterion(a, b):\n",
    "    return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "    # return (nn.CosineSimilarity()(a, b) ** 2).mean()\n",
    "\n",
    "exp_name = f\"ffrozen_binary_dualbranchmodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "dualbranch_kwargs = {\n",
    "    'mse_criterion': nn.MSELoss(),\n",
    "    'ce_criterion': nn.CrossEntropyLoss(),\n",
    "    'cos_criterion': cos_criterion,\n",
    "    'domain_to_idx': domain_to_idx,\n",
    "    'bce_criterion': nn.BCEWithLogitsLoss()\n",
    "}\n",
    "unified_train_loop(\n",
    "    model=dual_model,\n",
    "    domains=domains,\n",
    "    domain_dataloaders=domain_dataloaders,\n",
    "    buffer=buffer,\n",
    "    optimizer=optimizer,\n",
    "    writer=writer,\n",
    "    device=device,\n",
    "    batch_fn=dualbranch_batch,\n",
    "    batch_kwargs=dualbranch_kwargs,\n",
    "    num_epochs=10,\n",
    "    exp_name=exp_name,\n",
    "    gradient_clipping=True,\n",
    "    detach_base=False,\n",
    "    binary = True,\n",
    "    full_replay = False\n",
    ")\n",
    "\n",
    "dual_model = DualBranchNet_binary(weights_init=False, weights_norm=False, layer_norm=False, detach_base=False, freeze_base='full', explicit_grl=False).to(device)\n",
    "optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "\n",
    "def cos_criterion(a, b):\n",
    "    return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "    # return (nn.CosineSimilarity()(a, b) ** 2).mean()\n",
    "\n",
    "exp_name = f\"ffrozen_binary_explicitgrl_dualbranchmodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "dualbranch_kwargs = {\n",
    "    'mse_criterion': nn.MSELoss(),\n",
    "    'ce_criterion': nn.CrossEntropyLoss(),\n",
    "    'cos_criterion': cos_criterion,\n",
    "    'domain_to_idx': domain_to_idx,\n",
    "    'bce_criterion': nn.BCEWithLogitsLoss()\n",
    "}\n",
    "unified_train_loop(\n",
    "    model=dual_model,\n",
    "    domains=domains,\n",
    "    domain_dataloaders=domain_dataloaders,\n",
    "    buffer=buffer,\n",
    "    optimizer=optimizer,\n",
    "    writer=writer,\n",
    "    device=device,\n",
    "    batch_fn=dualbranch_batch,\n",
    "    batch_kwargs=dualbranch_kwargs,\n",
    "    num_epochs=10,\n",
    "    exp_name=exp_name,\n",
    "    gradient_clipping=True,\n",
    "    detach_base=False,\n",
    "    binary=True,\n",
    "    full_replay = False\n",
    ")\n",
    "\n",
    "\n",
    "dual_model = DualBranchNet_binary(weights_init=True, weights_norm=False, layer_norm=False, detach_base=False, freeze_base='full', explicit_grl=True).to(device)\n",
    "optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "\n",
    "def cos_criterion(a, b):\n",
    "    return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "    # return (nn.CosineSimilarity()(a, b) ** 2).mean()\n",
    "\n",
    "exp_name = f\"freplay_ffrozen_binary_explicitgrl_dualbranchmodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "dualbranch_kwargs = {\n",
    "    'mse_criterion': nn.MSELoss(),\n",
    "    'ce_criterion': nn.CrossEntropyLoss(),\n",
    "    'cos_criterion': cos_criterion,\n",
    "    'domain_to_idx': domain_to_idx,\n",
    "    'bce_criterion': nn.BCEWithLogitsLoss()\n",
    "}\n",
    "unified_train_loop(\n",
    "    model=dual_model,\n",
    "    domains=domains,\n",
    "    domain_dataloaders=domain_dataloaders,\n",
    "    buffer=buffer,\n",
    "    optimizer=optimizer,\n",
    "    writer=writer,\n",
    "    device=device,\n",
    "    batch_fn=dualbranch_batch,\n",
    "    batch_kwargs=dualbranch_kwargs,\n",
    "    num_epochs=10,\n",
    "    exp_name=exp_name,\n",
    "    gradient_clipping=True,\n",
    "    detach_base=False,\n",
    "    binary=True,\n",
    "    full_replay = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a5e038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "domains = df['domain'].unique()\n",
    "domain_to_idx = {d: i for i, d in enumerate(domains)}\n",
    "\n",
    "backbone_types = ['shallow', 'deep', 'pretrained']\n",
    "branch_types = ['linear', 'simple', 'special', 'adversarial']\n",
    "end_types = ['simple', 'adversarial']\n",
    "\n",
    "testing_scenarios = {\n",
    "    # 'pretrained_backbone_cnn_branch': ('pretrained', 'simple', 'simple'), \n",
    "    'linear_branch': ('3conv', 'linear', 'simple'),\n",
    "    'cnn_branch': ('3conv', 'simple', 'simple'),\n",
    "    'adversarial': ('2conv', 'adversarial', 'adversarial'),\n",
    "    'cnn_specialised_branches': ('3conv', 'special', 'simple'),\n",
    "    'double_input': ('none','adversarial','adversarial')\n",
    "}\n",
    "\n",
    "for name, (backbone, branch, end) in testing_scenarios.items():\n",
    "    print(f\"\\nTesting: {backbone} + {branch} + {end}\")\n",
    "    dual_model = DualBranchCNNNet(backbone_type=backbone, branch_type=branch, end_type=end, batch_norm=True).to(device)\n",
    "    optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "    buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "\n",
    "    def cos_criterion(a, b):\n",
    "        return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "\n",
    "    exp_name = f\"CNN_{name}_dualbranchmodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "    dualbranch_kwargs = {\n",
    "        'mse_criterion': nn.MSELoss(),\n",
    "        'ce_criterion': nn.CrossEntropyLoss(),\n",
    "        'cos_criterion': cos_criterion,\n",
    "        'domain_to_idx': domain_to_idx,\n",
    "        'bce_criterion': nn.BCEWithLogitsLoss()\n",
    "    }\n",
    "    unified_train_loop(\n",
    "        model=dual_model,\n",
    "        domains=domains,\n",
    "        domain_dataloaders=domain_dataloaders,\n",
    "        buffer=buffer,\n",
    "        optimizer=optimizer,\n",
    "        writer=writer,\n",
    "        device=device,\n",
    "        batch_fn=dualbranch_batch,\n",
    "        batch_kwargs=dualbranch_kwargs,\n",
    "        num_epochs=10,\n",
    "        exp_name=exp_name,\n",
    "        gradient_clipping=False,\n",
    "        detach_base=False,\n",
    "        binary = True,\n",
    "        full_replay = True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b741d28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715d6864",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36adb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ideas for potential ways to combine networks\n",
    "residual = SpecificHead(base + invariant_feats)\n",
    "specific_feats = invariant_feats + residual\n",
    "\n",
    "gate = GateNet(base + invariant_feats)\n",
    "residual = SpecificHead(base)\n",
    "specific_feats = invariant_feats + gate * residual\n",
    "\n",
    "residual = Attention(invariant_feats, base)\n",
    "specific_feats = invariant_feats + residual\n",
    "\n",
    "gamma, beta = SpecificHead(base)\n",
    "specific_feats = gamma * invariant_feats + beta\n",
    "\n",
    "invariant_feats = InvariantHead(base)\n",
    "specific_feats = SpecificHead(base)\n",
    "cos_sim(invariant_feats, specific_feats) ~ 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e848bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# different cos 1-abs fixed residual - fixedred_fixedcos_dualbranchmodel_20250604_014811_history\n",
    "#fixed res but old cosine ^2 - fixedred_dualbranchmodel_20250604_002951_history\n",
    "#broken baseline - baselinemodel_20250603_200948_history\n",
    "# recent dualbranch - dualbranchmodel_20250603_135728_history\n",
    "#normalised and standarised residual - dualbranchmodel_20250609_013632_history\n",
    "#standarised residual - nonorm_dualbranchmodel_20250609_131820_history\n",
    "#no residual connection - nores_dualbranchmodel_20250609_232842_history\n",
    "#same plus gradient clipping - nores_gradclip_dualbranchmodel_20250610_010647_history\n",
    "#same, no graidient clipping, weights initialisation and normalisation - nores_winit_wnorm_dualbranchmodel_20250610_024401_history\n",
    "#same, gradient clipping and weights optimisation - nores_gradclip_winit_wnorm_dualbranchmodel_20250610_042118_history\n",
    "#deeper invariant network - deep_norm_dualbranchmodel_20250610_223350_history\n",
    "#same but with weiths normalisation - deep_dualbranchmodel_20250610_205411_history\n",
    "\n",
    "with open('../checkpoints/nonorm_dualbranchmodel_20250609_131820_history.pkl', 'rb') as f:\n",
    "    nonorm = pickle.load(f)\n",
    "\n",
    "with open('../checkpoints/nores_dualbranchmodel_20250609_232842_history.pkl', 'rb') as f:\n",
    "    lnorm_nores = pickle.load(f)\n",
    "\n",
    "with open('../checkpoints/nores_gradclip_dualbranchmodel_20250610_010647_history.pkl', 'rb') as f:\n",
    "    lnorm_nores_gradclip = pickle.load(f)\n",
    "\n",
    "with open('../checkpoints/dualbranchmodel_20250609_013632_history.pkl', 'rb') as f:\n",
    "    lnorm = pickle.load(f)\n",
    "\n",
    "with open('../checkpoints/nores_winit_wnorm_dualbranchmodel_20250610_024401_history.pkl', 'rb') as f:\n",
    "    wnorm_nores = pickle.load(f)\n",
    "\n",
    "with open('../checkpoints/nores_gradclip_winit_wnorm_dualbranchmodel_20250610_042118_history.pkl', 'rb') as f:\n",
    "    wnorm_nores_gradclip = pickle.load(f)\n",
    "\n",
    "with open('../checkpoints/deep_norm_dualbranchmodel_20250610_223350_history.pkl', 'rb') as f:\n",
    "    wnorm_gradclip_deep = pickle.load(f)\n",
    "\n",
    "with open('../checkpoints/deep_dualbranchmodel_20250610_205411_history.pkl', 'rb') as f:\n",
    "    lnorm_gradclip_deep = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21170cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detached base with skip connection to head + smaller 16 batch - bdetach_batch16_dualbranchmodel_20250615_025032_history\n",
    "# detached and partialy frozen base - bdetach_pfrozen_dualbranchmodel_20250615_040906_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd3fe2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../checkpoints/bbdetach_deep_dualbranchmodel_20250613_155613_history.pkl', 'rb') as f:\n",
    "    bbdetach_deep = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578a8a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_file = torch.load('../checkpoints/dualbranchmodel_20250609_013632_domainSmallOffice_epoch9_step1300.pt')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "domains = df['domain'].unique()\n",
    "model = DualBranchNet(num_domains=len(domains)).to(device)\n",
    "model.load_state_dict(pt_file['model_state_dict'])\n",
    "history = pt_file['history']\n",
    "tsne_data = pt_file['tsne']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8bf879",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf83e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ed5c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'bbdetach_deep':bbdetach_deep}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c761c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "'nonorm': nonorm,\n",
    "'lnorm': lnorm,\n",
    "'lnorm_nores': lnorm_nores,\n",
    "'lnorm_nores_gradclip': lnorm_nores_gradclip,\n",
    "'wnorm_nores': wnorm_nores,\n",
    "'wnorm_nores_gradclip': wnorm_nores_gradclip,\n",
    "'wnorm_gradclip_deep': wnorm_gradclip_deep,\n",
    "'lnorm_gradclip_deep': lnorm_gradclip_deep\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfbf212",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,m in models.items():\n",
    "    filtered = [x for i, x in enumerate(m['cross_domain_val']) if i in [9, 19, 29, 39, 49, 58]]\n",
    "    m['cross_domain_val'] = filtered\n",
    "\n",
    "for i,m in models.items():\n",
    "    print(len(m['cross_domain_val']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1598c390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for model_name, history in models.items():\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=list(range(len(history['train_epoch_loss']))),\n",
    "        y=history['train_epoch_loss'],\n",
    "        mode='lines',\n",
    "        name=f'{model_name} Train Loss'\n",
    "    ))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=list(range(len(history['val_epoch_loss']))),\n",
    "        y=history['val_epoch_loss'],\n",
    "        mode='lines',\n",
    "        name=f'{model_name} Val Loss'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Training and Validation Loss',\n",
    "    xaxis_title='Epoch',\n",
    "    yaxis_title='Loss',\n",
    "    template='plotly_white',\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f792f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt\n",
    "plt.figure(figsize=(20,7))\n",
    "for name, model in models.items():\n",
    "    plt.plot(model['train_epoch_loss'], label=f'{name} Train Loss')\n",
    "    plt.plot(model['val_epoch_loss'], label=f'{name} Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "# plt.ylim(-0.01, 1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1a1af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,m in models.items():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c42bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = []\n",
    "for name, model in models.items():\n",
    "    for i in range(6):\n",
    "        final += list(model['cross_domain_val'][i].values())\n",
    "max_loss = max(final)\n",
    "min_loss = min(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ded6c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt\n",
    "history = models['history']['cross_domain_val']\n",
    "\n",
    "# Extract domain names\n",
    "domains = list(history[0].keys())\n",
    "\n",
    "# Prepare accuracy per domain over time\n",
    "domain_scores = {domain: [] for domain in domains}\n",
    "for snapshot in history:\n",
    "    for domain in domains:\n",
    "        domain_scores[domain].append(snapshot[domain])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "for domain, scores in domain_scores.items():\n",
    "    plt.plot(domains[:len(scores)], scores, label=domain, marker='o')\n",
    "\n",
    "plt.xlabel(\"After training on domain X\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Domain-wise Accuracy Over Time\")\n",
    "# plt.ylim(min(-0.1, min_loss), max_loss)\n",
    "# plt.ylim(-0.05, 0.1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc92afd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Prepare data structure\n",
    "domain_data = {}\n",
    "for model_name, model_history in models.items():\n",
    "    history = model_history['cross_domain_val']\n",
    "    domains = list(history[0].keys())\n",
    "    domain_data[model_name] = {\n",
    "        domain: [snapshot[domain] for snapshot in history]\n",
    "        for domain in domains\n",
    "    }\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Color palette for domains\n",
    "domain_colors = {\n",
    "    domain: color for domain, color in zip(\n",
    "        domains, \n",
    "        ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', \"#05ffee\"]\n",
    "    )\n",
    "}\n",
    "\n",
    "# Add traces for each model and domain\n",
    "for model_idx, (model_name, domains) in enumerate(domain_data.items()):\n",
    "    for domain, scores in domains.items():\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=list(range(len(scores))),\n",
    "            y=scores,\n",
    "            mode='lines+markers',\n",
    "            name=domain,\n",
    "            line=dict(color=domain_colors[domain], width=2),\n",
    "            marker=dict(size=8, symbol=model_idx+1),  # Unique symbol per model\n",
    "            legendgroup=model_name,\n",
    "            legendgrouptitle_text=model_name,\n",
    "            visible=True if model_idx == 0 else 'legendonly'  # Show first model by default\n",
    "        ))\n",
    "\n",
    "# Create model selection buttons\n",
    "buttons = [\n",
    "    dict(\n",
    "        label=model_name,\n",
    "        method='update',\n",
    "        args=[\n",
    "            {'visible': [m == model_name for m in domain_data.keys() for _ in domains]},\n",
    "            {'title': f'Domain Losses: {model_name}'}\n",
    "        ]\n",
    "    ) for model_name in domain_data.keys()\n",
    "]\n",
    "\n",
    "# Layout configuration\n",
    "fig.update_layout(\n",
    "    title='Cross-Domain Validation Loss Comparison',\n",
    "    xaxis_title='Training Epoch',\n",
    "    yaxis_title='Loss',\n",
    "    legend=dict(\n",
    "        groupclick=\"toggleitem\",  # Allows group toggling while preserving individual control\n",
    "        itemsizing='constant'\n",
    "    ),\n",
    "    updatemenus=[{\n",
    "        'type': 'dropdown',\n",
    "        'direction': 'down',\n",
    "        'showactive': True,\n",
    "        'buttons': buttons,\n",
    "        'x': 1,\n",
    "        'xanchor': 'left',\n",
    "        'y': 1.1,\n",
    "        'yanchor': 'top'\n",
    "    }],\n",
    "    template='plotly_white',\n",
    "    # width=1200,\n",
    "    # height=700\n",
    "    # yaxis=dict(range=[min(-0.1, min_loss), max_loss]),\n",
    "    \n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072bf471",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt similarity\n",
    "h = models['deep_norm']\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot([m['similarity'] for m in h['train_epoch_metrics']])\n",
    "plt.xticks(np.arange(0, 60, step=1))\n",
    "plt.title('cosine similarity of two branches')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d878b1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt\n",
    "h = models['history']\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "for metric in ['inv_acc', 'spec_acc']:\n",
    "    plt.plot([m[metric] for m in h['train_epoch_metrics']], label=metric)\n",
    "plt.title('Branch accuracies and their similarity')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Metric Value')\n",
    "plt.xticks(np.arange(0, 60, step=1))\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce368a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for model_name, history in models.items():\n",
    "    for metric in ['inv_acc', 'spec_acc']:\n",
    "        y_values = [m[metric] for m in history['train_epoch_metrics']]\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=list(range(len(y_values))),\n",
    "            y=y_values,\n",
    "            mode='lines+markers',\n",
    "            name=f'{model_name} - {metric}'\n",
    "        ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Branch Accuracies',\n",
    "    xaxis_title='Epoch',\n",
    "    yaxis_title='Accuracy',\n",
    "    # xaxis=dict(tickmode='linear', tick0=0, dtick=1),\n",
    "    template='plotly_white',\n",
    "    # width=1000,\n",
    "    # height=400\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b02e6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt\n",
    "h = models['history']\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "for metric in ['inv_domain', 'spec_domain', 'task_loss']:\n",
    "    plt.plot([m[metric] for m in h['train_epoch_metrics']], label=metric)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Metric Value')\n",
    "plt.ylim(-0.01, 1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50704b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for model_name, history in models.items():\n",
    "    for metric in ['inv_domain', 'spec_domain', 'task_loss']:\n",
    "        y_values = [m[metric] for m in history['train_epoch_metrics']]\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=list(range(len(y_values))),\n",
    "            y=y_values,\n",
    "            mode='lines+markers',\n",
    "            name=f'{model_name} - {metric}'\n",
    "        ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='CE loss - inv_domain, spec_domain, and MSE task_loss',\n",
    "    xaxis_title='Epoch',\n",
    "    yaxis_title='Loss',\n",
    "    template='plotly_white',\n",
    "    # width=1000,\n",
    "    # height=400\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5599bcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = models['history']\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "for metric in ['replay_count', 'current_count']:\n",
    "    plt.plot([m[metric]/32*100 for m in h['train_epoch_metrics']], label=metric)\n",
    "plt.title('Type of samples in batch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('% of batch')\n",
    "# plt.axhline(32, color='r')\n",
    "# plt.xticks(np.arange(0, 60, step=1))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3728d54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = models['history']\n",
    "\n",
    "print(h['grad_norms'][0].keys())\n",
    "for grad_dict in h['grad_norms']:\n",
    "    for key in h['grad_norms'][0].keys():\n",
    "        grad_dict.setdefault(key, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d41c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "# for module in ['invariant', 'specific_residual', 'domain_classifier']:\n",
    "for module in h['grad_norms'][0].keys():\n",
    "    plt.plot([m[f'{module}'] for m in h['grad_norms']], label=module)\n",
    "plt.title('Gradient Norms by Module')\n",
    "# plt.ylim(-0.001, 1)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928c851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Collect all module names across all models\n",
    "all_modules = set()\n",
    "for model_name, history in models.items():\n",
    "    if 'grad_norms' in history and len(history['grad_norms']) > 0:\n",
    "        for grad_dict in history['grad_norms']:\n",
    "            all_modules.update(grad_dict.keys())\n",
    "all_modules = sorted(all_modules)\n",
    "all_modules = ['invariant', 'specific', 'head']\n",
    "\n",
    "\n",
    "# Add traces for each model and module, only show the first model by default\n",
    "trace_visibility = []\n",
    "for model_idx, (model_name, history) in enumerate(models.items()):\n",
    "    if 'grad_norms' not in history or len(history['grad_norms']) == 0:\n",
    "        continue\n",
    "    for grad_dict in history['grad_norms']:\n",
    "        for key in all_modules:\n",
    "            grad_dict.setdefault(key, 0)\n",
    "    for module in all_modules:\n",
    "        y_values = [m[module] for m in history['grad_norms']]\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=list(range(len(y_values))),\n",
    "            y=y_values,\n",
    "            mode='lines+markers',\n",
    "            name=f'{model_name} - {module}',\n",
    "            # visible=(model_idx == 0)\n",
    "        ))\n",
    "    trace_visibility.append((model_name, len(all_modules)))\n",
    "\n",
    "# Create dropdown buttons for each model\n",
    "buttons = []\n",
    "start_idx = 0\n",
    "for model_name, n_traces in trace_visibility:\n",
    "    visible = [False] * len(fig.data)\n",
    "    for i in range(start_idx, start_idx + n_traces):\n",
    "        visible[i] = True\n",
    "    buttons.append(dict(\n",
    "        label=model_name,\n",
    "        method='update',\n",
    "        args=[{'visible': visible}, {'title': f'Gradient Norms by Module - {model_name}'}]\n",
    "    ))\n",
    "    start_idx += n_traces\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'Gradient Norms by Module - {list(models.keys())[0]}',\n",
    "    xaxis_title='Epoch',\n",
    "    yaxis_title='Gradient Norm',\n",
    "    template='plotly_white',\n",
    "    # width=1000,\n",
    "    # height=400,\n",
    "    updatemenus=[{\n",
    "        'buttons': buttons,\n",
    "        'direction': 'down',\n",
    "        'showactive': True,\n",
    "        'x': 1,\n",
    "        'xanchor': 'left',\n",
    "        'y': 1.2,\n",
    "        'yanchor': 'top'\n",
    "    }]\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97530f3f",
   "metadata": {},
   "source": [
    "## --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbdbdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "\n",
    "# 1. Gather all checkpoint files\n",
    "checkpoint_files = glob.glob(\"../checkpoints/dualbranchmodel_20250609_013632_*.pt\")\n",
    "\n",
    "# 2. Parse out the step value and sort\n",
    "pattern = re.compile(r\"_step(\\d+)\\.pt\")\n",
    "files_with_steps = []\n",
    "for f in checkpoint_files:\n",
    "    match = pattern.search(f)\n",
    "    if match:\n",
    "        step = int(match.group(1))\n",
    "        files_with_steps.append((step, f))\n",
    "files_with_steps.sort()  # Sort by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb858a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e574052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Precompute t-SNE for all checkpoints (0-59)\n",
    "tsne_projections = []\n",
    "for idx, (step, ckpt_file) in enumerate(tqdm(files_with_steps, desc=\"Processing checkpoints\")):\n",
    "    ckpt = torch.load(ckpt_file, map_location='cpu')\n",
    "    data = ckpt['tsne']\n",
    "    inv_feats = np.array(data['inv_feats'])\n",
    "    spec_feats = np.array(data['spec_feats'])\n",
    "    domain_labels = np.array(data['domain_labels'])\n",
    "\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    inv_2d = tsne.fit_transform(inv_feats)\n",
    "    spec_2d = tsne.fit_transform(spec_feats)\n",
    "\n",
    "    tsne_projections.append({\n",
    "        'timeline_idx': idx,  # 0 to 59\n",
    "        'inv_2d': inv_2d,\n",
    "        'spec_2d': spec_2d,\n",
    "        'domains': domain_labels,\n",
    "        'filename': ckpt_file\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f2e395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# State variable for current index\n",
    "current_idx = 0\n",
    "\n",
    "# Output widget for the plot\n",
    "out = widgets.Output()\n",
    "\n",
    "# Buttons\n",
    "button_prev = widgets.Button(description=\"Previous\")\n",
    "button_next = widgets.Button(description=\"Next\")\n",
    "\n",
    "# Precompute limits\n",
    "all_x = np.concatenate([d['inv_2d'][:,0] for d in tsne_projections] + [d['spec_2d'][:,0] for d in tsne_projections])\n",
    "all_y = np.concatenate([d['inv_2d'][:,1] for d in tsne_projections] + [d['spec_2d'][:,1] for d in tsne_projections])\n",
    "x_min, x_max = all_x.min(), all_x.max()\n",
    "y_min, y_max = all_y.min(), all_y.max()\n",
    "\n",
    "def plot_epoch(timeline_idx):\n",
    "    data = tsne_projections[timeline_idx]\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6), constrained_layout=True)\n",
    "    domain_to_int = {name: i for i, name in enumerate(domains)}\n",
    "    domain_ints = np.array([domain_to_int[name] for name in data['domains']])\n",
    "    scatter1 = ax1.scatter(data['inv_2d'][:,0], data['inv_2d'][:,1], \n",
    "                          c=domain_ints, cmap='tab10', alpha=0.7, vmin=0, vmax=len(domains)-1)\n",
    "    ax1.set_title(f\"Invariant Features - Timeline {timeline_idx}\")\n",
    "    ax1.set_xlim(x_min, x_max)\n",
    "    ax1.set_ylim(y_min, y_max)\n",
    "    scatter2 = ax2.scatter(data['spec_2d'][:,0], data['spec_2d'][:,1],\n",
    "                          c=domain_ints, cmap='tab10', alpha=0.7, vmin=0, vmax=len(domains)-1)\n",
    "    ax2.set_title(f\"Specific Features - Timeline {timeline_idx}\")\n",
    "    ax2.set_xlim(x_min, x_max)\n",
    "    ax2.set_ylim(y_min, y_max)\n",
    "    cbar = fig.colorbar(scatter1, ax=[ax1, ax2], label='Domain', \n",
    "                        ticks=np.arange(len(domains)), boundaries=np.arange(len(domains)+1)-0.5)\n",
    "    cbar.set_ticks(np.arange(len(domains)))\n",
    "    cbar.set_ticklabels(domains)\n",
    "    plt.show()\n",
    "\n",
    "def on_prev_clicked(b):\n",
    "    global current_idx\n",
    "    if current_idx > 0:\n",
    "        current_idx -= 1\n",
    "        with out:\n",
    "            clear_output(wait=True)\n",
    "            plot_epoch(current_idx)\n",
    "\n",
    "def on_next_clicked(b):\n",
    "    global current_idx\n",
    "    if current_idx < len(tsne_projections) - 1:\n",
    "        current_idx += 1\n",
    "        with out:\n",
    "            clear_output(wait=True)\n",
    "            plot_epoch(current_idx)\n",
    "\n",
    "button_prev.on_click(on_prev_clicked)\n",
    "button_next.on_click(on_next_clicked)\n",
    "\n",
    "# Display everything\n",
    "display(widgets.HBox([button_prev, button_next]))\n",
    "display(out)\n",
    "\n",
    "# Initial plot\n",
    "with out:\n",
    "    plot_epoch(current_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6870cd48",
   "metadata": {},
   "source": [
    "## ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895de6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After model output\n",
    "outputs = model(inputs)  # Should be in [1,5]\n",
    "print(f\"Output range: {outputs.min().item()}–{outputs.max().item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2bbea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = LGRBaseline().to(device)\n",
    "test_optimizer = optim.Adam(test_model.parameters(), lr=1e-3)\n",
    "buffer = NaiveRehearsalBuffer(0)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "first_domain = domains[0]\n",
    "train_loader = domain_dataloaders[first_domain]['train']\n",
    "single_batch = next(iter(train_loader))\n",
    "inputs, labels, _ = single_batch\n",
    "inputs = inputs.to(device, dtype=torch.float32)\n",
    "labels = labels.to(device, dtype=torch.float32)\n",
    "\n",
    "# %%\n",
    "num_test_epochs = 400\n",
    "for epoch in range(num_test_epochs):\n",
    "    test_optimizer.zero_grad()\n",
    "\n",
    "    outputs = test_model(inputs)\n",
    "    loss = criterion(outputs['output'], labels)\n",
    "    \n",
    "    loss.backward()\n",
    "    test_optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0 or epoch == 0:\n",
    "        print(f\"Overfit Epoch {epoch+1}/{num_test_epochs} | Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40f72c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# device = torch.device('cpu')torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "domains = df['domain'].unique()\n",
    "\n",
    "writer = SummaryWriter(\"visualisation/\")\n",
    "model = DualBranchNet().to(device)\n",
    "first_domain = domains[0]\n",
    "train_loader = domain_dataloaders[first_domain]['train']\n",
    "single_batch = next(iter(train_loader))\n",
    "inputs, labels, _ = single_batch\n",
    "inputs = inputs.to(device, dtype=torch.float32)\n",
    "labels = labels.to(device, dtype=torch.float32)\n",
    "# writer.add_graph(model, inputs)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ba343e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_names = [\"image\"]\n",
    "output_names = [\"appropriateness scores\"]\n",
    "\n",
    "torch.onnx.export(model, inputs, \"model.onnx\", input_names=input_names, output_names=output_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ac7616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "y = model(inputs)\n",
    "make_dot(y.mean(), params=dict(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cadf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1. Get a single batch from any domain's train loader\n",
    "domain = domains[0]\n",
    "single_batch = next(iter(domain_dataloaders[domain]['train']))\n",
    "\n",
    "\n",
    "buffer = NaiveRehearsalBuffer(0)\n",
    "\n",
    "# 4. Overfit loop for both models\n",
    "def overfit_model(\n",
    "    model, optimizer, batch_fn, batch_kwargs, device, num_epochs=100, exp_name=\"overfit\"\n",
    "):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        loss, metrics = batch_fn(model, single_batch, device, **batch_kwargs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.6f}\")\n",
    "    return losses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cd1862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Baseline model overfit\n",
    "baseline_model = LGRBaseline().to(device)\n",
    "optimizer = torch.optim.Adam(baseline_model.parameters(), lr=1e-3)\n",
    "baseline_losses = overfit_model(\n",
    "    baseline_model, optimizer, baseline_batch, {'mse_criterion': torch.nn.MSELoss()}, device\n",
    ")\n",
    "\n",
    "# 6. DualBranch model overfit\n",
    "dual_model = DualBranchNet(num_domains=len(domains)).to(device)\n",
    "optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "dualbranch_kwargs = {\n",
    "    'mse_criterion': torch.nn.MSELoss(),\n",
    "    'ce_criterion': torch.nn.CrossEntropyLoss(),\n",
    "    'cos_criterion': lambda a, b: (torch.nn.CosineSimilarity()(a, b) ** 2).mean(),\n",
    "    'domain_to_idx': domain_to_idx,\n",
    "    'current_domain': domain\n",
    "}\n",
    "dualbranch_losses = overfit_model(\n",
    "    dual_model, optimizer, dualbranch_batch, dualbranch_kwargs, device\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaf299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Plot the loss curves (optional)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(baseline_losses, label='Baseline')\n",
    "plt.plot(dualbranch_losses, label='DualBranch')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Overfitting to a Single Batch')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfa9229",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "socialsense",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
