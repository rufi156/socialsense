{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d72ee38c",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2560ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import pickle\n",
    "import datetime\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# DATASET_DIR = (Path(\"..\") / \"..\" / \"datasets\").resolve()\n",
    "# DATASETS = [\"OFFICE-MANNERSDB\", \"MANNERSDBPlus\"]\n",
    "# LABEL_COLS = [\n",
    "#     \"Vaccum Cleaning\", \"Mopping the Floor\", \"Carry Warm Food\",\n",
    "#     \"Carry Cold Food\", \"Carry Drinks\", \"Carry Small Objects\",\n",
    "#     \"Carry Large Objects\", \"Cleaning\", \"Starting a conversation\"\n",
    "# ]\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from data_processing.data_processing import ImageLabelDataset,DualImageDataset,create_dataloaders,create_crossvalidation_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7254948",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../data/pepper_data.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43ca986",
   "metadata": {},
   "source": [
    "## CL Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b563a996",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c51f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import random\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Subset\n",
    "import torchvision.models.segmentation as segmentation\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052e9597",
   "metadata": {},
   "source": [
    "### ForgettingGatedSplitModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80b99f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import pickle\n",
    "import datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from ultralytics import YOLO\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from typing import Tuple, Optional\n",
    "from collections import deque\n",
    "\n",
    "sys.path.append('D:/projects/Depth-Anything-V2')\n",
    "from depth_anything_v2.dpt import DepthAnythingV2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e14a20a",
   "metadata": {},
   "source": [
    "#### backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51fcf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO11FeatureExtractor(nn.Module):\n",
    "    \"\"\"Extract features from YOLO11-seg backbone (layers 0-8)\"\"\"\n",
    "    def __init__(self, model_path='../models/yolo11n-seg.pt'):\n",
    "        super().__init__()\n",
    "        yolo = YOLO(model_path)\n",
    "\n",
    "        # Extract layers 0-8 as discussed (before SPPF to preserve spatial granularity)\n",
    "        self.backbone = nn.Sequential(*list(yolo.model.model[:9]))\n",
    "        del yolo\n",
    "        \n",
    "        # Freeze parameters\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)  # Output: [B, 256, H/32, W/32]\n",
    "\n",
    "class DepthAnythingFeatureExtractor(nn.Module):\n",
    "    def __init__(self, model_path='../models/depth_anything_v2_vits.pth'):\n",
    "        super().__init__()\n",
    "        model_configs = {\n",
    "            'vits': {'encoder': 'vits', 'features': 64, 'out_channels': [48, 96, 192, 384]},\n",
    "        }\n",
    "        model = DepthAnythingV2(**model_configs['vits'])\n",
    "        model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "        \n",
    "        self.backbone = model.pretrained\n",
    "        del model\n",
    "\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Patch embedding\n",
    "            x = self.backbone.patch_embed(x)\n",
    "            \n",
    "            # Pass through transformer blocks\n",
    "            for block in self.backbone.blocks:\n",
    "                x = block(x)\n",
    "            \n",
    "            # Apply final norm\n",
    "            x = self.backbone.norm(x)\n",
    "            \n",
    "            # Remove CLS token and reshape to spatial format\n",
    "            if x.shape[1] > (H//14) * (W//14):\n",
    "                patch_tokens = x[:, 1:, :]  # Remove CLS token\n",
    "            else:\n",
    "                patch_tokens = x\n",
    "            \n",
    "            # Reshape to spatial format\n",
    "            patch_h, patch_w = H // 14, W // 14\n",
    "            spatial_features = patch_tokens.transpose(1, 2).reshape(B, 384, patch_h, patch_w)\n",
    "            \n",
    "            return spatial_features\n",
    "\n",
    "\n",
    "class DualBackboneFeatureExtractor(nn.Module):\n",
    "    \"\"\"Combines YOLO11 and DepthAnything feature extractors\"\"\"\n",
    "    def __init__(self, model_paths):\n",
    "        super().__init__()\n",
    "        # Individual feature extractors\n",
    "        self.yolo_extractor = YOLO11FeatureExtractor(model_paths['YOLO11n_seg'])\n",
    "        self.depth_extractor = DepthAnythingFeatureExtractor(model_paths['DepthAnythingV2_small'])\n",
    "        \n",
    "        # Feature projection layers (optional - can keep features as-is)\n",
    "        self.yolo_proj = nn.Conv2d(256, 256, 1)\n",
    "        self.depth_proj = nn.Conv2d(384, 384, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Extract features from both backbones\n",
    "        yolo_features = self.yolo_extractor(x[0])  # [B, 256, H/32, W/32]\n",
    "        depth_features = self.depth_extractor(x[1])  # [B, 384, H/14, W/14]\n",
    "        \n",
    "        # Apply projections\n",
    "        yolo_features = self.yolo_proj(yolo_features)\n",
    "        depth_features = self.depth_proj(depth_features)\n",
    "        \n",
    "        # Downsample the depthanything features to match yolo\n",
    "        depth_features = F.adaptive_avg_pool2d(depth_features, (7, 7)) #image size /32 224,224 > 7,7\n",
    "        \n",
    "        # Concatenate features\n",
    "        combined_features = torch.cat([yolo_features, depth_features], dim=1)  # [B, 640, H/14, W/14] \n",
    "        \n",
    "        return combined_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397757eb",
   "metadata": {},
   "source": [
    "#### model components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ee971a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatastrophicForgettingAdapter(nn.Module):\n",
    "    \"\"\"Standalone adapter that measures forgetting and gates spatial features\"\"\"\n",
    "    def __init__(self, num_channels=640, num_outputs=9):\n",
    "        super().__init__()\n",
    "        self.num_channels = num_channels\n",
    "        \n",
    "        # Forgetting measurement storage (per channel)\n",
    "        self.previous_adapter_state = None\n",
    "        self.current_forgetting_scores = None\n",
    "        \n",
    "        # Adapter that predicts main task (for forgetting measurement)\n",
    "        self.adapter = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),  # Global average pooling\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(num_channels, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_outputs)  # Predicts main task\n",
    "        )\n",
    "        \n",
    "        # Learnable gating network (operates on channel-wise forgetting scores)\n",
    "        self.gating = nn.Sequential(\n",
    "            nn.Linear(num_channels, num_channels // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_channels // 4, num_channels),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, backbone_features, use_gating=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            backbone_features: [B, 640, 36, 36] spatial features\n",
    "        Returns:\n",
    "            forgetting_features: [B, 640, 36, 36] features routed to forgetting branch\n",
    "            not_forgetting_features: [B, 640, 36, 36] features routed to stable branch\n",
    "            adapter_predictions: [B, 9] task predictions for forgetting measurement\n",
    "        \"\"\"\n",
    "        B, C, H, W = backbone_features.shape\n",
    "        \n",
    "        # Adapter makes predictions (for forgetting measurement)\n",
    "        adapter_predictions = self.adapter(backbone_features)\n",
    "        \n",
    "        if use_gating and self.current_forgetting_scores is not None:\n",
    "            # Apply channel-wise gating based on forgetting scores\n",
    "            forgetting_scores_batch = self.current_forgetting_scores.unsqueeze(0).expand(B, -1)  # [B, 640]\n",
    "            gating_mask = self.gating(forgetting_scores_batch)  # [B, 640]\n",
    "            \n",
    "            # Reshape for spatial broadcasting\n",
    "            gating_mask = gating_mask.unsqueeze(2).unsqueeze(3)  # [B, 640, 1, 1]\n",
    "            \n",
    "            # Route features channel-wise\n",
    "            forgetting_features = backbone_features * gating_mask\n",
    "            not_forgetting_features = backbone_features * (1 - gating_mask)\n",
    "        else:\n",
    "            # No gating - both branches get all features\n",
    "            forgetting_features = backbone_features\n",
    "            not_forgetting_features = backbone_features\n",
    "        \n",
    "        return forgetting_features, not_forgetting_features, adapter_predictions\n",
    "    \n",
    "    def store_adapter_state(self):\n",
    "        \"\"\"Store current adapter state for forgetting measurement\"\"\"\n",
    "        self.previous_adapter_state = {\n",
    "            name: param.clone().detach() \n",
    "            for name, param in self.adapter.named_parameters()\n",
    "        }\n",
    "    \n",
    "    def compute_forgetting_scores(self):\n",
    "        \"\"\"Compute channel-wise forgetting scores by comparing adapter states\"\"\"\n",
    "        # Get the device from model parameters\n",
    "        device = next(self.parameters()).device\n",
    "        \n",
    "        if self.previous_adapter_state is None:\n",
    "            # First domain - no forgetting to measure\n",
    "            self.current_forgetting_scores = torch.zeros(self.num_channels, device=device)\n",
    "            return\n",
    "        \n",
    "        # Compare adapter weights to measure which channels are most affected\n",
    "        forgetting_scores = []\n",
    "        \n",
    "        for name, current_param in self.adapter.named_parameters():\n",
    "            if name in self.previous_adapter_state:\n",
    "                previous_param = self.previous_adapter_state[name]\n",
    "                \n",
    "                if 'weight' in name and len(current_param.shape) == 2:\n",
    "                    # For first linear layer after pooling: [256, 640]\n",
    "                    if current_param.shape[1] == self.num_channels:\n",
    "                        # Compute change per input channel\n",
    "                        weight_change = torch.norm(current_param - previous_param, dim=0)\n",
    "                        forgetting_scores.append(weight_change)\n",
    "                        break  # Use only first layer that maps from channels\n",
    "        \n",
    "        # Use channel-wise forgetting scores\n",
    "        if forgetting_scores:\n",
    "            self.current_forgetting_scores = forgetting_scores[0].to(device)\n",
    "            \n",
    "            # Normalize to [0, 1]\n",
    "            if self.current_forgetting_scores.max() > 0:\n",
    "                self.current_forgetting_scores = (\n",
    "                    self.current_forgetting_scores / self.current_forgetting_scores.max()\n",
    "                )\n",
    "        else:\n",
    "            # Fallback if no forgetting scores computed\n",
    "            self.current_forgetting_scores = torch.zeros(self.num_channels, device=device)\n",
    "\n",
    "class ConvBranch(nn.Module):\n",
    "    \"\"\"Convolutional processing branch for spatial features\"\"\"\n",
    "    def __init__(self, input_channels=640, hidden_channels=256, output_channels=128):\n",
    "        super().__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            # First conv block\n",
    "            nn.Conv2d(input_channels, hidden_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(hidden_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(0.1),\n",
    "            \n",
    "            # Second conv block\n",
    "            nn.Conv2d(hidden_channels, hidden_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(hidden_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(0.1),\n",
    "            \n",
    "            # Output conv block\n",
    "            nn.Conv2d(hidden_channels, output_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(output_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Global pooling to get fixed-size output\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten()  # [B, output_channels]\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.conv_layers(x)\n",
    "    \n",
    "    \n",
    "class FeatureFusion(nn.Module):\n",
    "    \"\"\"Attention-based fusion of branch features\"\"\"\n",
    "    def __init__(self, feature_dim=256):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(feature_dim * 2, feature_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(feature_dim, 2),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, high_features, low_features):\n",
    "        # Concatenate features\n",
    "        combined = torch.cat([high_features, low_features], dim=1)  # [B, 512]\n",
    "        \n",
    "        # Compute attention weights\n",
    "        attention_weights = self.attention(combined)  # [B, 2]\n",
    "        \n",
    "        # Apply attention\n",
    "        weighted_high = high_features * attention_weights[:, 0:1]\n",
    "        weighted_low = low_features * attention_weights[:, 1:2]\n",
    "        \n",
    "        # Combine with residual connection\n",
    "        fused = weighted_high + weighted_low\n",
    "        \n",
    "        return fused\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c35dfb2",
   "metadata": {},
   "source": [
    "#### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbc671e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatastrophicForgettingDisentanglementModel(nn.Module):\n",
    "    \"\"\"Updated model with spatial features and convolutional branches\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 backbone_output_channels: int = 640,\n",
    "                 branch_hidden_channels: int = 256,\n",
    "                 branch_output_channels: int = 128,\n",
    "                 num_outputs: int = 9):\n",
    "        super().__init__()\n",
    "        \n",
    "        print(\"ðŸš€ Initializing Spatial Catastrophic Forgetting Model...\")\n",
    "        \n",
    "        # Dual backbone (frozen) - now outputs spatial features\n",
    "        model_paths={\n",
    "            'YOLO11n_seg': '../models/yolo11n-seg.pt', \n",
    "            'DepthAnythingV2_small': '../models/depth_anything_v2_vits.pth'\n",
    "            }\n",
    "        missing = [name for name, path in model_paths.items() if not os.path.exists(path)]\n",
    "        if missing:\n",
    "            raise FileNotFoundError(f\"Missing model files for: {', '.join(missing)}\")\n",
    "\n",
    "        self.backbone = DualBackboneFeatureExtractor(model_paths=model_paths)  # [B, 640, 36, 36]\n",
    "        \n",
    "        # Standalone forgetting adapter\n",
    "        self.forgetting_adapter = CatastrophicForgettingAdapter(\n",
    "            num_channels=backbone_output_channels,\n",
    "            num_outputs=num_outputs\n",
    "        )\n",
    "        \n",
    "        # Convolutional branches for spatial processing\n",
    "        self.branch_forgetting = ConvBranch(\n",
    "            backbone_output_channels, \n",
    "            branch_hidden_channels, \n",
    "            branch_output_channels\n",
    "        )\n",
    "        self.branch_not_forgetting = ConvBranch(\n",
    "            backbone_output_channels, \n",
    "            branch_hidden_channels, \n",
    "            branch_output_channels\n",
    "        )\n",
    "        \n",
    "        self.fusion = FeatureFusion(branch_output_channels)\n",
    "\n",
    "        # Final head combines branch outputs\n",
    "        self.head =  nn.Sequential(\n",
    "            nn.Linear(branch_output_channels, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(256, num_outputs)\n",
    "        )\n",
    "        \n",
    "        print(\"âœ… Spatial model initialized successfully!\")\n",
    "        \n",
    "    def forward(self, x, use_gating: bool = True):\n",
    "        # Extract spatial features from frozen backbone\n",
    "        backbone_features = self.backbone(x)  # [B, 640, 36, 36]\n",
    "        \n",
    "        # Process through forgetting adapter (gating + task prediction)\n",
    "        forgetting_features, not_forgetting_features, adapter_predictions = \\\n",
    "            self.forgetting_adapter(backbone_features, use_gating)\n",
    "        \n",
    "        # Process through convolutional branches\n",
    "        forgetting_output = self.branch_forgetting(forgetting_features)      # [B, 128]\n",
    "        not_forgetting_output = self.branch_not_forgetting(not_forgetting_features)  # [B, 128]\n",
    "        \n",
    "        # Combine branch outputs for final prediction\n",
    "        fused_features = self.fusion(forgetting_output, not_forgetting_output)\n",
    "        final_output = self.head(fused_features)\n",
    "        \n",
    "        return {\n",
    "            'output': final_output,\n",
    "            'adapter_output': adapter_predictions,\n",
    "            'backbone_features': backbone_features,\n",
    "            'forgetting_features': forgetting_features,\n",
    "            'not_forgetting_features': not_forgetting_features\n",
    "        }\n",
    "    \n",
    "    def store_adapter_state(self):\n",
    "        \"\"\"Delegate to forgetting adapter\"\"\"\n",
    "        self.forgetting_adapter.store_adapter_state()\n",
    "    \n",
    "    def compute_forgetting_scores(self):\n",
    "        \"\"\"Delegate to forgetting adapter\"\"\"\n",
    "        self.forgetting_adapter.compute_forgetting_scores()\n",
    "\n",
    "    @property\n",
    "    def current_forgetting_scores(self):\n",
    "        \"\"\"Access forgetting scores from adapter\"\"\"\n",
    "        return self.forgetting_adapter.current_forgetting_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785b41e1",
   "metadata": {},
   "source": [
    "#### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacf8a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Initialize your model\n",
    "# cf_model = CatastrophicForgettingDisentanglementModel(\n",
    "#     backbone_output_channels=640,\n",
    "#     branch_hidden_channels=256,\n",
    "#     branch_output_channels=128,\n",
    "#     num_outputs=9\n",
    "# ).to(device)\n",
    "\n",
    "# # Set model to evaluation mode (important for testing)\n",
    "# cf_model.eval()\n",
    "\n",
    "# # Create dummy input tensor matching your expected input size\n",
    "# # Your model expects: [batch_size, 3, height, width]\n",
    "# # Using 224x224 as we discussed for memory efficiency\n",
    "# batch_size = 2\n",
    "# dummy1 = torch.randn(batch_size, 3, 224, 224).to(device)\n",
    "# dummy2 = torch.randn(batch_size, 3, 224, 224).to(device)\n",
    "# dummy_input = (dummy1, dummy2)\n",
    "\n",
    "# print(f\"Input shape: {dummy_input[0].shape}\")\n",
    "\n",
    "# # Test forward pass without gating (first domain)\n",
    "# with torch.no_grad():\n",
    "#     outputs_no_gating = cf_model(dummy_input, use_gating=False)\n",
    "\n",
    "# print(\"âœ… Forward pass without gating successful!\")\n",
    "# print(f\"Output shape: {outputs_no_gating['output'].shape}\")\n",
    "# print(f\"Adapter output shape: {outputs_no_gating['adapter_output'].shape}\")\n",
    "# print(f\"Backbone features shape: {outputs_no_gating['backbone_features'].shape}\")\n",
    "\n",
    "# # Test forward pass with gating (after first domain)\n",
    "# # First, simulate having forgetting scores\n",
    "# cf_model.forgetting_adapter.current_forgetting_scores = torch.randn(640).to(device)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     outputs_with_gating = cf_model(dummy_input, use_gating=True)\n",
    "\n",
    "# print(\"âœ… Forward pass with gating successful!\")\n",
    "# print(f\"Forgetting features shape: {outputs_with_gating['forgetting_features'].shape}\")\n",
    "# print(f\"Not forgetting features shape: {outputs_with_gating['not_forgetting_features'].shape}\")\n",
    "\n",
    "# # Test forgetting measurement functions\n",
    "# cf_model.store_adapter_state()\n",
    "# print(\"âœ… Adapter state stored successfully!\")\n",
    "\n",
    "# cf_model.compute_forgetting_scores()\n",
    "# print(\"âœ… Forgetting scores computed successfully!\")\n",
    "# print(f\"Forgetting scores shape: {cf_model.current_forgetting_scores.shape}\")\n",
    "\n",
    "# outputs = cf_model(dummy_input, use_gating=True)\n",
    "# print(outputs['output'].device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b2d6c1",
   "metadata": {},
   "source": [
    "#### helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7277c284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_cf(model, dataloader, criterion, device):\n",
    "    \"\"\"Modified evaluation function for catastrophic forgetting model\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for yolo_images, depth_images, labels, _ in dataloader:\n",
    "            yolo_images = yolo_images.to(device, dtype=torch.float32)\n",
    "            depth_images = depth_images.to(device, dtype=torch.float32)\n",
    "            inputs = (yolo_images, depth_images)\n",
    "            labels = labels.to(device, dtype=torch.float32)\n",
    "            outputs = model(inputs, use_gating=True)  # Use gating during evaluation\n",
    "            loss = criterion(outputs['output'], labels)\n",
    "            total_loss += loss.item() * inputs[0].size(0)\n",
    "            total_samples += inputs[0].size(0)\n",
    "    return total_loss / total_samples\n",
    "\n",
    "def cross_domain_validation_cf(model, domain_dataloaders, criterion, device):\n",
    "    \"\"\"Modified cross-domain validation for catastrophic forgetting model\"\"\"\n",
    "    results = {}\n",
    "    for domain, loaders in domain_dataloaders.items():\n",
    "        val_loader = loaders['val']\n",
    "        val_loss = evaluate_model_cf(model, val_loader, criterion, device)\n",
    "        results[domain] = val_loss\n",
    "    return results\n",
    "\n",
    "def average_metrics(metrics_list):\n",
    "    if not metrics_list:\n",
    "        return {}\n",
    "    keys = metrics_list[0].keys()\n",
    "    avg_metrics = {}\n",
    "    for k in keys:\n",
    "        avg_metrics[k] = float(np.mean([m[k] for m in metrics_list if k in m]))\n",
    "    return avg_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa12b00",
   "metadata": {},
   "source": [
    "#### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd794edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gating_loss(forgetting_scores: torch.Tensor, \n",
    "                       gating_mask: torch.Tensor,\n",
    "                       lambda_balance: float = 1.0) -> torch.Tensor:\n",
    "    \"\"\"Compute loss for gating network\"\"\"\n",
    "    high_forgetting_features = forgetting_scores * gating_mask\n",
    "    low_forgetting_features = forgetting_scores * (1 - gating_mask)\n",
    "    \n",
    "    high_mean = high_forgetting_features.sum() / (gating_mask.sum() + 1e-8)\n",
    "    low_mean = low_forgetting_features.sum() / ((1 - gating_mask).sum() + 1e-8)\n",
    "    \n",
    "    split_loss = -(high_mean - low_mean)\n",
    "    balance_loss = torch.abs(gating_mask.mean() - 0.5)\n",
    "    \n",
    "    total_loss = split_loss + lambda_balance * balance_loss\n",
    "    return total_loss\n",
    "\n",
    "def catastrophic_forgetting_batch(model, batch, device, loss_params={'main': 1.0, 'adapter': 0.5, 'gating': 0.1}, **kwargs):\n",
    "    \"\"\"CORRECTED: Batch function with proper adapter access\"\"\"\n",
    "    yolo_images, depth_images, labels, domain_labels = batch\n",
    "    yolo_images = yolo_images.to(device)\n",
    "    depth_images = depth_images.to(device)\n",
    "    inputs = (yolo_images, depth_images)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    mse_criterion = kwargs['mse_criterion']\n",
    "    domain_idx = kwargs.get('domain_idx', 0)\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(inputs, use_gating=(domain_idx > 0))\n",
    "    \n",
    "    # Main task loss (from final head)\n",
    "    main_loss = mse_criterion(outputs['output'], labels)\n",
    "    \n",
    "    # Adapter loss (for monitoring forgetting)\n",
    "    adapter_loss = mse_criterion(outputs['adapter_output'], labels)\n",
    "    \n",
    "    # Main loss backpropagation\n",
    "    main_loss.backward(retain_graph=True) \n",
    "    \n",
    "    # CORRECTED: Gating loss with proper path access\n",
    "    gating_loss = torch.tensor(0.0, device=device)\n",
    "    if domain_idx > 0 and model.current_forgetting_scores is not None:\n",
    "        backbone_features = outputs['backbone_features']\n",
    "        batch_size = backbone_features.size(0)\n",
    "        forgetting_scores_batch = model.current_forgetting_scores.unsqueeze(0).expand(batch_size, -1).to(device)\n",
    "        \n",
    "        # FIXED: Use correct path to gating network\n",
    "        gating_mask = model.forgetting_adapter.gating(forgetting_scores_batch)\n",
    "        \n",
    "        gating_loss = compute_gating_loss(\n",
    "            model.current_forgetting_scores.to(device), \n",
    "            gating_mask.mean(dim=0)\n",
    "        )\n",
    "    \n",
    "    metrics = {\n",
    "        'main_loss': main_loss.item(),\n",
    "        'adapter_loss': adapter_loss.item(),\n",
    "        'gating_loss': gating_loss.item()\n",
    "    }\n",
    "    \n",
    "    return main_loss, gating_loss, metrics\n",
    "\n",
    "def catastrophic_forgetting_train_loop(\n",
    "    model, domains, domain_dataloaders, buffer, optimizer, gating_optimizer, device,\n",
    "    batch_fn, batch_kwargs, loss_params, num_epochs=5, exp_name=\"cf_exp\", \n",
    "    gradient_clipping=False, restart={}\n",
    "):\n",
    "    \"\"\"CORRECTED: Training loop with proper forgetting measurement\"\"\"\n",
    "    start_domain_idx = 0\n",
    "    global_step = 0\n",
    "    history = {\n",
    "        'train_epoch_loss': [],\n",
    "        'val_epoch_loss': [],\n",
    "        'train_epoch_metrics': [],\n",
    "        'cross_domain_val': [],\n",
    "        'grad_norms': [],\n",
    "        'forgetting_scores_history': [],\n",
    "        'gating_losses': []\n",
    "    }\n",
    "    \n",
    "    if restart:\n",
    "        global_step = restart['global_step']\n",
    "        history = restart['history']\n",
    "        start_domain_idx = np.where(domains == restart['domain'])[0][0]\n",
    "        for domain_idx, current_domain in enumerate(domains[:start_domain_idx]):\n",
    "            buffer.update_buffer(current_domain, domain_dataloaders[current_domain]['train'].dataset) \n",
    "        print(f\"Restarting from domain {restart['domain']} index {start_domain_idx}\")\n",
    "        print(f\"Buffer: {buffer.get_domain_distribution()}\")         \n",
    "\n",
    "    for domain_idx, current_domain in enumerate(tqdm(domains[start_domain_idx:], desc=f\"Total training\"), start=start_domain_idx):\n",
    "        print(f\"\\n=== Training on Domain {domain_idx}: {current_domain} ===\")\n",
    "        \n",
    "        # Store adapter state before training (for forgetting measurement)\n",
    "        if domain_idx > 0:\n",
    "            model.store_adapter_state()\n",
    "        \n",
    "        train_loader = buffer.get_loader_with_replay(current_domain, domain_dataloaders[current_domain]['train'])\n",
    "        \n",
    "        for epoch in trange(num_epochs, desc=f\"Current domain {current_domain}\"):\n",
    "            model.train()\n",
    "            epoch_loss = 0.0\n",
    "            samples = 0\n",
    "            batch_metrics_list = []\n",
    "            \n",
    "            for batch_idx, batch in enumerate(tqdm(train_loader, desc=f\"Current epoch {epoch}\", leave=False)):\n",
    "                # Main model training\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                batch_kwargs_with_domain = {**batch_kwargs, 'current_domain': current_domain, 'domain_idx': domain_idx}\n",
    "                \n",
    "                main_loss, gating_loss, metrics = batch_fn(model, batch, device, loss_params, **batch_kwargs_with_domain)\n",
    "                \n",
    "                if gradient_clipping:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Gating training (in same batch, separate optimizer)\n",
    "                if domain_idx > 0 and gating_loss.item() > 0:\n",
    "                    gating_optimizer.zero_grad()\n",
    "                    gating_loss.backward()\n",
    "                    gating_optimizer.step()\n",
    "                \n",
    "                batch_size = batch[0].size(0)\n",
    "                epoch_loss += main_loss.item() * batch_size\n",
    "                samples += batch_size\n",
    "                global_step += 1\n",
    "                batch_metrics_list.append(metrics)\n",
    "                \n",
    "            avg_epoch_loss = epoch_loss / samples\n",
    "            history['train_epoch_loss'].append(avg_epoch_loss)\n",
    "            \n",
    "            avg_metrics = average_metrics(batch_metrics_list)\n",
    "            history['train_epoch_metrics'].append(avg_metrics)\n",
    "            \n",
    "            grad_norms = collect_gradients(model)\n",
    "            history['grad_norms'].append(grad_norms)\n",
    "            \n",
    "            # Validation on current domain\n",
    "            val_loss = evaluate_model_cf(model, domain_dataloaders[current_domain]['val'], batch_kwargs['mse_criterion'], device)\n",
    "            history['val_epoch_loss'].append(val_loss)\n",
    "            \n",
    "            # Cross-domain validation (after each domain)\n",
    "            if epoch == num_epochs-1:\n",
    "                cross_val = cross_domain_validation_cf(model, domain_dataloaders, batch_kwargs['mse_criterion'], device)\n",
    "                history['cross_domain_val'].append(cross_val)\n",
    "\n",
    "                # Compute forgetting scores after training on domain (for next domain)\n",
    "                model.compute_forgetting_scores()\n",
    "                history['forgetting_scores_history'].append(\n",
    "                    model.current_forgetting_scores.clone() if model.current_forgetting_scores is not None else None\n",
    "                )\n",
    "                if model.current_forgetting_scores is not None:\n",
    "                    print(f\"Forgetting scores computed. Mean: {model.current_forgetting_scores.mean():.4f}, \"\n",
    "                        f\"Std: {model.current_forgetting_scores.std():.4f}\")\n",
    "                \n",
    "\n",
    "                # Save checkpoint\n",
    "                torch.save({\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'gating_optimizer_state_dict': gating_optimizer.state_dict(),\n",
    "                    'history': history,\n",
    "                    'forgetting_scores': model.current_forgetting_scores,\n",
    "                }, f\"../checkpoints/{exp_name}_domain{current_domain}_epoch{epoch}_step{global_step}.pt\")\n",
    "            \n",
    "            with open(f\"../checkpoints/{exp_name}_history.pkl\", \"wb\") as f:\n",
    "                pickle.dump(history, f)\n",
    "        \n",
    "        buffer.update_buffer(current_domain, domain_dataloaders[current_domain]['train'].dataset)\n",
    "        print(f\"Domain {domain_idx} completed. Buffer: {buffer.get_domain_distribution()}\")\n",
    "    \n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82339e1",
   "metadata": {},
   "source": [
    "### Explicit Heuristic Split Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb05cd5",
   "metadata": {},
   "source": [
    "#### ZoeDepth - HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a4bad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from pathlib import Path\n",
    "# import torch\n",
    "# import numpy as np\n",
    "# from transformers import AutoImageProcessor, ZoeDepthForDepthEstimation\n",
    "# from PIL import Image\n",
    "# from tqdm import tqdm\n",
    "# from torchvision import transforms\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# output_dir = Path('../data/depth')\n",
    "# output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# image_processor = AutoImageProcessor.from_pretrained(\"Intel/zoedepth-nyu-kitti\", use_fast=True)\n",
    "# model = ZoeDepthForDepthEstimation.from_pretrained(\"Intel/zoedepth-nyu-kitti\").to(device).eval()\n",
    "\n",
    "# # Prepare image paths list\n",
    "# image_paths = df['image_path'].tolist()\n",
    "\n",
    "# batch_size = 10  # or whatever batch size you want\n",
    "# for batch_idx in tqdm(range(0, len(image_paths), batch_size)):\n",
    "#     batch_paths = image_paths[batch_idx:batch_idx + batch_size]\n",
    "    \n",
    "#     # Load images as PIL Images (no manual transform)\n",
    "#     batch_images = [Image.open(img_path).convert(\"RGB\") for img_path in batch_paths]\n",
    "    \n",
    "#     # Preprocess with ZoeDepth image processor\n",
    "#     inputs = image_processor(images=batch_images, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**inputs)\n",
    "    \n",
    "#     # Post-process depth maps to original sizes\n",
    "#     source_sizes = [(img.height, img.width) for img in batch_images]\n",
    "#     post_processed = image_processor.post_process_depth_estimation(\n",
    "#         outputs,\n",
    "#         source_sizes=source_sizes\n",
    "#     )\n",
    "    \n",
    "#     for i, depth_dict in enumerate(post_processed):\n",
    "#         # Get raw depth map\n",
    "#         depth_array = depth_dict[\"predicted_depth\"].cpu().numpy()\n",
    "#         img_stem = Path(batch_paths[i]).stem\n",
    "#         np.save(output_dir / f\"{img_stem}.npy\", depth_array)\n",
    "#         # Save visualization PNG\n",
    "#         depth_norm = (depth_array - depth_array.min()) / (depth_array.max() - depth_array.min())\n",
    "#         depth_img = Image.fromarray((depth_norm * 255).astype(np.uint8))\n",
    "#         depth_img.save(output_dir / f\"{img_stem}_depth.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd6ee64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "498f923f",
   "metadata": {},
   "source": [
    "#### segmentation generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7b5847",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autodistill_grounded_sam import GroundedSAM\n",
    "from autodistill.detection import CaptionOntology\n",
    "from autodistill.utils import plot\n",
    "import cv2\n",
    "import pickle\n",
    "import bz2\n",
    "\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858438c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an ontology to map class names to our GroundedSAM prompt\n",
    "# the ontology dictionary has the format {caption: class}\n",
    "# where caption is the prompt sent to the base model, and class is the label that will\n",
    "# be saved for that caption in the generated annotations\n",
    "# then, load the model\n",
    "base_model = GroundedSAM(\n",
    "    ontology=CaptionOntology(\n",
    "        {\n",
    "            \"human . child . person\": \"human\",\n",
    "            \"robot\": \"robot\",\n",
    "            \"dog\": \"dog\"\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "# human : human, anima: animal, robot:robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34d558c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # run inference on a single image\n",
    "# results = base_model.predict(df['image_path'].iloc[0])\n",
    "\n",
    "# plot(\n",
    "#     image=cv2.imread(df['image_path'].iloc[0]),\n",
    "#     classes=base_model.ontology.classes(),\n",
    "#     detections=results\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acf4520",
   "metadata": {},
   "outputs": [],
   "source": [
    "with bz2.BZ2File('autodistill_dataset_home.pbz2', 'rb') as f:\n",
    "    dataset_home = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69a5b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with bz2.BZ2File('autodistill_dataset.pbz2', 'wb') as f:\n",
    "#     pickle.dump(dataset, f, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3684de9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f434e371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_home = base_model.label(\"../../socialsense/data/images/home\", extension=\".png\")\n",
    "# with bz2.BZ2File('autodistill_dataset_home.pbz2', 'wb') as f:\n",
    "#     pickle.dump(dataset_home, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebd0427",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"autodistill_temp_dataset.pkl\", \"rb\") as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7ee43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "import os\n",
    "import supervision as sv\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "# Define a color palette for your classes\n",
    "# Use RGBA for masks (with transparency), RGB for boxes (solid)\n",
    "class_colors = {\n",
    "    0: (255, 0, 0, 100),    # Red for class 0 (human)\n",
    "    1: (0, 255, 0, 100),    # Green for class 1 (robot)\n",
    "    2: (0, 0, 255, 100),    # Blue for class 2 (animal)\n",
    "    3: (122, 122, 0, 100),\n",
    "    # Add more if you have more classes\n",
    "}\n",
    "\n",
    "def visualize_and_save_pil_colored(dataset, confidence_threshold=0.3, output_dir=\"../data/temp_masks_coloured\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for idx, (path, image, detections) in enumerate(tqdm(dataset)):\n",
    "        # Convert BGR to RGB for PIL (if your image is BGR)\n",
    "        rgb_image = image[:, :, ::-1]\n",
    "        pil_img = Image.fromarray(rgb_image)\n",
    "        draw = ImageDraw.Draw(pil_img, \"RGBA\")\n",
    "        \n",
    "        # Filter detections by confidence\n",
    "        keep_indices = [i for i, conf in enumerate(detections.confidence) if conf >= confidence_threshold]\n",
    "        if not keep_indices:\n",
    "            print(f\"No detections above threshold for image {path}\")\n",
    "            continue\n",
    "\n",
    "        filtered_boxes = detections.xyxy[keep_indices]\n",
    "        filtered_masks = detections.mask[keep_indices]\n",
    "        filtered_confidences = detections.confidence[keep_indices]\n",
    "        filtered_class_ids = detections.class_id[keep_indices]\n",
    "        \n",
    "        # Overlay masks with transparency and class colors\n",
    "        for i, (mask, conf) in enumerate(zip(filtered_masks, filtered_confidences)):\n",
    "            class_id = filtered_class_ids[i] if filtered_class_ids is not None else 0\n",
    "            color = class_colors.get(class_id, (255, 255, 255, 100))  # Default white if class unknown\n",
    "            # Create a colored mask with alpha\n",
    "            mask_img = Image.fromarray((mask * 255).astype(np.uint8), mode=\"L\")\n",
    "            colored_mask = Image.new(\"RGBA\", pil_img.size, color)\n",
    "            # Composite the colored mask onto the image with transparency\n",
    "            pil_img = Image.alpha_composite(pil_img.convert(\"RGBA\"), Image.composite(colored_mask, Image.new(\"RGBA\", pil_img.size), mask_img))\n",
    "        \n",
    "        draw = ImageDraw.Draw(pil_img)\n",
    "        \n",
    "        # Draw bounding boxes and confidence with class colors\n",
    "        for i, (box, conf) in enumerate(zip(filtered_boxes, filtered_confidences)):\n",
    "            class_id = filtered_class_ids[i] if filtered_class_ids is not None else 0\n",
    "            color = class_colors[class_id][:3]  # Use RGB for boxes (no alpha)\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            draw.rectangle([x1, y1, x2, y2], outline=color, width=2)\n",
    "            draw.text((x1, y1 - 10*class_id), f\"{class_id}: {conf:.2f}\", fill=color)\n",
    "        \n",
    "        # Save the image as PNG\n",
    "        filename = os.path.basename(path)\n",
    "        save_path = os.path.join(output_dir, os.path.splitext(filename)[0] + \".png\")\n",
    "        pil_img.convert(\"RGB\").save(save_path)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a90879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from supervision import Detections\n",
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"Calculate Intersection over Union for two boxes [x1,y1,x2,y2]\"\"\"\n",
    "    x1_inter = max(box1[0], box2[0])\n",
    "    y1_inter = max(box1[1], box2[1])\n",
    "    x2_inter = min(box1[2], box2[2])\n",
    "    y2_inter = min(box1[3], box2[3])\n",
    "    inter_area = max(0, x2_inter - x1_inter) * max(0, y2_inter - y1_inter)\n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    return inter_area / (box1_area + box2_area - inter_area + 1e-6)\n",
    "\n",
    "def remove_duplicates_any_class(detections: Detections, iou_threshold=0.9) -> Detections:\n",
    "    \"\"\"\n",
    "    Remove duplicate detections using IoU and confidence, regardless of class.\n",
    "    \n",
    "    Args:\n",
    "        detections: supervision.Detections object\n",
    "        iou_threshold: IoU threshold for considering duplicates\n",
    "        \n",
    "    Returns:\n",
    "        Filtered Detections object\n",
    "    \"\"\"\n",
    "    # Extract components from Detections\n",
    "    xyxy = detections.xyxy\n",
    "    confidence = detections.confidence\n",
    "    class_id = detections.class_id\n",
    "    mask = detections.mask\n",
    "\n",
    "    # Convert to list of dicts for processing\n",
    "    detections_list = [\n",
    "        {\n",
    "            'box': xyxy[i],\n",
    "            'mask': mask[i] if mask is not None else None,\n",
    "            'confidence': confidence[i],\n",
    "            'class_id': class_id[i]\n",
    "        }\n",
    "        for i in range(len(xyxy))\n",
    "    ]\n",
    "\n",
    "    # Sort by confidence (highest first)\n",
    "    detections_list.sort(key=lambda x: x['confidence'], reverse=True)\n",
    "    \n",
    "    # Filter duplicates (do NOT check class_id)\n",
    "    keep = []\n",
    "    while detections_list:\n",
    "        current = detections_list.pop(0)\n",
    "        keep.append(current)\n",
    "        detections_list = [\n",
    "            d for d in detections_list\n",
    "            if calculate_iou(current['box'], d['box']) <= iou_threshold\n",
    "        ]\n",
    "\n",
    "    # Reconstruct Detections object\n",
    "    return Detections(\n",
    "        xyxy=np.array([d['box'] for d in keep]),\n",
    "        confidence=np.array([d['confidence'] for d in keep]),\n",
    "        class_id=np.array([d['class_id'] for d in keep]),\n",
    "        mask=np.array([d['mask'] for d in keep]) if mask is not None else None\n",
    "    )\n",
    "\n",
    "# Usage example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1425ffef",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dataset = []\n",
    "for path, image, detections in dataset_746:\n",
    "    filtered_detections = remove_duplicates_any_class(detections, iou_threshold=0.95)\n",
    "    filtered_dataset.append((path, image, filtered_detections))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5746dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_and_save_pil_colored(dataset, confidence_threshold=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3abbcf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c2ab6bf",
   "metadata": {},
   "source": [
    "#### depth mean std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b30629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def calculate_mean_std_for_npy(folder_path):\n",
    "    total_sum = 0\n",
    "    total_sum_sq = 0\n",
    "    total_count = 0\n",
    "\n",
    "    # List all .npy files\n",
    "    files = [f for f in os.listdir(folder_path) if f.endswith('.npy')]\n",
    "    \n",
    "    # Wrap the loop with tqdm for progress bar\n",
    "    for filename in tqdm(files):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        img = np.load(file_path).astype(np.float64)\n",
    "        total_sum += img.sum()\n",
    "        total_sum_sq += (img ** 2).sum()\n",
    "        total_count += img.size\n",
    "\n",
    "    mean = total_sum / total_count if total_count > 0 else None\n",
    "    variance = (total_sum_sq / total_count) - (mean ** 2) if total_count > 0 else None\n",
    "    std = np.sqrt(variance) if variance is not None else None\n",
    "    return mean, std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d709f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_mean_std_for_npy('../data/depth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64981e76",
   "metadata": {},
   "source": [
    "#### mask fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5417fa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def process_segmentation_data(detections_dataset, output_dir, imagenet_mean=[0.485, 0.456, 0.406], confidence_threshold=0.3):\n",
    "    \"\"\"\n",
    "    Process supervision Detections dataset to create social and environment images\n",
    "    \n",
    "    Args:\n",
    "        detections_dataset: List of tuples (image_path, Detection_object, ...)\n",
    "        output_dir: Base directory to save processed images\n",
    "        imagenet_mean: RGB mean values for filling masked areas\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create output directories\n",
    "    social_dir = Path(output_dir) / \"social\"\n",
    "    env_dir = Path(output_dir) / \"environment\"\n",
    "    social_dir.mkdir(parents=True, exist_ok=True)\n",
    "    env_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for item in tqdm(detections_dataset):\n",
    "        image_path = item[0]\n",
    "        detections = item[2]\n",
    "        \n",
    "        # Load original image\n",
    "        original_image = cv2.imread(str(image_path))\n",
    "        original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "        height, width = original_image.shape[:2]\n",
    "        \n",
    "        # Get filename for saving\n",
    "        filename = Path(image_path).name\n",
    "\n",
    "        keep_indices = [i for i, conf in enumerate(detections.confidence) if conf >= confidence_threshold]\n",
    "        filtered_masks = detections.mask[keep_indices]\n",
    "        \n",
    "        # Combine all masks into one\n",
    "        combined_mask = combine_masks(filtered_masks, height, width)\n",
    "        \n",
    "        # Create social image (only people and robot visible)\n",
    "        social_image = apply_mask_with_mean(\n",
    "            original_image, combined_mask, imagenet_mean, keep_masked=True\n",
    "        )\n",
    "        \n",
    "        # Create environment image (room only, people and robot masked out)\n",
    "        env_image = apply_mask_with_mean(\n",
    "            original_image, combined_mask, imagenet_mean, keep_masked=False\n",
    "        )\n",
    "        \n",
    "        # Save images\n",
    "        social_path = social_dir / filename\n",
    "        env_path = env_dir / filename\n",
    "        \n",
    "        save_image(social_image, social_path)\n",
    "        save_image(env_image, env_path)\n",
    "\n",
    "\n",
    "def combine_masks(masks, height, width, confidence_threshold=0.3):\n",
    "    \"\"\"\n",
    "    Combine multiple masks into a single binary mask using union operation\n",
    "    \n",
    "    Args:\n",
    "        masks: Array of individual masks from Detection object\n",
    "        height, width: Dimensions of the original image\n",
    "        \n",
    "    Returns:\n",
    "        combined_mask: Single binary mask (1 = object, 0 = background)\n",
    "    \"\"\"\n",
    "    if masks is None or len(masks) == 0:\n",
    "        return np.zeros((height, width), dtype=np.uint8)\n",
    "    \n",
    "    # Initialize combined mask\n",
    "    combined_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "    \n",
    "    # Union all individual masks using maximum function (as shown in search results)\n",
    "    for mask in masks:\n",
    "        # Ensure mask is the right size\n",
    "        if mask.shape != (height, width):\n",
    "            raise ValueError(f\"Mask shape incorrect: {mask.shape}, should be {(height, width)}\")\n",
    "        \n",
    "        # Union operation: take maximum of current combined mask and new mask\n",
    "        combined_mask = np.maximum(combined_mask, mask.astype(np.uint8))\n",
    "    \n",
    "    return combined_mask\n",
    "\n",
    "def apply_mask_with_mean(image, mask, imagenet_mean, keep_masked=True):\n",
    "    \"\"\"\n",
    "    Apply mask to image and fill empty areas with ImageNet mean values\n",
    "    \n",
    "    Args:\n",
    "        image: Original RGB image (H, W, 3)\n",
    "        mask: Binary mask (H, W) where 1 = object, 0 = background\n",
    "        imagenet_mean: RGB mean values [R, G, B] in range [0, 1]\n",
    "        keep_masked: If True, keep masked areas (social). If False, remove masked areas (environment)\n",
    "        \n",
    "    Returns:\n",
    "        processed_image: Image with mask applied and filled with mean values\n",
    "    \"\"\"\n",
    "    processed_image = image.copy().astype(np.float32) / 255.0\n",
    "    \n",
    "    # Convert imagenet_mean to same range as image\n",
    "    mean_values = np.array(imagenet_mean).reshape(1, 1, 3)\n",
    "    \n",
    "    if keep_masked:\n",
    "        # Social image: keep people/robot, fill background with mean\n",
    "        fill_mask = (mask == 0)  # Areas to fill (background)\n",
    "    else:\n",
    "        # Environment image: keep background, fill people/robot with mean  \n",
    "        fill_mask = (mask == 1)  # Areas to fill (people/robot)\n",
    "    \n",
    "    # Fill specified areas with ImageNet mean values\n",
    "    for c in range(3):  # RGB channels\n",
    "        processed_image[:, :, c][fill_mask] = imagenet_mean[c]\n",
    "    \n",
    "    # Convert back to uint8\n",
    "    processed_image = (processed_image * 255).astype(np.uint8)\n",
    "    \n",
    "    return processed_image\n",
    "\n",
    "def save_image(image, save_path):\n",
    "    \"\"\"\n",
    "    Save image to specified path\n",
    "    \n",
    "    Args:\n",
    "        image: RGB image array (H, W, 3)\n",
    "        save_path: Path to save the image\n",
    "    \"\"\"\n",
    "    # Convert to PIL Image and save\n",
    "    pil_image = Image.fromarray(image)\n",
    "    pil_image.save(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d59426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with bz2.BZ2File('autodistill_dataset_home.pbz2', 'rb') as f:\n",
    "#     dataset_home = pickle.load(f)\n",
    "\n",
    "# process_segmentation_data(\n",
    "#     detections_dataset=dataset_home,\n",
    "#     output_dir='../data/masked',\n",
    "#     imagenet_mean=[0.485, 0.456, 0.406]  # ImageNet RGB means\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59184030",
   "metadata": {},
   "source": [
    "#### dualbranch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e72296a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intermediate_layer_size(input, output, n_layers):\n",
    "    start_exp = (output + 1).bit_length()\n",
    "    end_exp = (input - 1).bit_length()\n",
    "    \n",
    "    total_powers = end_exp - start_exp\n",
    "    if total_powers < n_layers:\n",
    "        return None\n",
    "\n",
    "    result = []\n",
    "    denominator = n_layers + 1\n",
    "    half_denominator = denominator // 2\n",
    "\n",
    "    for i in range(1, n_layers + 1):\n",
    "        numerator = i * total_powers + half_denominator #works same as rounding\n",
    "        idx = numerator // denominator\n",
    "        power = 1 << (start_exp + idx)\n",
    "        result.append(power)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "intermediate_layer_size(1280+64, 9, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d27c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class DualBranchModel(nn.Module):\n",
    "    def __init__(self, num_outputs=9, dropout_rate=0.3, architecture={'env':'lightweight', 'head':'deep'}):\n",
    "        super(DualBranchModel, self).__init__()\n",
    "        self.setup = architecture\n",
    "        \n",
    "        self.social_branch = nn.Sequential(\n",
    "            models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1).features,\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        soc_feature_dim = 1280\n",
    "        \n",
    "\n",
    "        if self.setup['env'] == 'lightweight':\n",
    "            self.env_branch = nn.Sequential(\n",
    "                models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1).features,\n",
    "                nn.AdaptiveAvgPool2d(1),\n",
    "                nn.Flatten()\n",
    "            )\n",
    "            env_feature_dim = 1280\n",
    "\n",
    "        elif self.setup['env'] == 'label':\n",
    "            max_rooms = 30\n",
    "            self.env_branch = nn.Embedding(max_rooms, 64)\n",
    "            env_feature_dim = 64\n",
    "\n",
    "\n",
    "        self.fusion_dim = soc_feature_dim + env_feature_dim\n",
    "\n",
    "        layers = intermediate_layer_size(soc_feature_dim, num_outputs, 1)\n",
    "        self.social_classifier = nn.Sequential(\n",
    "            nn.Linear(soc_feature_dim, layers[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(layers[0], num_outputs)\n",
    "        )\n",
    "        layers = intermediate_layer_size(env_feature_dim, num_outputs, 1)\n",
    "        self.env_classifier = nn.Sequential(\n",
    "            nn.Linear(env_feature_dim, layers[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(layers[0], num_outputs)\n",
    "        )\n",
    "        \n",
    "        if self.setup['head'] == 'deep':\n",
    "            self.head = nn.Sequential(\n",
    "                nn.Linear(self.fusion_dim, 512),\n",
    "                nn.BatchNorm1d(512),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                \n",
    "                nn.Linear(512, 256),\n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                \n",
    "                nn.Linear(256, 128),\n",
    "                nn.BatchNorm1d(128),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                \n",
    "                nn.Linear(128, num_outputs)\n",
    "            )\n",
    "        elif self.setup['head'] == 'shallow':\n",
    "            self.head = nn.Sequential(\n",
    "                nn.Linear(self.fusion_dim, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(512, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(256, num_outputs)\n",
    "            )\n",
    "        \n",
    "    def forward(self, social_img, env_img):\n",
    "        social_features = self.social_branch(social_img)\n",
    "        env_features = self.env_branch(env_img)\n",
    "        \n",
    "        fused_features = torch.cat([social_features, env_features], dim=1)\n",
    "        scores = self.head(fused_features)\n",
    "\n",
    "        social_class = self.social_classifier(social_features.detach())\n",
    "        env_class = self.env_classifier(env_features.detach())\n",
    "        \n",
    "        return {\n",
    "            'output': scores,\n",
    "            'invariant_domain': social_class,\n",
    "            'specific_domain': env_class,\n",
    "            'invariant_feats': social_features,\n",
    "            'specific_feats': env_features\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5849e928",
   "metadata": {},
   "source": [
    "### K Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1525b7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_fold_histories(fold_history):\n",
    "    \"\"\"\n",
    "    Combine multiple training histories by averaging them element-wise.\n",
    "    Handles both simple lists and lists of dictionaries.\n",
    "    \"\"\"\n",
    "    combined_history = {}\n",
    "    metric_keys = list(fold_history[0].keys())\n",
    "    \n",
    "    for key in metric_keys:\n",
    "        # Check if this metric contains dictionaries\n",
    "        first_element = fold_history[0][key][0] if fold_history[0][key] else None\n",
    "        \n",
    "        if isinstance(first_element, dict):\n",
    "            # Handle lists of dictionaries (train_epoch_metrics, grad_norms)\n",
    "            combined_history[key] = average_list_of_dicts(fold_history, key)\n",
    "        else:\n",
    "            # Handle simple lists (train_epoch_loss, val_epoch_loss, cross_domain_val)\n",
    "            stacked_metrics = np.stack([fold_history[fold][key] for fold in fold_history])\n",
    "            combined_history[key] = np.mean(stacked_metrics, axis=0).tolist()\n",
    "    \n",
    "    return combined_history\n",
    "\n",
    "def average_list_of_dicts(fold_history, metric_key):\n",
    "    \"\"\"\n",
    "    Average a list of dictionaries across folds.\n",
    "    \"\"\"\n",
    "    # Get the dictionary keys from the first fold's first epoch\n",
    "    dict_keys = list(fold_history[0][metric_key][0].keys())\n",
    "    \n",
    "    # Convert each fold's list of dicts to a 2D numpy array\n",
    "    fold_arrays = []\n",
    "    for fold in fold_history:\n",
    "        # Convert list of dicts to 2D array: [epochs, sub_metrics]\n",
    "        fold_array = np.array([[epoch_dict[k] for k in dict_keys] \n",
    "                              for epoch_dict in fold_history[fold][metric_key]])\n",
    "        fold_arrays.append(fold_array)\n",
    "    \n",
    "    # Stack all folds and average: [folds, epochs, sub_metrics] -> [epochs, sub_metrics]\n",
    "    stacked = np.stack(fold_arrays)\n",
    "    averaged = np.mean(stacked, axis=0)\n",
    "    \n",
    "    # Convert back to list of dictionaries\n",
    "    result = []\n",
    "    for epoch_values in averaged:\n",
    "        epoch_dict = dict(zip(dict_keys, epoch_values))\n",
    "        result.append(epoch_dict)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b8200e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "df = pd.read_pickle(\"../data/pepper_data.pkl\")\n",
    "df['image_path'] = '../' + df['image_path']\n",
    "\n",
    "# Initialize fold column\n",
    "df['fold'] = -1\n",
    "\n",
    "# Get unique image paths for splitting\n",
    "unique_images_df = df[['image_path', 'domain']].reset_index(drop=True)\n",
    "unique_images_df = unique_images_df[~unique_images_df['image_path'].isin(test_split_idx)]\n",
    "\n",
    "# Create stratified 5-fold splits based on domain\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Assign fold numbers based on domain stratification\n",
    "for fold, (_, val_idx) in enumerate(skf.split(unique_images_df['image_path'], unique_images_df['domain'])):\n",
    "    val_image_paths = unique_images_df.iloc[val_idx]['image_path'].tolist()\n",
    "    df.loc[df['image_path'].isin(val_image_paths), 'fold'] = fold\n",
    "\n",
    "# Verify domain distribution across folds\n",
    "print(\"Domain distribution across folds:\")\n",
    "print(df.groupby(['fold', 'domain']).size().unstack(fill_value=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c600ef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_loaders = create_crossvalidation_loaders(df, 5, batch_sizes=(32, 64, 64), resize_img_to=(512, 288))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f961279",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0cba9f",
   "metadata": {},
   "source": [
    "### setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b327ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For LGRBaseline\n",
    "def baseline_batch(model, batch, device, detach_base, binary, full_replay, loss_params, **kwargs):\n",
    "    inputs, labels, _ = batch\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    outputs = model(inputs)['output']\n",
    "    loss = kwargs['mse_criterion'](outputs, labels)\n",
    "    loss.backward()\n",
    "    metrics = {}\n",
    "    return loss, metrics\n",
    "\n",
    "#For DANN\n",
    "def dann_batch(model, batch, device, detach_base, binary, full_replay, loss_params={'head':0.5, 'social':0.5}, **kwargs):\n",
    "    inputs, labels, domain_labels = batch\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    domain_to_idx = kwargs['domain_to_idx']\n",
    "    domain_labels = torch.tensor([domain_to_idx[d] for d in domain_labels], device=device)\n",
    "    mse_criterion = kwargs['mse_criterion']\n",
    "    bce_criterion = kwargs['bce_criterion']\n",
    "    alpha = kwargs['alpha']\n",
    "\n",
    "    current_domain = kwargs['current_domain']\n",
    "    current_binary_labels = (domain_labels == domain_to_idx[current_domain]).float()\n",
    "    is_first_domain = bool(domain_to_idx[current_domain] == 0)\n",
    "\n",
    "    outputs = model(inputs, alpha=alpha, is_first_domain=is_first_domain)\n",
    "\n",
    "    task_loss = mse_criterion(outputs['output'], labels)\n",
    "\n",
    "    if is_first_domain:\n",
    "        inv_domain_loss = 0\n",
    "        inv_acc = 0\n",
    "    else:\n",
    "        inv_domain_loss = bce_criterion(outputs['invariant_domain'].squeeze(), current_binary_labels)\n",
    "        preds = (outputs['invariant_domain'].squeeze() > 0).float()\n",
    "        inv_acc = (preds == current_binary_labels).float().mean().item()\n",
    "    \n",
    "    total_loss = (loss_params['head'] * task_loss +\n",
    "                    loss_params['social'] * inv_domain_loss)\n",
    "\n",
    "    total_loss.backward()\n",
    "    \n",
    "    metrics = {\n",
    "        'task_loss': task_loss.item(),\n",
    "        'inv_domain': 0 if is_first_domain else inv_domain_loss.item(),\n",
    "        'inv_acc': inv_acc\n",
    "    }\n",
    "    return total_loss, metrics\n",
    "\n",
    "def heuristic_dualbranch_batch(model, batch, device, detach_base, binary, full_replay, loss_params={}, **kwargs):\n",
    "    inputs1, inputs2, labels, domain_labels = batch\n",
    "    inputs1, inputs2, labels, domain_labels = inputs1.to(device), inputs2.to(device), labels.to(device), domain_labels.to(device)\n",
    "    domain_to_idx = kwargs['domain_to_idx']\n",
    "    # domain_labels = torch.tensor([domain_to_idx[d] for d in domain_labels], device=device)\n",
    "    mse_criterion = kwargs['mse_criterion']\n",
    "    ce_criterion = kwargs['ce_criterion']\n",
    "\n",
    "    outputs = model(inputs1, inputs2)\n",
    "\n",
    "    loss = mse_criterion(outputs['output'], labels)\n",
    "    loss.backward()\n",
    "\n",
    "    class_optimiser = kwargs['class_optimizer']\n",
    "    class_optimiser.zero_grad()\n",
    "    inv_domain_loss = ce_criterion(outputs['invariant_domain'], domain_labels)\n",
    "    spec_domain_loss = ce_criterion(outputs['specific_domain'], domain_labels)\n",
    "    (inv_domain_loss + spec_domain_loss).backward()\n",
    "    class_optimiser.step()\n",
    "    inv_acc = (outputs['invariant_domain'].argmax(1) == domain_labels).float().mean().item()\n",
    "    spec_acc = (outputs['specific_domain'].argmax(1) == domain_labels).float().mean().item()\n",
    "    \n",
    "    metrics = {\n",
    "        'inv_domain': inv_domain_loss.item(),\n",
    "        'spec_domain': spec_domain_loss.item(),\n",
    "        'inv_acc': inv_acc,\n",
    "        'spec_acc': spec_acc\n",
    "    }\n",
    "    return loss, metrics\n",
    "\n",
    "\n",
    "# For DualBranchNet\n",
    "def dualbranch_batch(model, batch, device, detach_base, binary, full_replay, loss_params={'head': 1, 'social': 0.5, 'room': 0.2}, **kwargs):\n",
    "    inputs, labels, domain_labels = batch\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    domain_to_idx = kwargs['domain_to_idx']\n",
    "    domain_labels = torch.tensor([domain_to_idx[d] for d in domain_labels], device=device)\n",
    "    mse_criterion = kwargs['mse_criterion']\n",
    "    ce_criterion = kwargs['ce_criterion']\n",
    "    cos_criterion = kwargs['cos_criterion']\n",
    "    alpha = kwargs['alpha']\n",
    "    if binary:\n",
    "        bce_criterion = kwargs['bce_criterion']\n",
    "\n",
    "    # Split batch\n",
    "    current_domain = kwargs['current_domain']\n",
    "    current_binary_labels = (domain_labels == domain_to_idx[current_domain]).float()\n",
    "    current_mask = (domain_labels == domain_to_idx[current_domain])\n",
    "\n",
    "    if full_replay:\n",
    "        current_mask = torch.ones_like(current_mask, dtype=torch.bool)\n",
    "\n",
    "    replay_mask = ~current_mask\n",
    "\n",
    "    # 1. Current samples: update all parameters\n",
    "    if current_mask.any():\n",
    "        inputs_current = inputs[current_mask]\n",
    "        labels_current = labels[current_mask]\n",
    "        domain_labels_current = domain_labels[current_mask]\n",
    "\n",
    "        outputs_current = model(inputs_current, alpha=alpha)\n",
    "        inv_feats = outputs_current['invariant_feats']\n",
    "        spec_feats = outputs_current['specific_feats']\n",
    "\n",
    "        task_loss = mse_criterion(outputs_current['output'], labels_current)\n",
    "        if binary:\n",
    "            inv_domain_loss = bce_criterion(outputs_current['invariant_domain'].squeeze(), current_binary_labels[current_mask])\n",
    "        else:\n",
    "            inv_domain_loss = ce_criterion(outputs_current['invariant_domain'], domain_labels_current)\n",
    "        spec_domain_loss = ce_criterion(outputs_current['specific_domain'], domain_labels_current)\n",
    "        similarity_loss = cos_criterion(inv_feats, spec_feats)\n",
    "        \n",
    "        total_loss = (loss_params['head'] * task_loss +\n",
    "                      loss_params['social'] * inv_domain_loss +\n",
    "                      loss_params['room'] * spec_domain_loss)\n",
    "\n",
    "        total_loss.backward(retain_graph= not full_replay)\n",
    "        \n",
    "        if binary:\n",
    "            # Threshold at 0 (sigmoid(0) = 0.5)\n",
    "            preds = (outputs_current['invariant_domain'].squeeze() > 0).float()\n",
    "            inv_acc = (preds == current_binary_labels[current_mask]).float().mean().item()\n",
    "        else:\n",
    "            inv_acc = (outputs_current['invariant_domain'].argmax(1) == domain_labels_current).float().mean().item()\n",
    "        spec_acc = (outputs_current['specific_domain'].argmax(1) == domain_labels_current).float().mean().item()\n",
    "    else:\n",
    "        total_loss = torch.tensor(0.0, device=device)\n",
    "        inv_acc = 0.0\n",
    "        spec_acc = 0.0\n",
    "        task_loss = torch.tensor(0.0, device=device)\n",
    "        inv_domain_loss = torch.tensor(0.0, device=device)\n",
    "        spec_domain_loss = torch.tensor(0.0, device=device)\n",
    "        similarity_loss = torch.tensor(0.0, device=device)\n",
    "\n",
    "    # 2. Replay samples: update only specific branch + head\n",
    "    if replay_mask.any():\n",
    "        inputs_replay = inputs[replay_mask]\n",
    "        labels_replay = labels[replay_mask]\n",
    "        domain_labels_replay = domain_labels[replay_mask]\n",
    "\n",
    "        #no_grad, unlike requires_grad=False, detaches all elements from the gradient computation graph\n",
    "        with torch.no_grad():\n",
    "            base_replay = model.backbone(inputs_replay)\n",
    "            base_replay = model.pool(base_replay).flatten(1)\n",
    "            inv_feats_replay = model.invariant(base_replay)\n",
    "\n",
    "        specific_feats = model.specific(base_replay)\n",
    "        spec_domain_pred = model.specific_domain_classifier(specific_feats)\n",
    "        \n",
    "        if detach_base:\n",
    "            combined = torch.cat([inv_feats_replay, specific_feats, base_replay], dim=1)\n",
    "        else:\n",
    "            combined = torch.cat([inv_feats_replay, specific_feats], dim=1)  \n",
    "        \n",
    "        scores = model.head(combined)\n",
    "        \n",
    "        task_loss_replay = mse_criterion(scores, labels_replay)\n",
    "        spec_domain_loss_replay = ce_criterion(spec_domain_pred, domain_labels_replay)\n",
    "        total_loss_replay = task_loss_replay + 0.2 * spec_domain_loss_replay\n",
    "        \n",
    "        total_loss_replay.backward()\n",
    "    \n",
    "    metrics = {\n",
    "        'task_loss': task_loss.item(),\n",
    "        'inv_domain': inv_domain_loss.item(),\n",
    "        'spec_domain': spec_domain_loss.item(),\n",
    "        'similarity': similarity_loss.item(),\n",
    "        'inv_acc': inv_acc,\n",
    "        'spec_acc': spec_acc,\n",
    "        'replay_count': replay_mask.sum().item(),\n",
    "        'current_count': current_mask.sum().item()\n",
    "    }\n",
    "    return total_loss, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6df3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: change dataset to return torch domain labels indexes not strings\n",
    "def evaluate_model(model, dataloader, criterion, device , tsne=None):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            if len(batch) == 4:\n",
    "                inputs1, inputs2, labels, domain_labels = batch\n",
    "                inputs1 = inputs1.to(device, dtype=torch.float32)\n",
    "                inputs2 = inputs2.to(device, dtype=torch.float32)\n",
    "                labels = labels.to(device, dtype=torch.float32)\n",
    "                inputs = (inputs1, inputs2)\n",
    "            elif len(batch) == 3:\n",
    "                inputs, labels, _ = batch\n",
    "                inputs = inputs.to(device, dtype=torch.float32)\n",
    "                labels = labels.to(device, dtype=torch.float32)\n",
    "                inputs = (inputs,)\n",
    "            else:\n",
    "                raise ValueError(f\"Batch contains {len(batch)} objects. Should contain 3 or 4 - image/two, labels, domain_labels\")\n",
    "\n",
    "            outputs = model(*inputs)['output']\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item() * inputs[0].size(0)\n",
    "            total_samples += inputs[0].size(0)\n",
    "            \n",
    "            if tsne:\n",
    "                tsne['social'].append(outputs['invariant_feats'].cpu())\n",
    "                tsne['environmental'].append(outputs['specific_feats'].cpu())\n",
    "                tsne['domains'].append(domain_labels.cpu())\n",
    "\n",
    "            val_loss = total_loss / total_samples\n",
    "\n",
    "    return (val_loss, tsne) if tsne else val_loss\n",
    "\n",
    "def cross_domain_validation(model, domain_dataloaders, criterion, device, tsne=None):\n",
    "    results = {}\n",
    "    for domain, loaders in domain_dataloaders.items():\n",
    "        val_loader = loaders['val']\n",
    "        if tsne:\n",
    "            val_loss, tsne = evaluate_model(model, val_loader, criterion, device, tsne)\n",
    "        else:\n",
    "            val_loss = evaluate_model(model, val_loader, criterion, device)\n",
    "        results[domain] = val_loss\n",
    "    return (results, tsne) if tsne else results\n",
    "\n",
    "def average_metrics(metrics_list):\n",
    "    # metrics_list: list of dicts, each dict contains metrics for a batch\n",
    "    if not metrics_list:\n",
    "        return {}\n",
    "    keys = metrics_list[0].keys()\n",
    "    avg_metrics = {}\n",
    "    for k in keys:\n",
    "        avg_metrics[k] = float(np.mean([m[k] for m in metrics_list if k in m]))\n",
    "    return avg_metrics\n",
    "\n",
    "def collect_tsne_features(model, loader, device):\n",
    "    model.eval()\n",
    "    all_inv, all_spec, all_domains = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for domain, loaders in domain_dataloaders.items():\n",
    "            loader = loaders['val']\n",
    "            for x, _, d in loader:\n",
    "                x = x.to(device)\n",
    "                out = model(x)\n",
    "                all_inv.append(out['invariant_feats'].cpu())\n",
    "                all_domains += list(d)\n",
    "    inv_feats = torch.cat(all_inv, dim=0).numpy()\n",
    "    return inv_feats, all_domains\n",
    "\n",
    "\n",
    "def collect_gradients(model):\n",
    "    grad_norms = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.grad is not None and not name.startswith(\"backbone\"):\n",
    "            module = name.split('.')[0]\n",
    "            norm = param.grad.norm(2).item()\n",
    "            if module not in grad_norms:\n",
    "                grad_norms[module] = []\n",
    "            grad_norms[module].append(norm)\n",
    "    # Take mean per module\n",
    "    grad_norms = {k: float(np.mean(v)) for k, v in grad_norms.items()}\n",
    "    return grad_norms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcbbc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "def unified_train_loop(\n",
    "    model, domains, domain_dataloaders, buffer, optimizer, writer, device,\n",
    "    batch_fn, batch_kwargs, loss_params, num_epochs=5, exp_name=\"exp\", gradient_clipping=False, detach_base=False, binary=False, full_replay=False, collect_tsne_data=False, restart={}, eval_buffer=False\n",
    "):\n",
    "    start_domain_idx = 0\n",
    "    global_step = 0\n",
    "    history = {\n",
    "        'train_epoch_loss': [],\n",
    "        'val_epoch_loss': [],\n",
    "        'val_buffer_epoch_loss': [],\n",
    "        'train_epoch_metrics': [],\n",
    "        'cross_domain_val': [],\n",
    "        'grad_norms': [],\n",
    "    }\n",
    "    \n",
    "    if restart:\n",
    "        # Populate history\n",
    "        global_step = restart['global_step']\n",
    "        history = restart['history']\n",
    "        # Populate buffer\n",
    "        start_domain_idx = np.where(domains == restart['domain'])[0][0]\n",
    "        for domain_idx, current_domain in enumerate(domains[:start_domain_idx]):\n",
    "            buffer.update_buffer(current_domain, domain_dataloaders[current_domain]['train'].dataset) \n",
    "        print(f\"Restarting from domain {restart['domain']} index {start_domain_idx}\")\n",
    "        print(f\"Buffer: {buffer.get_domain_distribution()}\")         \n",
    "        \n",
    "\n",
    "    for domain_idx, current_domain in enumerate(tqdm(domains[start_domain_idx:], desc=f\"Total training\"), start=start_domain_idx):\n",
    "        train_loader = buffer.get_loader_with_replay(current_domain, domain_dataloaders[current_domain]['train'])\n",
    "        if eval_buffer:\n",
    "            eval_loader = eval_buffer.get_loader_with_replay(current_domain, domain_dataloaders[current_domain]['val'])\n",
    "        else:\n",
    "            eval_loader = domain_dataloaders[current_domain]['val']\n",
    "        len_dataloader = len(train_loader)\n",
    "        \n",
    "        for epoch in trange(num_epochs, desc=f\"Current domain {current_domain}\"):\n",
    "            model.train()\n",
    "            epoch_loss = 0.0\n",
    "            samples = 0\n",
    "            batch_metrics_list = []\n",
    "            \n",
    "            # for batch_idx, batch in enumerate(train_loader):\n",
    "            for batch_idx, batch in enumerate(tqdm(train_loader, desc=f\"Current epoch {epoch}\", leave=False)):\n",
    "                if not batch_kwargs['alpha']:\n",
    "                    p = (epoch * len_dataloader + batch_idx) / (num_epochs * len_dataloader)\n",
    "                    alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
    "                else:\n",
    "                    alpha = batch_kwargs['alpha']\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss, metrics = batch_fn(model, batch, device, detach_base, binary, full_replay, loss_params, **{**batch_kwargs, 'current_domain': current_domain, 'alpha':alpha})\n",
    "                if gradient_clipping:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "                batch_size = batch[0].size(0)\n",
    "                epoch_loss += loss.item() * batch_size\n",
    "                samples += batch_size\n",
    "                global_step += 1\n",
    "                batch_metrics_list.append(metrics)\n",
    "                # # TensorBoard logging (every 10 batches)\n",
    "                # if writer and batch_idx % 10 == 0:\n",
    "                #     writer.add_scalar(f'{exp_name}/train_loss', loss.item(), global_step)\n",
    "                #     for k, v in metrics.items():\n",
    "                #         writer.add_scalar(f'{exp_name}/train_{k}', v, global_step)\n",
    "            avg_epoch_loss = epoch_loss / samples\n",
    "            # writer.add_scalar(f'{exp_name}/train_epoch_loss', avg_epoch_loss, global_step)\n",
    "            history['train_epoch_loss'].append(avg_epoch_loss)\n",
    "            # Average batch metrics for this epoch\n",
    "            avg_metrics = average_metrics(batch_metrics_list)\n",
    "            history['train_epoch_metrics'].append(avg_metrics)\n",
    "\n",
    "            # Collect gradients\n",
    "            grad_norms = collect_gradients(model)\n",
    "            history['grad_norms'].append(grad_norms)\n",
    "\n",
    "            # Validation on current domain\n",
    "            val_loss = evaluate_model(model, domain_dataloaders[current_domain]['val'], batch_kwargs['mse_criterion'], device)\n",
    "            val_loss_buffer = evaluate_model(model, eval_loader, batch_kwargs['mse_criterion'], device)\n",
    "            # writer.add_scalar(f'{exp_name}/val_epoch_loss', val_loss, global_step)\n",
    "            history['val_epoch_loss'].append(val_loss)\n",
    "            history['val_buffer_epoch_loss'].append(val_loss_buffer)\n",
    "\n",
    "            # Collect data for t-SNE domain separation graphs\n",
    "            if collect_tsne_data:\n",
    "                inv_feats, domain_labels = collect_tsne_features(model, domain_dataloaders, device)\n",
    "                tsne_data = {\n",
    "                    'inv_feats': inv_feats,\n",
    "                    'domain_labels': domain_labels\n",
    "                }\n",
    "            else:\n",
    "                tsne_data = None\n",
    "\n",
    "            # Cross-domain validation (after each domain)\n",
    "            if epoch == num_epochs-1:\n",
    "                if collect_tsne_data:\n",
    "                    tsne = {'social': [], 'env': [], 'domains': []}\n",
    "                    cross_val, tsne_data = cross_domain_validation(model, domain_dataloaders, batch_kwargs['mse_criterion'], device, tsne)\n",
    "                else:\n",
    "                    cross_val = cross_domain_validation(model, domain_dataloaders, batch_kwargs['mse_criterion'], device)\n",
    "                history['cross_domain_val'].append(cross_val)\n",
    "\n",
    "                # Only save last model per domain to save space\n",
    "                torch.save({\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'history': history,\n",
    "                    'tsne' : tsne_data,\n",
    "                }, f\"../checkpoints/{exp_name}_domain{current_domain}_epoch{epoch}_step{global_step}.pt\")\n",
    "            # else:\n",
    "            #     # Save metrics\n",
    "            #     torch.save({\n",
    "            #         # 'model_state_dict': model.state_dict(),\n",
    "            #         # 'optimizer_state_dict': optimizer.state_dict(),\n",
    "            #         'history': history,\n",
    "            #         'tsne' : tsne_data,\n",
    "            #     }, f\"../checkpoints/{exp_name}_domain{current_domain}_epoch{epoch}_step{global_step}.pt\")\n",
    "            with open(f\"../checkpoints/{exp_name}_history.pkl\", \"wb\") as f:\n",
    "                pickle.dump(history, f)\n",
    "            \n",
    "        buffer.update_buffer(current_domain, domain_dataloaders[current_domain]['train'].dataset)\n",
    "        eval_buffer.update_buffer(current_domain, domain_dataloaders[current_domain]['val'].dataset)\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1584bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a91eb94",
   "metadata": {},
   "source": [
    "### runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973cdbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "domains = df['domain'].unique()\n",
    "domain_to_idx = {d: i for i, d in enumerate(domains)}\n",
    "\n",
    "# # For baseline model\n",
    "# baseline_model = LGRBaseline().to(device)\n",
    "# optimizer = torch.optim.Adam(baseline_model.parameters(), lr=1e-3)\n",
    "# buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "# exp_name = f\"baselinemodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "# writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "# baseline_kwargs = {'mse_criterion': nn.MSELoss()}\n",
    "# unified_train_loop(\n",
    "#     model=baseline_model,\n",
    "#     domains=domains,\n",
    "#     domain_dataloaders=domain_dataloaders,\n",
    "#     buffer=buffer,\n",
    "#     optimizer=optimizer,\n",
    "#     writer=writer,\n",
    "#     device=device,\n",
    "#     batch_fn=baseline_batch,\n",
    "#     batch_kwargs=baseline_kwargs,\n",
    "#     num_epochs=10,\n",
    "#     exp_name=exp_name\n",
    "# )\n",
    "\n",
    "# For DualBranchNet\n",
    "dual_model = DualBranchNet(num_domains=len(domains)).to(device)\n",
    "optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "\n",
    "def cos_criterion(a, b):\n",
    "    return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "    # return (nn.CosineSimilarity()(a, b) ** 2).mean()\n",
    "\n",
    "exp_name = f\"nores_dualbranchmodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "dualbranch_kwargs = {\n",
    "    'mse_criterion': nn.MSELoss(),\n",
    "    'ce_criterion': nn.CrossEntropyLoss(),\n",
    "    'cos_criterion': cos_criterion,\n",
    "    'domain_to_idx': domain_to_idx\n",
    "}\n",
    "unified_train_loop(\n",
    "    model=dual_model,\n",
    "    domains=domains,\n",
    "    domain_dataloaders=domain_dataloaders,\n",
    "    buffer=buffer,\n",
    "    optimizer=optimizer,\n",
    "    writer=writer,\n",
    "    device=device,\n",
    "    batch_fn=dualbranch_batch,\n",
    "    batch_kwargs=dualbranch_kwargs,\n",
    "    num_epochs=10,\n",
    "    exp_name=exp_name,\n",
    "    gradient_clipping=False\n",
    ")\n",
    "\n",
    "\n",
    "# For DualBranchNet\n",
    "dual_model = DualBranchNet(num_domains=len(domains)).to(device)\n",
    "optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "\n",
    "def cos_criterion(a, b):\n",
    "    return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "    # return (nn.CosineSimilarity()(a, b) ** 2).mean()\n",
    "\n",
    "exp_name = f\"nores_gradclip_dualbranchmodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "dualbranch_kwargs = {\n",
    "    'mse_criterion': nn.MSELoss(),\n",
    "    'ce_criterion': nn.CrossEntropyLoss(),\n",
    "    'cos_criterion': cos_criterion,\n",
    "    'domain_to_idx': domain_to_idx\n",
    "}\n",
    "unified_train_loop(\n",
    "    model=dual_model,\n",
    "    domains=domains,\n",
    "    domain_dataloaders=domain_dataloaders,\n",
    "    buffer=buffer,\n",
    "    optimizer=optimizer,\n",
    "    writer=writer,\n",
    "    device=device,\n",
    "    batch_fn=dualbranch_batch,\n",
    "    batch_kwargs=dualbranch_kwargs,\n",
    "    num_epochs=10,\n",
    "    exp_name=exp_name,\n",
    "    gradient_clipping=True\n",
    ")\n",
    "\n",
    "# For DualBranchNet\n",
    "dual_model = DualBranchNet(weights_init=True, weights_norm=True).to(device)\n",
    "optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "\n",
    "def cos_criterion(a, b):\n",
    "    return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "    # return (nn.CosineSimilarity()(a, b) ** 2).mean()\n",
    "\n",
    "exp_name = f\"nores_winit_wnorm_dualbranchmodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "dualbranch_kwargs = {\n",
    "    'mse_criterion': nn.MSELoss(),\n",
    "    'ce_criterion': nn.CrossEntropyLoss(),\n",
    "    'cos_criterion': cos_criterion,\n",
    "    'domain_to_idx': domain_to_idx\n",
    "}\n",
    "unified_train_loop(\n",
    "    model=dual_model,\n",
    "    domains=domains,\n",
    "    domain_dataloaders=domain_dataloaders,\n",
    "    buffer=buffer,\n",
    "    optimizer=optimizer,\n",
    "    writer=writer,\n",
    "    device=device,\n",
    "    batch_fn=dualbranch_batch,\n",
    "    batch_kwargs=dualbranch_kwargs,\n",
    "    num_epochs=10,\n",
    "    exp_name=exp_name,\n",
    "    gradient_clipping=False\n",
    ")\n",
    "\n",
    "# For DualBranchNet\n",
    "dual_model = DualBranchNet(weights_init=True, weights_norm=True).to(device)\n",
    "optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "\n",
    "def cos_criterion(a, b):\n",
    "    return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "    # return (nn.CosineSimilarity()(a, b) ** 2).mean()\n",
    "\n",
    "exp_name = f\"nores_gradclip_winit_wnorm_dualbranchmodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "dualbranch_kwargs = {\n",
    "    'mse_criterion': nn.MSELoss(),\n",
    "    'ce_criterion': nn.CrossEntropyLoss(),\n",
    "    'cos_criterion': cos_criterion,\n",
    "    'domain_to_idx': domain_to_idx\n",
    "}\n",
    "unified_train_loop(\n",
    "    model=dual_model,\n",
    "    domains=domains,\n",
    "    domain_dataloaders=domain_dataloaders,\n",
    "    buffer=buffer,\n",
    "    optimizer=optimizer,\n",
    "    writer=writer,\n",
    "    device=device,\n",
    "    batch_fn=dualbranch_batch,\n",
    "    batch_kwargs=dualbranch_kwargs,\n",
    "    num_epochs=10,\n",
    "    exp_name=exp_name,\n",
    "    gradient_clipping = True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9dfd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "domains = df['domain'].unique()\n",
    "domain_to_idx = {d: i for i, d in enumerate(domains)}\n",
    "\n",
    "dual_model = DualBranchNet_deep(weights_init=True, weights_norm=False).to(device)\n",
    "optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "\n",
    "def cos_criterion(a, b):\n",
    "    return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "    # return (nn.CosineSimilarity()(a, b) ** 2).mean()\n",
    "\n",
    "exp_name = f\"deep_dualbranchmodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "dualbranch_kwargs = {\n",
    "    'mse_criterion': nn.MSELoss(),\n",
    "    'ce_criterion': nn.CrossEntropyLoss(),\n",
    "    'cos_criterion': cos_criterion,\n",
    "    'domain_to_idx': domain_to_idx\n",
    "}\n",
    "unified_train_loop(\n",
    "    model=dual_model,\n",
    "    domains=domains,\n",
    "    domain_dataloaders=domain_dataloaders,\n",
    "    buffer=buffer,\n",
    "    optimizer=optimizer,\n",
    "    writer=writer,\n",
    "    device=device,\n",
    "    batch_fn=dualbranch_batch,\n",
    "    batch_kwargs=dualbranch_kwargs,\n",
    "    num_epochs=10,\n",
    "    exp_name=exp_name,\n",
    "    gradient_clipping=True\n",
    ")\n",
    "\n",
    "\n",
    "dual_model = DualBranchNet_deep(weights_init=True, weights_norm=True).to(device)\n",
    "optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "\n",
    "def cos_criterion(a, b):\n",
    "    return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "    # return (nn.CosineSimilarity()(a, b) ** 2).mean()\n",
    "\n",
    "exp_name = f\"deep_norm_dualbranchmodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "dualbranch_kwargs = {\n",
    "    'mse_criterion': nn.MSELoss(),\n",
    "    'ce_criterion': nn.CrossEntropyLoss(),\n",
    "    'cos_criterion': cos_criterion,\n",
    "    'domain_to_idx': domain_to_idx\n",
    "}\n",
    "unified_train_loop(\n",
    "    model=dual_model,\n",
    "    domains=domains,\n",
    "    domain_dataloaders=domain_dataloaders,\n",
    "    buffer=buffer,\n",
    "    optimizer=optimizer,\n",
    "    writer=writer,\n",
    "    device=device,\n",
    "    batch_fn=dualbranch_batch,\n",
    "    batch_kwargs=dualbranch_kwargs,\n",
    "    num_epochs=10,\n",
    "    exp_name=exp_name,\n",
    "    gradient_clipping=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86449b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "domains = df['domain'].unique()\n",
    "domain_to_idx = {d: i for i, d in enumerate(domains)}\n",
    "\n",
    "dual_model = DualBranchNet_deep(weights_init=False, weights_norm=False, layer_norm=False, detach_base=True).to(device)\n",
    "optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "\n",
    "def cos_criterion(a, b):\n",
    "    return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "    # return (nn.CosineSimilarity()(a, b) ** 2).mean()\n",
    "\n",
    "exp_name = f\"bbdetach_deep_dualbranchmodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "dualbranch_kwargs = {\n",
    "    'mse_criterion': nn.MSELoss(),\n",
    "    'ce_criterion': nn.CrossEntropyLoss(),\n",
    "    'cos_criterion': cos_criterion,\n",
    "    'domain_to_idx': domain_to_idx\n",
    "}\n",
    "unified_train_loop(\n",
    "    model=dual_model,\n",
    "    domains=domains,\n",
    "    domain_dataloaders=domain_dataloaders,\n",
    "    buffer=buffer,\n",
    "    optimizer=optimizer,\n",
    "    writer=writer,\n",
    "    device=device,\n",
    "    batch_fn=dualbranch_batch,\n",
    "    batch_kwargs=dualbranch_kwargs,\n",
    "    num_epochs=10,\n",
    "    exp_name=exp_name,\n",
    "    gradient_clipping=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41678456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "domains = df['domain'].unique()\n",
    "domain_to_idx = {d: i for i, d in enumerate(domains)}\n",
    "\n",
    "dual_model = DualBranchNet_deep(weights_init=True, weights_norm=False, layer_norm=False, detach_base=True).to(device)\n",
    "optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "\n",
    "def cos_criterion(a, b):\n",
    "    return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "    # return (nn.CosineSimilarity()(a, b) ** 2).mean()\n",
    "\n",
    "exp_name = f\"bdetach_batch16_dualbranchmodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "dualbranch_kwargs = {\n",
    "    'mse_criterion': nn.MSELoss(),\n",
    "    'ce_criterion': nn.CrossEntropyLoss(),\n",
    "    'cos_criterion': cos_criterion,\n",
    "    'domain_to_idx': domain_to_idx\n",
    "}\n",
    "\n",
    "domain_dataloaders = {}\n",
    "for domain in domains:\n",
    "    domain_df = df[df['domain'] == domain]\n",
    "    loaders = create_dataloaders(domain_df, batch_sizes=(16, 64, 64), resize_img_to=(128, 128), seed=SEED)  #TODO should be (384, 216) to retain scale or (224, 224) for best performance on MobileNet\n",
    "    domain_dataloaders[domain] = loaders\n",
    "\n",
    "unified_train_loop(\n",
    "    model=dual_model,\n",
    "    domains=domains,\n",
    "    domain_dataloaders=domain_dataloaders,\n",
    "    buffer=buffer,\n",
    "    optimizer=optimizer,\n",
    "    writer=writer,\n",
    "    device=device,\n",
    "    batch_fn=dualbranch_batch,\n",
    "    batch_kwargs=dualbranch_kwargs,\n",
    "    num_epochs=10,\n",
    "    exp_name=exp_name,\n",
    "    gradient_clipping=True,\n",
    "    detach_base=True\n",
    ")\n",
    "\n",
    "domain_dataloaders = {}\n",
    "for domain in domains:\n",
    "    domain_df = df[df['domain'] == domain]\n",
    "    loaders = create_dataloaders(domain_df, batch_sizes=(32, 64, 64), resize_img_to=(128, 128), seed=SEED)  #TODO should be (384, 216) to retain scale or (224, 224) for best performance on MobileNet\n",
    "    domain_dataloaders[domain] = loaders\n",
    "\n",
    "\n",
    "dual_model = DualBranchNet_deep(weights_init=False, weights_norm=False, layer_norm=False, detach_base=True, freeze_base='partial').to(device)\n",
    "optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "\n",
    "def cos_criterion(a, b):\n",
    "    return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "    # return (nn.CosineSimilarity()(a, b) ** 2).mean()\n",
    "\n",
    "exp_name = f\"bdetach_pfrozen_dualbranchmodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "dualbranch_kwargs = {\n",
    "    'mse_criterion': nn.MSELoss(),\n",
    "    'ce_criterion': nn.CrossEntropyLoss(),\n",
    "    'cos_criterion': cos_criterion,\n",
    "    'domain_to_idx': domain_to_idx\n",
    "}\n",
    "unified_train_loop(\n",
    "    model=dual_model,\n",
    "    domains=domains,\n",
    "    domain_dataloaders=domain_dataloaders,\n",
    "    buffer=buffer,\n",
    "    optimizer=optimizer,\n",
    "    writer=writer,\n",
    "    device=device,\n",
    "    batch_fn=dualbranch_batch,\n",
    "    batch_kwargs=dualbranch_kwargs,\n",
    "    num_epochs=10,\n",
    "    exp_name=exp_name,\n",
    "    gradient_clipping=True,\n",
    "    detach_base=True\n",
    ")\n",
    "\n",
    "dual_model = DualBranchNet_deep(weights_init=False, weights_norm=False, layer_norm=False, detach_base=False, freeze_base='full').to(device)\n",
    "optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "\n",
    "def cos_criterion(a, b):\n",
    "    return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "    # return (nn.CosineSimilarity()(a, b) ** 2).mean()\n",
    "\n",
    "exp_name = f\"ffrozen_dualbranchmodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "dualbranch_kwargs = {\n",
    "    'mse_criterion': nn.MSELoss(),\n",
    "    'ce_criterion': nn.CrossEntropyLoss(),\n",
    "    'cos_criterion': cos_criterion,\n",
    "    'domain_to_idx': domain_to_idx\n",
    "}\n",
    "unified_train_loop(\n",
    "    model=dual_model,\n",
    "    domains=domains,\n",
    "    domain_dataloaders=domain_dataloaders,\n",
    "    buffer=buffer,\n",
    "    optimizer=optimizer,\n",
    "    writer=writer,\n",
    "    device=device,\n",
    "    batch_fn=dualbranch_batch,\n",
    "    batch_kwargs=dualbranch_kwargs,\n",
    "    num_epochs=10,\n",
    "    exp_name=exp_name,\n",
    "    gradient_clipping=True,\n",
    "    detach_base=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f63e81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "domains = df['domain'].unique()\n",
    "domain_to_idx = {d: i for i, d in enumerate(domains)}\n",
    "\n",
    "dual_model = DualBranchNet_binary(weights_init=False, weights_norm=False, layer_norm=False, detach_base=False, freeze_base='full', explicit_grl=False).to(device)\n",
    "optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "\n",
    "def cos_criterion(a, b):\n",
    "    return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "    # return (nn.CosineSimilarity()(a, b) ** 2).mean()\n",
    "\n",
    "exp_name = f\"ffrozen_binary_dualbranchmodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "dualbranch_kwargs = {\n",
    "    'mse_criterion': nn.MSELoss(),\n",
    "    'ce_criterion': nn.CrossEntropyLoss(),\n",
    "    'cos_criterion': cos_criterion,\n",
    "    'domain_to_idx': domain_to_idx,\n",
    "    'bce_criterion': nn.BCEWithLogitsLoss()\n",
    "}\n",
    "unified_train_loop(\n",
    "    model=dual_model,\n",
    "    domains=domains,\n",
    "    domain_dataloaders=domain_dataloaders,\n",
    "    buffer=buffer,\n",
    "    optimizer=optimizer,\n",
    "    writer=writer,\n",
    "    device=device,\n",
    "    batch_fn=dualbranch_batch,\n",
    "    batch_kwargs=dualbranch_kwargs,\n",
    "    num_epochs=10,\n",
    "    exp_name=exp_name,\n",
    "    gradient_clipping=True,\n",
    "    detach_base=False,\n",
    "    binary = True,\n",
    "    full_replay = False\n",
    ")\n",
    "\n",
    "dual_model = DualBranchNet_binary(weights_init=False, weights_norm=False, layer_norm=False, detach_base=False, freeze_base='full', explicit_grl=False).to(device)\n",
    "optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "\n",
    "def cos_criterion(a, b):\n",
    "    return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "    # return (nn.CosineSimilarity()(a, b) ** 2).mean()\n",
    "\n",
    "exp_name = f\"ffrozen_binary_explicitgrl_dualbranchmodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "dualbranch_kwargs = {\n",
    "    'mse_criterion': nn.MSELoss(),\n",
    "    'ce_criterion': nn.CrossEntropyLoss(),\n",
    "    'cos_criterion': cos_criterion,\n",
    "    'domain_to_idx': domain_to_idx,\n",
    "    'bce_criterion': nn.BCEWithLogitsLoss()\n",
    "}\n",
    "unified_train_loop(\n",
    "    model=dual_model,\n",
    "    domains=domains,\n",
    "    domain_dataloaders=domain_dataloaders,\n",
    "    buffer=buffer,\n",
    "    optimizer=optimizer,\n",
    "    writer=writer,\n",
    "    device=device,\n",
    "    batch_fn=dualbranch_batch,\n",
    "    batch_kwargs=dualbranch_kwargs,\n",
    "    num_epochs=10,\n",
    "    exp_name=exp_name,\n",
    "    gradient_clipping=True,\n",
    "    detach_base=False,\n",
    "    binary=True,\n",
    "    full_replay = False\n",
    ")\n",
    "\n",
    "\n",
    "dual_model = DualBranchNet_binary(weights_init=True, weights_norm=False, layer_norm=False, detach_base=False, freeze_base='full', explicit_grl=True).to(device)\n",
    "optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "\n",
    "def cos_criterion(a, b):\n",
    "    return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "    # return (nn.CosineSimilarity()(a, b) ** 2).mean()\n",
    "\n",
    "exp_name = f\"freplay_ffrozen_binary_explicitgrl_dualbranchmodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "dualbranch_kwargs = {\n",
    "    'mse_criterion': nn.MSELoss(),\n",
    "    'ce_criterion': nn.CrossEntropyLoss(),\n",
    "    'cos_criterion': cos_criterion,\n",
    "    'domain_to_idx': domain_to_idx,\n",
    "    'bce_criterion': nn.BCEWithLogitsLoss()\n",
    "}\n",
    "unified_train_loop(\n",
    "    model=dual_model,\n",
    "    domains=domains,\n",
    "    domain_dataloaders=domain_dataloaders,\n",
    "    buffer=buffer,\n",
    "    optimizer=optimizer,\n",
    "    writer=writer,\n",
    "    device=device,\n",
    "    batch_fn=dualbranch_batch,\n",
    "    batch_kwargs=dualbranch_kwargs,\n",
    "    num_epochs=10,\n",
    "    exp_name=exp_name,\n",
    "    gradient_clipping=True,\n",
    "    detach_base=False,\n",
    "    binary=True,\n",
    "    full_replay = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a5e038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "domains = df['domain'].unique()\n",
    "domain_to_idx = {d: i for i, d in enumerate(domains)}\n",
    "\n",
    "testing_scenarios = {\n",
    "    # 'pretrained_backbone_cnn_branch': ('pretrained', 'simple', 'simple'), \n",
    "    # 'linear_branch': ('3conv', 'linear', 'simple'),\n",
    "    # 'cnn_branch': ('3conv', 'simple', 'simple'),\n",
    "    # 'adversarial': ('2conv', 'adversarial', 'adversarial'),\n",
    "    'cnn_specialised_branches': ('3conv', 'special', 'simple')\n",
    "}\n",
    "\n",
    "for name, (backbone, branch, end) in testing_scenarios.items():\n",
    "    print(f\"\\nTesting: {backbone} + {branch} + {end}\")\n",
    "    dual_model = DualBranchCNNNet(backbone_type=backbone, branch_type=branch, end_type=end, batch_norm=True).to(device)\n",
    "    optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "    buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "\n",
    "    def cos_criterion(a, b):\n",
    "        return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "\n",
    "    exp_name = f\"CNN_{name}_dualbranchmodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "    dualbranch_kwargs = {\n",
    "        'mse_criterion': nn.MSELoss(),\n",
    "        'ce_criterion': nn.CrossEntropyLoss(),\n",
    "        'cos_criterion': cos_criterion,\n",
    "        'domain_to_idx': domain_to_idx,\n",
    "        'bce_criterion': nn.BCEWithLogitsLoss()\n",
    "    }\n",
    "    unified_train_loop(\n",
    "        model=dual_model,\n",
    "        domains=domains,\n",
    "        domain_dataloaders=domain_dataloaders,\n",
    "        buffer=buffer,\n",
    "        optimizer=optimizer,\n",
    "        writer=writer,\n",
    "        device=device,\n",
    "        batch_fn=dualbranch_batch,\n",
    "        batch_kwargs=dualbranch_kwargs,\n",
    "        num_epochs=10,\n",
    "        exp_name=exp_name,\n",
    "        gradient_clipping=False,\n",
    "        detach_base=False,\n",
    "        binary = True,\n",
    "        full_replay = True,\n",
    "        collect_tsne_data=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8a1c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "domains = df['domain'].unique()\n",
    "domain_to_idx = {d: i for i, d in enumerate(domains)}\n",
    "\n",
    "testing_scenarios = {\n",
    "    'pretrained_simple': ('pretrained', 'simple', '3linear', False), \n",
    "    'pretrained_special': ('pretrained', 'special', '3linear', False),\n",
    "    '3conv_simple': ('3conv', 'simple', '3linear', True),\n",
    "    '3conv_special': ('3conv', 'special', '3linear', True),\n",
    "}\n",
    "\n",
    "for name, (backbone, branch, end, detach_base) in testing_scenarios.items():\n",
    "    print(f\"\\nTesting: {backbone} + {branch} + {end}\")\n",
    "    dual_model = DualBranchCNNNet(backbone_type=backbone, branch_type=branch, end_type=end, batch_norm=True).to(device)\n",
    "    optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "    buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "\n",
    "    def cos_criterion(a, b):\n",
    "        return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "\n",
    "    exp_name = f\"CNN_{name}_dualbranchmodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "    dualbranch_kwargs = {\n",
    "        'mse_criterion': nn.MSELoss(),\n",
    "        'ce_criterion': nn.CrossEntropyLoss(),\n",
    "        'cos_criterion': cos_criterion,\n",
    "        'domain_to_idx': domain_to_idx,\n",
    "        'bce_criterion': nn.BCEWithLogitsLoss()\n",
    "    }\n",
    "    unified_train_loop(\n",
    "        model=dual_model,\n",
    "        domains=domains,\n",
    "        domain_dataloaders=domain_dataloaders,\n",
    "        buffer=buffer,\n",
    "        optimizer=optimizer,\n",
    "        writer=writer,\n",
    "        device=device,\n",
    "        batch_fn=dualbranch_batch,\n",
    "        batch_kwargs=dualbranch_kwargs,\n",
    "        num_epochs=10,\n",
    "        exp_name=exp_name,\n",
    "        gradient_clipping=True,\n",
    "        detach_base=detach_base,\n",
    "        binary = True,\n",
    "        full_replay = True,\n",
    "        collect_tsne_data=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021e4b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "domains = df['domain'].unique()\n",
    "domain_to_idx = {d: i for i, d in enumerate(domains)}\n",
    "\n",
    "testing_scenarios = {\n",
    "    'pretrained_simple_0.25branches': ('pretrained', 'simple', '3linear'), \n",
    "    # '3conv_adversarial': ('3conv', 'adversarial', 'adversarial'),\n",
    "}\n",
    "\n",
    "for name, (backbone, branch, end) in testing_scenarios.items():\n",
    "    print(f\"\\nTesting: {backbone} + {branch} + {end}\")\n",
    "    dual_model = DualBranchCNNNet(backbone_type=backbone, branch_type=branch, end_type=end, batch_norm=True).to(device)\n",
    "    optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "    buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "\n",
    "    def cos_criterion(a, b):\n",
    "        return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "\n",
    "    exp_name = f\"CNN_{name}_dualbranchmodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "    dualbranch_kwargs = {\n",
    "        'mse_criterion': nn.MSELoss(),\n",
    "        'ce_criterion': nn.CrossEntropyLoss(),\n",
    "        'cos_criterion': cos_criterion,\n",
    "        'domain_to_idx': domain_to_idx,\n",
    "        'bce_criterion': nn.BCEWithLogitsLoss()\n",
    "    }\n",
    "    unified_train_loop(\n",
    "        model=dual_model,\n",
    "        domains=domains,\n",
    "        domain_dataloaders=domain_dataloaders,\n",
    "        buffer=buffer,\n",
    "        optimizer=optimizer,\n",
    "        writer=writer,\n",
    "        device=device,\n",
    "        batch_fn=dualbranch_batch,\n",
    "        batch_kwargs=dualbranch_kwargs,\n",
    "        num_epochs=10,\n",
    "        exp_name=exp_name,\n",
    "        gradient_clipping=True,\n",
    "        detach_base=False,\n",
    "        binary = True,\n",
    "        full_replay = True,\n",
    "        collect_tsne_data=False,\n",
    "        loss_params = {'head': 0.5, 'social': 0.25, 'room': 0.25}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585c84d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "domains = df['domain'].unique()\n",
    "domain_to_idx = {d: i for i, d in enumerate(domains)}\n",
    "\n",
    "testing_scenarios = {\n",
    "    # 'pretrained_simple': ('pretrained', 'simple', '3linear'), \n",
    "    '3conv_adversarial': ('3conv', 'adversarial', 'adversarial'),\n",
    "}\n",
    "\n",
    "for name, (backbone, branch, end) in testing_scenarios.items():\n",
    "    print(f\"\\nTesting: {backbone} + {branch} + {end}\")\n",
    "    fold_history = {}\n",
    "    for fold_num, domain_dataloaders in tqdm(fold_loaders.items()):\n",
    "        dual_model = DualBranchCNNNet(backbone_type=backbone, branch_type=branch, end_type=end, batch_norm=True).to(device)\n",
    "        optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "        buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "\n",
    "        def cos_criterion(a, b):\n",
    "            return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "\n",
    "        exp_name = f\"fold{fold_num}_CNN_{name}_dualbranchmodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "        writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "        dualbranch_kwargs = {\n",
    "            'mse_criterion': nn.MSELoss(),\n",
    "            'ce_criterion': nn.CrossEntropyLoss(),\n",
    "            'cos_criterion': cos_criterion,\n",
    "            'domain_to_idx': domain_to_idx,\n",
    "            'bce_criterion': nn.BCEWithLogitsLoss()\n",
    "        }\n",
    "        history = unified_train_loop(\n",
    "            model=dual_model,\n",
    "            domains=domains,\n",
    "            domain_dataloaders=domain_dataloaders,\n",
    "            buffer=buffer,\n",
    "            optimizer=optimizer,\n",
    "            writer=writer,\n",
    "            device=device,\n",
    "            batch_fn=dualbranch_batch,\n",
    "            batch_kwargs=dualbranch_kwargs,\n",
    "            num_epochs=10,\n",
    "            exp_name=exp_name,\n",
    "            gradient_clipping=True,\n",
    "            detach_base=False,\n",
    "            binary = True,\n",
    "            full_replay = True,\n",
    "            collect_tsne_data=False,\n",
    "            loss_params = {'head': 0.5, 'social': 0.25, 'room': 0.25}\n",
    "        )\n",
    "        fold_history[fold_num] = history\n",
    "    with open(f\"../checkpoints/5foldcrossval_{exp_name}_history.pkl\", \"wb\") as f:\n",
    "        pickle.dump(fold_history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd74e23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "domains = df['domain'].unique()\n",
    "domain_to_idx = {d: i for i, d in enumerate(domains)}\n",
    "\n",
    "\n",
    "dual_model = DualBranchNet_DANN().to(device)\n",
    "optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "\n",
    "def cos_criterion(a, b):\n",
    "    return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "\n",
    "exp_name = f\"DANN_dualbranchmodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "dualbranch_kwargs = {\n",
    "    'mse_criterion': nn.MSELoss(),\n",
    "    'domain_to_idx': domain_to_idx,\n",
    "    'bce_criterion': nn.BCEWithLogitsLoss()\n",
    "}\n",
    "history = unified_train_loop(\n",
    "    model=dual_model,\n",
    "    domains=domains,\n",
    "    domain_dataloaders=domain_dataloaders,\n",
    "    buffer=buffer,\n",
    "    optimizer=optimizer,\n",
    "    writer=writer,\n",
    "    device=device,\n",
    "    batch_fn=dann_batch,\n",
    "    batch_kwargs=dualbranch_kwargs,\n",
    "    num_epochs=10,\n",
    "    exp_name=exp_name,\n",
    "    gradient_clipping=True,\n",
    "    detach_base=False,\n",
    "    binary = True,\n",
    "    full_replay = True,\n",
    "    collect_tsne_data=False,\n",
    "    loss_params = {'head': 1, 'social': 2}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a44c001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "domains = df['domain'].unique()\n",
    "domain_to_idx = {d: i for i, d in enumerate(domains)}\n",
    "\n",
    "domain_dataloaders = {}\n",
    "for domain in domains:\n",
    "    domain_df = df[df['domain'] == domain]\n",
    "    loaders, split_idx = create_dataloaders(domain_df, batch_sizes=(32, 64, 64), resize_img_to=(512,288), seed=SEED, return_splits=True)  #512, 288 # 352,128 #LGR had 128,128 MobileNetv2 had 224, 224\n",
    "    domain_dataloaders[domain] = loaders\n",
    "\n",
    "baseline_model = LGRBaseline().to(device)\n",
    "optimizer = torch.optim.Adam(baseline_model.parameters(), lr=1e-3)\n",
    "buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "\n",
    "exp_name = f\"baselinemodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "baseline_kwargs = {'mse_criterion': nn.MSELoss()}\n",
    "unified_train_loop(\n",
    "    model=baseline_model,\n",
    "    domains=domains,\n",
    "    domain_dataloaders=domain_dataloaders,\n",
    "    buffer=buffer,\n",
    "    optimizer=optimizer,\n",
    "    writer=writer,\n",
    "    device=device,\n",
    "    batch_fn=baseline_batch,\n",
    "    batch_kwargs=baseline_kwargs,\n",
    "    num_epochs=10,\n",
    "    exp_name=exp_name,\n",
    "    loss_params={}\n",
    ")\n",
    "\n",
    "domain_dataloaders = {}\n",
    "for domain in domains:\n",
    "    domain_df = df[df['domain'] == domain]\n",
    "    loaders, split_idx = create_dataloaders(domain_df, batch_sizes=(32, 64, 64), resize_img_to=(256,144), seed=SEED, return_splits=True)  #512, 288 # 352,128 #LGR had 128,128 MobileNetv2 had 224, 224\n",
    "    domain_dataloaders[domain] = loaders\n",
    "\n",
    "testing_scenarios = {\n",
    "    'simple': ('3conv', 'simple', False, 1000), \n",
    "    'simple_buffer05': ('3conv', 'simple', False, 500),\n",
    "    'special': ('3conv', 'special', False, 1000),\n",
    "    'special_bnorm': ('3conv', 'special', True, 1000)\n",
    "}\n",
    "\n",
    "for name, (backbone, branch, batch_norm, buffer_size) in testing_scenarios.items():\n",
    "    print(f\"\\nTesting: {backbone=} {branch=} {batch_norm=} {buffer_size=}\")\n",
    "    dual_model = DualBranchNet_minimal(backbone_type=backbone, branch_type=branch, head_type='3layer', batch_norm=batch_norm).to(device)\n",
    "    optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "    buffer = NaiveRehearsalBuffer(buffer_size=buffer_size)\n",
    "\n",
    "    exp_name = f\"minimal_{name}_dualbranchmodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "    baseline_kwargs = {'mse_criterion': nn.MSELoss()}\n",
    "    unified_train_loop(\n",
    "        model=dual_model,\n",
    "        domains=domains,\n",
    "        domain_dataloaders=domain_dataloaders,\n",
    "        buffer=buffer,\n",
    "        optimizer=optimizer,\n",
    "        writer=writer,\n",
    "        device=device,\n",
    "        batch_fn=baseline_batch,\n",
    "        batch_kwargs=baseline_kwargs,\n",
    "        num_epochs=10,\n",
    "        exp_name=exp_name,\n",
    "        gradient_clipping=True,\n",
    "        detach_base=False,\n",
    "        binary = True,\n",
    "        full_replay = True,\n",
    "        collect_tsne_data=False,\n",
    "        loss_params={}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ebee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "domains = df['domain'].unique()\n",
    "domain_to_idx = {d: i for i, d in enumerate(domains)}\n",
    "\n",
    "testing_scenarios = {\n",
    "    # 'dualbranch_CNN_1epoch': (DualBranchCNNNet('3conv', 'simple', 'simple'), 500, 1), \n",
    "    'minimal_absurd_buff500': (DualBranchNet_minimal(backbone_type='absurd', branch_type='absurd', head_type='absurd'), 500, 10),\n",
    "}\n",
    "\n",
    "for name, (model, buffer_size, epochs) in testing_scenarios.items():\n",
    "    print(f\"\\nTesting: {name}\")\n",
    "    dual_model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "    buffer = NaiveRehearsalBuffer(buffer_size=buffer_size)\n",
    "\n",
    "    exp_name = f\"{name}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "    def cos_criterion(a, b):\n",
    "        return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "    \n",
    "    baseline_kwargs = {'mse_criterion': nn.MSELoss()}\n",
    "    dualbranch_kwargs = {\n",
    "            'mse_criterion': nn.MSELoss(),\n",
    "            'ce_criterion': nn.CrossEntropyLoss(),\n",
    "            'cos_criterion': cos_criterion,\n",
    "            'domain_to_idx': domain_to_idx,\n",
    "            'bce_criterion': nn.BCEWithLogitsLoss()\n",
    "        }\n",
    "    \n",
    "    unified_train_loop(\n",
    "        model=dual_model,\n",
    "        domains=domains,\n",
    "        domain_dataloaders=domain_dataloaders,\n",
    "        buffer=buffer,\n",
    "        optimizer=optimizer,\n",
    "        writer=writer,\n",
    "        device=device,\n",
    "        batch_fn=baseline_batch,\n",
    "        batch_kwargs=dualbranch_kwargs,\n",
    "        num_epochs=epochs,\n",
    "        exp_name=exp_name,\n",
    "        gradient_clipping=True,\n",
    "        detach_base=False,\n",
    "        binary = True,\n",
    "        full_replay = True,\n",
    "        collect_tsne_data=False,\n",
    "        loss_params={}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24627314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "domains = df['domain'].unique()\n",
    "domain_to_idx = {d: i for i, d in enumerate(domains)}\n",
    "\n",
    "testing_scenarios = {\n",
    "    'DANN_notrain1dom': (DualBranchNet_DANN(), 500, 10, 1)\n",
    "}\n",
    "\n",
    "for name, (model, buffer_size, epochs, alpha) in testing_scenarios.items():\n",
    "    print(f\"\\nTesting: {name}\")\n",
    "    dual_model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "    buffer = NaiveRehearsalBuffer(buffer_size=buffer_size)\n",
    "\n",
    "    exp_name = f\"{name}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    writer = None #SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "    def cos_criterion(a, b):\n",
    "        return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "    \n",
    "    dualbranch_kwargs = {\n",
    "            'mse_criterion': nn.MSELoss(),\n",
    "            'ce_criterion': nn.CrossEntropyLoss(),\n",
    "            'cos_criterion': cos_criterion,\n",
    "            'domain_to_idx': domain_to_idx,\n",
    "            'bce_criterion': nn.BCEWithLogitsLoss(),\n",
    "            'alpha': alpha,\n",
    "        }\n",
    "    \n",
    "    unified_train_loop(\n",
    "        model=dual_model,\n",
    "        domains=domains,\n",
    "        domain_dataloaders=domain_dataloaders,\n",
    "        buffer=buffer,\n",
    "        optimizer=optimizer,\n",
    "        writer=writer,\n",
    "        device=device,\n",
    "        batch_fn=dann_batch,\n",
    "        batch_kwargs=dualbranch_kwargs,\n",
    "        num_epochs=epochs,\n",
    "        exp_name=exp_name,\n",
    "        gradient_clipping=True,\n",
    "        detach_base=False,\n",
    "        binary = True,\n",
    "        full_replay = True,\n",
    "        collect_tsne_data=False,\n",
    "        loss_params={'head':0.5, 'social':0.5}\n",
    "    )\n",
    "\n",
    "testing_scenarios = {\n",
    "    'dualbranch_CNN_1epoch': (DualBranchCNNNet(backbone_type='3conv', branch_type='simple', end_type='3linear'), 500, 1, 1), \n",
    "    'dualbranch_CNN_dynamicalpha': (DualBranchCNNNet(backbone_type='3conv', branch_type='simple', end_type='3linear'), 500, 10, 0), \n",
    "}\n",
    "\n",
    "for name, (model, buffer_size, epochs, alpha) in testing_scenarios.items():\n",
    "    print(f\"\\nTesting: {name}\")\n",
    "    dual_model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "    buffer = NaiveRehearsalBuffer(buffer_size=buffer_size)\n",
    "\n",
    "    exp_name = f\"{name}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    writer = None #SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "    def cos_criterion(a, b):\n",
    "        return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "    \n",
    "    dualbranch_kwargs = {\n",
    "            'mse_criterion': nn.MSELoss(),\n",
    "            'ce_criterion': nn.CrossEntropyLoss(),\n",
    "            'cos_criterion': cos_criterion,\n",
    "            'domain_to_idx': domain_to_idx,\n",
    "            'bce_criterion': nn.BCEWithLogitsLoss(),\n",
    "            'alpha': alpha,\n",
    "        }\n",
    "    \n",
    "    unified_train_loop(\n",
    "        model=dual_model,\n",
    "        domains=domains,\n",
    "        domain_dataloaders=domain_dataloaders,\n",
    "        buffer=buffer,\n",
    "        optimizer=optimizer,\n",
    "        writer=writer,\n",
    "        device=device,\n",
    "        batch_fn=dualbranch_batch,\n",
    "        batch_kwargs=dualbranch_kwargs,\n",
    "        num_epochs=epochs,\n",
    "        exp_name=exp_name,\n",
    "        gradient_clipping=True,\n",
    "        detach_base=False,\n",
    "        binary = True,\n",
    "        full_replay = True,\n",
    "        collect_tsne_data=False,\n",
    "        loss_params={'head':1, 'social':1, 'room':1}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f72631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "domains = df['domain'].unique()\n",
    "domain_to_idx = {d: i for i, d in enumerate(domains)}\n",
    "\n",
    "testing_scenarios = {\n",
    "    '3conv_simple_simple_bnorm_nogradclip': (DualBranchCNNNet(backbone_type='3conv', branch_type='simple', end_type='simple', batch_norm=True), 500, 10, 1, False), \n",
    "    '3conv_simple_simple_nogradclip': (DualBranchCNNNet(backbone_type='3conv', branch_type='simple', end_type='simple', batch_norm=False), 500, 10, 1, False), \n",
    "    '3conv_simple_simple_bnorm': (DualBranchCNNNet(backbone_type='3conv', branch_type='simple', end_type='simple', batch_norm=True), 500, 10, 1, True),\n",
    "    '3conv_simple_3linear_bnorm_nogradclip': (DualBranchCNNNet(backbone_type='3conv', branch_type='simple', end_type='simple', batch_norm=True), 500, 10, 1, False),\n",
    "}\n",
    "\n",
    "for name, (model, buffer_size, epochs, alpha, gradient_clip) in testing_scenarios.items():\n",
    "    print(f\"\\nTesting: {name}\")\n",
    "    dual_model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "    buffer = NaiveRehearsalBuffer(buffer_size=buffer_size)\n",
    "\n",
    "    exp_name = f\"{name}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    writer = None #SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "    def cos_criterion(a, b):\n",
    "        return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "    \n",
    "    dualbranch_kwargs = {\n",
    "            'mse_criterion': nn.MSELoss(),\n",
    "            'ce_criterion': nn.CrossEntropyLoss(),\n",
    "            'cos_criterion': cos_criterion,\n",
    "            'domain_to_idx': domain_to_idx,\n",
    "            'bce_criterion': nn.BCEWithLogitsLoss(),\n",
    "            'alpha': alpha,\n",
    "        }\n",
    "    \n",
    "    unified_train_loop(\n",
    "        model=dual_model,\n",
    "        domains=domains,\n",
    "        domain_dataloaders=domain_dataloaders,\n",
    "        buffer=buffer,\n",
    "        optimizer=optimizer,\n",
    "        writer=writer,\n",
    "        device=device,\n",
    "        batch_fn=dualbranch_batch,\n",
    "        batch_kwargs=dualbranch_kwargs,\n",
    "        num_epochs=epochs,\n",
    "        exp_name=exp_name,\n",
    "        gradient_clipping=gradient_clip,\n",
    "        detach_base=False,\n",
    "        binary = True,\n",
    "        full_replay = True,\n",
    "        collect_tsne_data=False,\n",
    "        loss_params={'head':1, 'social':1, 'room':1}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e197d48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "df = pd.read_pickle(\"../data/pepper_data.pkl\")\n",
    "domain_dataloaders = get_dataloader(df, batch_sizes=(32, 64, 64), resize_img_to=(224,224), return_splits=False, double_img=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "domains = df['domain'].unique()\n",
    "domain_to_idx = {d: i for i, d in enumerate(domains)}\n",
    "\n",
    "testing_scenarios = {\n",
    "    'deeplabv3mobilenetv3_dann': (DANN_classifier_poc(), 500, 30, 0, True),\n",
    "}\n",
    "\n",
    "for name, (model, buffer_size, epochs, alpha, gradient_clip) in testing_scenarios.items():\n",
    "    print(f\"\\nTesting: {name}\")\n",
    "    dual_model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "    buffer = NaiveRehearsalBuffer(buffer_size=buffer_size)\n",
    "\n",
    "    exp_name = f\"{name}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    writer = None #SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "    def cos_criterion(a, b):\n",
    "        return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "    \n",
    "    dualbranch_kwargs = {\n",
    "            'mse_criterion': nn.MSELoss(),\n",
    "            'ce_criterion': nn.CrossEntropyLoss(),\n",
    "            'cos_criterion': cos_criterion,\n",
    "            'domain_to_idx': domain_to_idx,\n",
    "            'bce_criterion': nn.BCEWithLogitsLoss(),\n",
    "            'alpha': alpha,\n",
    "        }\n",
    "    \n",
    "    unified_train_loop(\n",
    "        model=dual_model,\n",
    "        domains=domains,\n",
    "        domain_dataloaders=domain_dataloaders,\n",
    "        buffer=buffer,\n",
    "        optimizer=optimizer,\n",
    "        writer=writer,\n",
    "        device=device,\n",
    "        batch_fn=dann_batch,\n",
    "        batch_kwargs=dualbranch_kwargs,\n",
    "        num_epochs=epochs,\n",
    "        exp_name=exp_name,\n",
    "        gradient_clipping=gradient_clip,\n",
    "        detach_base=False,\n",
    "        binary = True,\n",
    "        full_replay = True,\n",
    "        collect_tsne_data=True,\n",
    "        loss_params={'head':1, 'social':1}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce30b78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#didit work, the architecture is flawed. Assesing category of features based on catastrophic forgetting makes no sense, \n",
    "# the features are not experiencing CF, the weights are. \n",
    "# But passing weights to split branches is not justified.\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "domains = df['domain'].unique()\n",
    "domain_to_idx = {d: i for i, d in enumerate(domains)}\n",
    "\n",
    "df = pd.read_pickle(\"../data/pepper_data.pkl\")\n",
    "domain_dataloaders = get_dataloader(df, batch_sizes=(32, 64, 64), resize_img_to=(224,224), return_splits=False, double_img=False)\n",
    "\n",
    "# CORRECTED: Initialize model with proper parameter names\n",
    "cf_model = CatastrophicForgettingDisentanglementModel(\n",
    "    backbone_output_channels=640,\n",
    "    branch_hidden_channels=256,\n",
    "    branch_output_channels=128,\n",
    "    num_outputs=9\n",
    ").to(device)\n",
    "\n",
    "# CORRECTED: Optimizers with proper parameter paths\n",
    "main_optimizer = torch.optim.Adam([\n",
    "    {'params': cf_model.forgetting_adapter.adapter.parameters()},\n",
    "    {'params': cf_model.branch_forgetting.parameters()},\n",
    "    {'params': cf_model.branch_not_forgetting.parameters()},\n",
    "    {'params': cf_model.head.parameters()},\n",
    "    {'params': cf_model.fusion.parameters()}\n",
    "], lr=1e-3)\n",
    "\n",
    "gating_optimizer = torch.optim.Adam(\n",
    "    cf_model.forgetting_adapter.gating.parameters(),\n",
    "    lr=1e-4\n",
    ")\n",
    "\n",
    "# restart = {\n",
    "# 'global_step':\n",
    "# 'history':\n",
    "# 'domain':\n",
    "# }\n",
    "\n",
    "# Use your existing buffer and data\n",
    "buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "\n",
    "# Modified batch kwargs for our model\n",
    "cf_kwargs = {\n",
    "    'mse_criterion': nn.MSELoss(),\n",
    "    'domain_to_idx': domain_to_idx,\n",
    "}\n",
    "\n",
    "# Run training with corrected functions\n",
    "exp_name = f\"forgetinggated_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "\n",
    "history = catastrophic_forgetting_train_loop(\n",
    "    model=cf_model,\n",
    "    domains=domains,\n",
    "    domain_dataloaders=domain_dataloaders,\n",
    "    buffer=buffer,\n",
    "    optimizer=main_optimizer,\n",
    "    gating_optimizer=gating_optimizer,\n",
    "    device=device,\n",
    "    batch_fn=catastrophic_forgetting_batch,\n",
    "    batch_kwargs=cf_kwargs,\n",
    "    num_epochs=10,\n",
    "    exp_name=exp_name,\n",
    "    gradient_clipping=True,\n",
    "    loss_params={'main': 1.0, 'adapter': 0.5, 'gating': 0.1},\n",
    "    restart = restart\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42881614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "df = pd.read_pickle(\"../data/pepper_data.pkl\")\n",
    "domain_dataloaders = get_dataloader(df, batch_sizes=(32, 64, 64), resize_img_to=(288,512), return_splits=False, double_img=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "domains = df['domain'].unique()\n",
    "domain_to_idx = {d: i for i, d in enumerate(domains)}\n",
    "\n",
    "testing_scenarios = {\n",
    "    # 'dann_mobilenet': (DualBranchNet_DANN(backbone_type='mobilenet'), 500, 10, 0, False, dann_batch),\n",
    "    # 'dual_2conv_adversarial_3linear_detach': (DualBranchCNNNet(9,6,'2conv', 'adversarial', '3linear'), 500, 10, 0, True, dualbranch_batch),\n",
    "    # 'dual_mobilenet_simple_3linear': (DualBranchCNNNet(9,6,'pretrained', 'simple', '3linear'), 500, 10, 0, False, dualbranch_batch),\n",
    "    # 'dual_mobilenet_linear_simple': (DualBranchCNNNet(9,6,'pretrained', 'linear', 'simple'), 500, 10, 0, False, dualbranch_batch),\n",
    "    'baseline': (LGRBaseline(), 500, 10, 0, False, baseline_batch)\n",
    "}\n",
    "\n",
    "for name, (model, buffer_size, epochs, alpha, detach_base, batch_fn) in testing_scenarios.items():\n",
    "    print(f\"\\nTesting: {name}\")\n",
    "    dual_model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "    buffer = NaiveRehearsalBuffer(buffer_size=buffer_size)\n",
    "\n",
    "    exp_name = f\"{name}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    writer = None\n",
    "\n",
    "    def cos_criterion(a, b):\n",
    "        return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "    \n",
    "    dualbranch_kwargs = {\n",
    "            'mse_criterion': nn.MSELoss(),\n",
    "            'ce_criterion': nn.CrossEntropyLoss(),\n",
    "            'cos_criterion': cos_criterion,\n",
    "            'domain_to_idx': domain_to_idx,\n",
    "            'bce_criterion': nn.BCEWithLogitsLoss(),\n",
    "            'alpha': alpha,\n",
    "        }\n",
    "    \n",
    "    unified_train_loop(\n",
    "        model=dual_model,\n",
    "        domains=domains,\n",
    "        domain_dataloaders=domain_dataloaders,\n",
    "        buffer=buffer,\n",
    "        optimizer=optimizer,\n",
    "        writer=writer,\n",
    "        device=device,\n",
    "        batch_fn=batch_fn,\n",
    "        batch_kwargs=dualbranch_kwargs,\n",
    "        num_epochs=epochs,\n",
    "        exp_name=exp_name,\n",
    "        gradient_clipping=True,\n",
    "        detach_base=detach_base,\n",
    "        binary = True,\n",
    "        full_replay = True,\n",
    "        collect_tsne_data=False,\n",
    "        loss_params={'head': 1, 'social': 1, 'room': 0.5}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df559160",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../data/pepper_data.pkl\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "domains = df['domain'].unique()\n",
    "domain_to_idx = {d: i for i, d in enumerate(domains)}\n",
    "\n",
    "domain_dataloaders = get_dataloader(df, batch_sizes=(32, 64, 64), resize_img_to=(288,512), return_splits=False, double_img=False)\n",
    "\n",
    "testing_scenarios = {\n",
    "    # 'dann_mobilenet_buff500': (DualBranchNet_DANN(backbone_type='mobilenet'), 500, 10, 0, False, dann_batch),\n",
    "    'dann_mobilenet_buff120': (DualBranchNet_DANN(backbone_type='mobilenet'), 120, 10, 0, False, dann_batch),\n",
    "    # 'dual_2conv_adversarial_3linear_detach_buff500': (DualBranchCNNNet(9,6,'2conv', 'adversarial', '3linear'), 500, 10, 0, True, dualbranch_batch),\n",
    "    # 'dual_2conv_adversarial_3linear_detach_buff120': (DualBranchCNNNet(9,6,'2conv', 'adversarial', '3linear'), 120, 10, 0, True, dualbranch_batch),\n",
    "    # 'dual_mobilenet_simple_3linear_buff500': (DualBranchCNNNet(9,6,'pretrained', 'simple', '3linear'), 500, 10, 0, False, dualbranch_batch),\n",
    "    # 'dual_mobilenet_simple_3linear_buff120': (DualBranchCNNNet(9,6,'pretrained', 'simple', '3linear'), 120, 10, 0, False, dualbranch_batch),\n",
    "    # 'dual_mobilenet_linear_simple_buff120': (DualBranchCNNNet(9,6,'pretrained', 'linear', 'simple'), 120, 10, 0, False, dualbranch_batch),\n",
    "    # 'baseline_buff500': (LGRBaseline(), 500, 10, 0, False, baseline_batch),\n",
    "    # 'baseline_buff120': (LGRBaseline(), 120, 10, 0, False, baseline_batch)\n",
    "}\n",
    "\n",
    "for name, (model, buffer_size, epochs, alpha, detach_base, batch_fn) in testing_scenarios.items():\n",
    "    print(f\"\\nTesting: {name}\")\n",
    "    dual_model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "    buffer = NaiveRehearsalBuffer(buffer_size=buffer_size)\n",
    "\n",
    "    exp_name = f\"{name}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    writer = None\n",
    "\n",
    "    def cos_criterion(a, b):\n",
    "        return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "    \n",
    "    dualbranch_kwargs = {\n",
    "            'mse_criterion': nn.MSELoss(),\n",
    "            'ce_criterion': nn.CrossEntropyLoss(),\n",
    "            'cos_criterion': cos_criterion,\n",
    "            'domain_to_idx': domain_to_idx,\n",
    "            'bce_criterion': nn.BCEWithLogitsLoss(),\n",
    "            'alpha': alpha,\n",
    "        }\n",
    "    \n",
    "    unified_train_loop(\n",
    "        model=dual_model,\n",
    "        domains=domains,\n",
    "        domain_dataloaders=domain_dataloaders,\n",
    "        buffer=buffer,\n",
    "        optimizer=optimizer,\n",
    "        writer=writer,\n",
    "        device=device,\n",
    "        batch_fn=batch_fn,\n",
    "        batch_kwargs=dualbranch_kwargs,\n",
    "        num_epochs=epochs,\n",
    "        exp_name=exp_name,\n",
    "        gradient_clipping=True,\n",
    "        detach_base=detach_base,\n",
    "        binary = True,\n",
    "        full_replay = True,\n",
    "        collect_tsne_data=False,\n",
    "        loss_params={'head': 1, 'social': 1, 'room': 0.5}\n",
    "    )\n",
    "\n",
    "# import subprocess\n",
    "\n",
    "# model_names = [\n",
    "#     'dann_mobilenet_buff500',\n",
    "#     'dann_mobilenet_buff120',\n",
    "#     'dual_2conv_adversarial_3linear_detach_buff500',\n",
    "#     'dual_2conv_adversarial_3linear_detach_buff120',\n",
    "#     'dual_mobilenet_simple_3linear_buff500',\n",
    "#     'dual_mobilenet_simple_3linear_buff120',\n",
    "#     'dual_mobilenet_linear_simple_buff120',\n",
    "#     'baseline_buff500',\n",
    "#     'baseline_buff120'\n",
    "#  ]\n",
    "\n",
    "# for model_name in model_names:\n",
    "#     print(f\"Running {model_name}\")\n",
    "#     result = subprocess.run(\n",
    "#         [\"python\", \"train_models.py\", \"--model_name\", model_name],\n",
    "#         capture_output=True, text=True\n",
    "#     )\n",
    "#     print(result.stdout)\n",
    "#     if result.stderr:\n",
    "#         print(\"Error:\", result.stderr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d2a457",
   "metadata": {},
   "source": [
    "### current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bee674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO tests: retrain the model with\n",
    "# 3 trains averaged\n",
    "# one branch, no mask\n",
    "# top branch + mask\n",
    "# bottom branch + mask\n",
    "# both branches + random masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502be9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "testing_scenarios = {\n",
    "    # 'heuristic_small_env': (DualBranchModel(), [(288,512), (144,256)], False),\n",
    "    # 'heuristic_square_img': (DualBranchModel(), [(224,224)]*2, False),\n",
    "    'heuristic_eval_buffer': (DualBranchModel(), [(288,512)]*2, True)\n",
    "}\n",
    "\n",
    "for name, (model, img_size, eval_buffer) in testing_scenarios.items():\n",
    "\n",
    "    transform_soc = transforms.Compose([\n",
    "        transforms.Resize(img_size[0]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                            std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    transform_env = transforms.Compose([\n",
    "        transforms.Resize(img_size[1]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                            std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    df = pd.read_pickle(\"../data/pepper_data.pkl\")\n",
    "    df['image_path_env'] = df['image_path'].apply(lambda p: str(Path('../data/masked/environment') / Path(p).name))\n",
    "    df['image_path_social'] = df['image_path'].apply(lambda p: str(Path('../data/masked/social') / Path(p).name))\n",
    "    domain_dataloaders = get_dataloader(df, batch_sizes=(16, 64, 64), return_splits=False, double_img=True, transforms=[transform_soc, transform_env], num_workers=0)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    domains = df['domain'].unique()\n",
    "    domain_to_idx = {d: i for i, d in enumerate(domains)}\n",
    "\n",
    "\n",
    "    print(f\"\\nTesting: {name}\")\n",
    "    dual_model = model.to(device)\n",
    "    # optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "    optimizer = optim.Adam([\n",
    "        {'params': dual_model.social_branch.parameters()},\n",
    "        {'params': dual_model.env_branch.parameters()},\n",
    "        {'params': dual_model.head.parameters()},\n",
    "    ], lr=1e-3)\n",
    "    classifier_optimizer = optim.Adam([ \n",
    "        {'params': dual_model.social_classifier.parameters()},\n",
    "        {'params': dual_model.env_classifier.parameters()}\n",
    "    ], lr=1e-3)\n",
    "\n",
    "    buffer = NaiveRehearsalBuffer(buffer_size=120)\n",
    "    if eval_buffer:\n",
    "        eval_buffer = NaiveRehearsalBuffer(buffer_size=120)\n",
    "\n",
    "    exp_name = f\"{name}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    writer = None\n",
    "\n",
    "    def cos_criterion(a, b):\n",
    "        return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "    \n",
    "    dualbranch_kwargs = {\n",
    "            'mse_criterion': nn.MSELoss(),\n",
    "            'ce_criterion': nn.CrossEntropyLoss(),\n",
    "            'cos_criterion': cos_criterion,\n",
    "            'domain_to_idx': domain_to_idx,\n",
    "            'bce_criterion': nn.BCEWithLogitsLoss(),\n",
    "            'alpha': 0,\n",
    "            'class_optimizer': classifier_optimizer\n",
    "        }\n",
    "    \n",
    "    unified_train_loop(\n",
    "        model=dual_model,\n",
    "        domains=domains,\n",
    "        domain_dataloaders=domain_dataloaders,\n",
    "        buffer=buffer,\n",
    "        optimizer=optimizer,\n",
    "        writer=writer,\n",
    "        device=device,\n",
    "        batch_fn=heuristic_dualbranch_batch,\n",
    "        batch_kwargs=dualbranch_kwargs,\n",
    "        num_epochs=10,\n",
    "        exp_name=exp_name,\n",
    "        gradient_clipping=True,\n",
    "        detach_base=False,\n",
    "        binary = True,\n",
    "        full_replay = True,\n",
    "        collect_tsne_data=False,\n",
    "        loss_params={'head': 1, 'social': 1, 'room': 0.5},\n",
    "        eval_buffer=eval_buffer\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434c4ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "model_names = [\n",
    "    'heuristic_small_env',\n",
    "    'heuristic_square_img',\n",
    "    'heuristic_eval_buffer'\n",
    "]\n",
    "\n",
    "for model_name in model_names:\n",
    "    print(f\"Running {model_name}\")\n",
    "    process = subprocess.Popen(\n",
    "        [\"python\", \"train_models.py\", \"--model_name\", model_name, \"--num_workers\", \"0\"],\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        text=True\n",
    "    )\n",
    "\n",
    "    for line in process.stdout:\n",
    "        print(line, end='')\n",
    "\n",
    "    process.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36adb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ideas for potential ways to combine networks\n",
    "# residual = SpecificHead(base + invariant_feats)\n",
    "# specific_feats = invariant_feats + residual\n",
    "\n",
    "# gate = GateNet(base + invariant_feats)\n",
    "# residual = SpecificHead(base)\n",
    "# specific_feats = invariant_feats + gate * residual\n",
    "\n",
    "# residual = Attention(invariant_feats, base)\n",
    "# specific_feats = invariant_feats + residual\n",
    "\n",
    "# gamma, beta = SpecificHead(base)\n",
    "# specific_feats = gamma * invariant_feats + beta\n",
    "\n",
    "# invariant_feats = InvariantHead(base)\n",
    "# specific_feats = SpecificHead(base)\n",
    "# cos_sim(invariant_feats, specific_feats) ~ 0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "socialsense",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
