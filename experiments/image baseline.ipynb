{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d72ee38c",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2560ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "DATASET_DIR = (Path(\"..\") / \"..\" / \"datasets\").resolve()\n",
    "DATASETS = [\"OFFICE-MANNERSDB\", \"MANNERSDBPlus\"]\n",
    "LABEL_COLS = [\n",
    "    \"Vaccum Cleaning\", \"Mopping the Floor\", \"Carry Warm Food\",\n",
    "    \"Carry Cold Food\", \"Carry Drinks\", \"Carry Small Objects\",\n",
    "    \"Carry Large Objects\", \"Cleaning\", \"Starting a conversation\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9da04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv(csv_path, dataset):\n",
    "    \"\"\"Process individual CSV files\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = df.drop(columns=df.columns[-1])\n",
    "    \n",
    "    # Extract metadata from first column\n",
    "    first_col = df.columns[0]\n",
    "    split_data = df[first_col].str.split('_', n=2, expand=True)\n",
    "    \n",
    "    df[\"robot\"] = split_data[0]\n",
    "    df[\"domain\"] = split_data[1]\n",
    "    df[\"image_ref\"] = split_data[2].astype(int)\n",
    "    df[\"dataset\"] = dataset\n",
    "\n",
    "    df = df.drop(columns=[first_col])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def consolidate_data(datasets):\n",
    "    \"\"\"Aggregate all CSVs\"\"\"\n",
    "    all_dfs = []\n",
    "    for dataset in datasets:\n",
    "        source_path = DATASET_DIR / dataset\n",
    "        \n",
    "        for robot in [\"NAO\", \"Pepper\", \"PR2\"]:\n",
    "            ann_dir = source_path / robot / \"Annotations\"\n",
    "            if not ann_dir.exists():\n",
    "                raise ValueError(f\"Labels csv file path ({ann_dir}) doesn't exist\")\n",
    "                \n",
    "            \n",
    "            for csv_file in ann_dir.glob(\"*.csv\"):\n",
    "                try:\n",
    "                    df = process_csv(csv_file, dataset)\n",
    "                    all_dfs.append(df)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {csv_file}: {str(e)}\")\n",
    "    \n",
    "    df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53657ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_raw_data(df):\n",
    "    \"\"\"Comprehensive data quality checks for raw annotation data\"\"\"\n",
    "    required_columns = {'robot', 'domain', 'image_ref', 'dataset'}\n",
    "\n",
    "    # Check for any missing columns\n",
    "    missing_cols = required_columns - set(df.columns)\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "\n",
    "    # Label value validation (should be between 1 and 5)\n",
    "    for col in LABEL_COLS:\n",
    "        if df[col].min() < 1 or df[col].max() > 5:\n",
    "            raise ValueError(f\"Label {col} has invalid range [{df[col].min()}, {df[col].max()}]\")\n",
    "\n",
    "    # Null values check\n",
    "    null_cols = df.columns[df.isnull().any()].tolist()\n",
    "    if null_cols:\n",
    "        raise ValueError(f\"Null values found in columns: {null_cols}\")\n",
    "\n",
    "    # Data type and value validation for image_ref\n",
    "    if not pd.api.types.is_integer_dtype(df['image_ref']):\n",
    "        raise TypeError(\"image_ref must be integer type\")\n",
    "    if (df['image_ref'] < 0).any():\n",
    "        raise ValueError(\"image_ref contains negative values, which is invalid\")\n",
    "\n",
    "    # Categorical value validation\n",
    "    valid_robots = {'NAO', 'Pepper', 'PR2'}\n",
    "    invalid_robots = set(df['robot']) - valid_robots\n",
    "    if invalid_robots:\n",
    "        raise ValueError(f\"Invalid robot values: {invalid_robots}\")\n",
    "\n",
    "    valid_sources = {'OFFICE-MANNERSDB', 'MANNERSDBPlus'}\n",
    "    invalid_sources = set(df['dataset']) - valid_sources\n",
    "    if invalid_sources:\n",
    "        raise ValueError(f\"Invalid source directories: {invalid_sources}\")\n",
    "\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb45d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_labels(df):\n",
    "    \"\"\"Aggregate multiple annotations per image by image path\"\"\"    \n",
    "    agg_dict = {\n",
    "        **{col: 'mean' for col in LABEL_COLS},\n",
    "        **{col: 'first' for col in df.columns.difference(LABEL_COLS).tolist()},\n",
    "    }\n",
    "    \n",
    "    return df.groupby('image_path', as_index=False).agg(agg_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e53d64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_image_path(row):\n",
    "    \"\"\"Robust path resolution with validation\"\"\"\n",
    "    base_dir = DATASET_DIR / row['dataset'] / row['robot'] / \"Images\"\n",
    "    \n",
    "    if row['dataset'] == \"OFFICE-MANNERSDB\":\n",
    "        target = base_dir / f\"{row['domain']}_{row['image_ref']}.png\"\n",
    "    else:\n",
    "        target = next(base_dir.glob(f\"{row['image_ref']}_*.png\"), None)\n",
    "    \n",
    "    if target and target.exists():\n",
    "        return str(target.resolve())\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37acfe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageLabelDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, torch.Tensor):\n",
    "            idx = idx.item()\n",
    "            \n",
    "        img_path = str(self.df.at[idx, \"image_path\"])\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error loading {img_path}: {str(e)}\")\n",
    "        \n",
    "        raw_labels = self.df.iloc[idx][LABEL_COLS].values.astype(np.float32)\n",
    "        scaled_labels = (raw_labels - 1) / 4  # Convert 1-5 → 0-1\n",
    "        domain_labels = self.df.at[idx, 'domain']\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, torch.from_numpy(scaled_labels), domain_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f915a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(df, batch_sizes=(32, 64, 64), resize_img_to=(128, 128)):\n",
    "    \"\"\"Create train/val/test dataloaders using image_path as unique key\"\"\"\n",
    "    \n",
    "    # Get image paths as indexing for split\n",
    "    unique_images = df[['image_path']].reset_index(drop=True)\n",
    "    \n",
    "    # Split using image_path as key #TODO is is spliting based on index or path strings? index faster\n",
    "    train_paths, temp_paths = train_test_split(\n",
    "        unique_images['image_path'], \n",
    "        test_size=0.3, \n",
    "        random_state=42\n",
    "    )\n",
    "    val_paths, test_paths = train_test_split(\n",
    "        temp_paths,\n",
    "        test_size=0.5, \n",
    "        random_state=42\n",
    "    )\n",
    "   \n",
    "    # Create subsets\n",
    "    train_df = df[df['image_path'].isin(train_paths)].reset_index(drop=True)\n",
    "    val_df = df[df['image_path'].isin(val_paths)].reset_index(drop=True)\n",
    "    test_df = df[df['image_path'].isin(test_paths)].reset_index(drop=True)\n",
    "    \n",
    "    #TODO add coordinate values for spacialy aware CNN Uber's CoordNav\n",
    "    # Define transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(resize_img_to),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                            std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = ImageLabelDataset(train_df, transform)\n",
    "    val_dataset = ImageLabelDataset(val_df, transform)\n",
    "    test_dataset = ImageLabelDataset(test_df, transform)\n",
    "    \n",
    "    # Create loaders\n",
    "    num_workers = 0\n",
    "    loaders = {\n",
    "        'train': DataLoader(train_dataset, batch_size=batch_sizes[0], shuffle=True, num_workers=num_workers, pin_memory=torch.cuda.is_available()),\n",
    "        'val': DataLoader(val_dataset, batch_size=batch_sizes[1], shuffle=False, num_workers=num_workers, pin_memory=torch.cuda.is_available()),\n",
    "        'test': DataLoader(test_dataset, batch_size=batch_sizes[2], shuffle=False, num_workers=num_workers, pin_memory=torch.cuda.is_available())\n",
    "    }\n",
    "    \n",
    "    return loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9668e590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_final_data(df):\n",
    "    \"\"\"Final validation after aggregation\"\"\"\n",
    "    # Missing image paths\n",
    "    missing = df[df['image_path'].isnull()]\n",
    "    if not missing.empty:\n",
    "        raise FileNotFoundError(\n",
    "            f\"{len(missing)} images missing after aggregation. Examples:\\n\"\n",
    "            f\"{missing[['robot', 'domain', 'image_ref']].head()}\"\n",
    "        )\n",
    "    \n",
    "    # Null values check\n",
    "    null_cols = df.columns[df.isnull().any()].tolist()\n",
    "    if null_cols:\n",
    "        raise ValueError(f\"Null values found in columns: {null_cols}\")\n",
    "\n",
    "    # Duplicate image paths\n",
    "    duplicates = df[df.duplicated('image_path', keep=False)]\n",
    "    if not duplicates.empty:\n",
    "        raise RuntimeError(\n",
    "            f\"Duplicate image paths after aggregation:\\n\"\n",
    "            f\"{duplicates['image_path'].unique()}\"\n",
    "        )\n",
    "\n",
    "    # Label validity (1-5)\n",
    "    for col in LABEL_COLS:\n",
    "        if df[col].min() < 1 or df[col].max() > 5:\n",
    "            raise ValueError(\n",
    "                f\"Aggregated label {col} out of range: \"\n",
    "                f\"[{df[col].min()}, {df[col].max()}]\"\n",
    "            )\n",
    "\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfd34a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac2a2a2b",
   "metadata": {},
   "source": [
    "## --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f66130",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    raw_df = consolidate_data(DATASETS)\n",
    "    validate_raw_data(raw_df)\n",
    "    raw_df['image_path'] = raw_df.apply(resolve_image_path, axis=1)   \n",
    "    aggregated_df = aggregate_labels(raw_df)\n",
    "    validate_final_data(aggregated_df) \n",
    "except Exception as e:\n",
    "    print(f\"Pipeline failed: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "aggregated_df.to_pickle(\"../data/processed_all_data.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43ca986",
   "metadata": {},
   "source": [
    "## CL Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b327a539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import random\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Subset, ConcatDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca1a5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SocialContinualModel(nn.Module):\n",
    "    def __init__(self, num_tasks=9):\n",
    "        super().__init__()\n",
    "        # Initialize the ResNet50 architecture with Places365 configuration\n",
    "        self.backbone = models.resnet50(num_classes=365)\n",
    "        \n",
    "        # get Places365 weights and fix their naming leftover from troch saving convention\n",
    "        places365_weights = torch.load('resnet50_places365.pth.tar', weights_only=True)\n",
    "        state_dict = places365_weights['state_dict']\n",
    "        state_dict = {k.replace('module.', ''): v \n",
    "                     for k, v in state_dict.items()}\n",
    "        \n",
    "        # Load weights\n",
    "        self.backbone.load_state_dict(state_dict)\n",
    "        \n",
    "        # Remove classification head\n",
    "        self.backbone.fc = nn.Identity()\n",
    "\n",
    "        #Freeze all params except last layer\n",
    "        for name, param in self.backbone.named_parameters():\n",
    "            if 'layer4' not in name:\n",
    "                param.requires_grad_(False)\n",
    "        \n",
    "        #TODO human mask average, std, quadrants, human in realtion to robot std\n",
    "        \n",
    "\n",
    "\n",
    "        # Shared layers #TODO deeper shared space?\n",
    "        self.shared_fc = nn.Sequential(\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        # Task-specific heads with more expensive but finegrained GELU\n",
    "        self.heads = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(1024, 512),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(512, 1),\n",
    "                nn.Sigmoid()\n",
    "            ) for _ in range(num_tasks)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        shared = self.shared_fc(features)\n",
    "        outputs = [head(shared) for head in self.heads]\n",
    "        return torch.cat(outputs, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971efe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "class LGRBaseline(nn.Module):\n",
    "    \"\"\"\n",
    "    @misc{churamani_feature_2024,\n",
    "\t\ttitle = {Feature Aggregation with Latent Generative Replay for Federated Continual Learning of Socially Appropriate Robot Behaviours},\n",
    "\t\turl = {http://arxiv.org/abs/2405.15773},\n",
    "\t\tdoi = {10.48550/arXiv.2405.15773},\n",
    "\t\tnumber = {{arXiv}:2405.15773},\n",
    "\t\tpublisher = {{arXiv}},\n",
    "\t\tauthor = {Churamani, Nikhil and Checker, Saksham and Chiang, Hao-Tien Lewis and Gunes, Hatice},\n",
    "\t\turldate = {2025-01-30},\n",
    "\t\tdate = {2024-03-16},\n",
    "\t}\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=9):\n",
    "        super(LGRBaseline, self).__init__()\n",
    "        \n",
    "        # MobileNetV2 backbone\n",
    "        self.backbone = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1).features\n",
    "        \n",
    "        # Backbone feature processing\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # Regression head\n",
    "        self.fc1_bn = nn.BatchNorm1d(1280)\n",
    "        self.fc2 = nn.Linear(1280, 32)\n",
    "        # self.fc2_bn = nn.BatchNorm1d(128)\n",
    "\t\t# self.fc3 = nn.Linear(128, 32)\n",
    "        self.fc4 = nn.Linear(32, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Feature extraction\n",
    "        x = self.backbone(x)\n",
    "        \n",
    "        # Spatial reduction\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        # Regression\n",
    "        x = self.fc1_bn(x)\n",
    "        x = self.fc2(x)\n",
    "        # x = self.fc2_bn(x)\n",
    "\t\t# x = self.fc3(x)\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return {'output': x}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a7176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "class ReservoirBuffer:\n",
    "    def __init__(self, capacity=1000, replay_ratio=0.2, input_shape=(3, 384, 216), label_shape=(9,), device=torch.device('cpu')):\n",
    "        self.capacity = capacity\n",
    "        self.inputs = torch.empty((capacity, *input_shape), dtype=torch.float32, device=device)\n",
    "        self.labels = torch.empty((capacity, *label_shape), dtype=torch.float32, device=device)\n",
    "        self.domains = [None] * capacity\n",
    "        self.size = 0          # Number of samples currently in buffer\n",
    "        self.num_seen = 0      # Total samples seen\n",
    "        self.replay_ratio = replay_ratio\n",
    "\n",
    "    def add(self, new_samples):\n",
    "        for sample in new_samples:\n",
    "            self.num_seen += 1\n",
    "            if self.size < self.capacity:\n",
    "                idx = self.size\n",
    "                self.size += 1\n",
    "            else:\n",
    "                idx = random.randint(0, self.num_seen - 1)\n",
    "                if idx >= self.capacity:\n",
    "                    continue\n",
    "            self.inputs[idx].copy_(sample[0])\n",
    "            self.labels[idx].copy_(sample[1])\n",
    "            self.domains[idx] = sample[2]\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        if self.size == 0:\n",
    "            return []\n",
    "        indices = torch.randint(0, self.size, (batch_size,))\n",
    "        return [(self.inputs[i], self.labels[i], self.domains[i]) for i in indices]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def get_domain_distribution(self):\n",
    "        return pd.Series(self.domains[:self.size]).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb2f843",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveRehearsalBuffer:\n",
    "    \"\"\"\n",
    "    @inproceedings{Hsu18_EvalCL,\n",
    "        title={Re-evaluating Continual Learning Scenarios: A Categorization and Case for Strong Baselines},\n",
    "        author={Yen-Chang Hsu and Yen-Cheng Liu and Anita Ramasamy and Zsolt Kira},\n",
    "        booktitle={NeurIPS Continual learning Workshop },\n",
    "        year={2018},\n",
    "        url={https://arxiv.org/abs/1810.12488}\n",
    "    }\n",
    "    \"\"\"\n",
    "    def __init__(self, buffer_size=1000):\n",
    "        self.buffer_size = buffer_size\n",
    "        self.domain_buffer = {}\n",
    "\n",
    "    def update_buffer(self, domain, dataset):\n",
    "        # Add/overwrite current domain\n",
    "        self.domain_buffer[domain] = Subset(dataset, torch.arange(len(dataset)))\n",
    "        \n",
    "        # Recalculate quota\n",
    "        num_domains = len(self.domain_buffer)\n",
    "        buffer_quota_per_domain = self.buffer_size // num_domains\n",
    "        \n",
    "        # Reduce all domains (including current)\n",
    "        for domain in self.domain_buffer:\n",
    "            subset = self.domain_buffer[domain]\n",
    "            max_safe_samples_to_overwrite = min(buffer_quota_per_domain, len(subset.dataset))\n",
    "            rand_indices = torch.randperm(len(dataset))[:max_safe_samples_to_overwrite].numpy()\n",
    "            self.domain_buffer[domain] = Subset(dataset, rand_indices)\n",
    "\n",
    "    def get_loader_with_replay(self, current_domain, current_loader):\n",
    "        current_dataset = current_loader.dataset\n",
    "        replay_datasets = [dataset for domain, dataset in self.domain_buffer.items() if domain != current_domain]\n",
    "\n",
    "        #Enforces 1:1 ratio when current ≥ buffer\n",
    "        total_replay = sum(len(dataset) for dataset in replay_datasets)\n",
    "        if total_replay > 0:\n",
    "            K = max(len(current_dataset) // total_replay, 1)\n",
    "            replay_datasets = replay_datasets * K\n",
    "\n",
    "        combined_dataset =  ConcatDataset(replay_datasets + [current_dataset])\n",
    "        combined_dataset = DataLoader(\n",
    "            combined_dataset,\n",
    "            batch_size=current_loader.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=current_loader.num_workers,\n",
    "            pin_memory=current_loader.pin_memory,\n",
    "            drop_last=current_loader.drop_last\n",
    "        )\n",
    "        return combined_dataset\n",
    "    \n",
    "    def get_domain_distribution(self):\n",
    "        \"\"\"Returns {domain: num_samples} without needing Storage\"\"\"\n",
    "        return {domain: len(subset) for domain, subset in self.domain_buffer.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7c71f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientReversalFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        return x\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return -grad_output\n",
    "\n",
    "class GradientReversal(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return GradientReversalFunction.apply(x)\n",
    "\n",
    "\n",
    "class DualBranchNet(nn.Module):\n",
    "    def __init__(self, num_outputs=9, num_domains=6):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1).features\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.feature_dim = 1280\n",
    "\n",
    "        self.invariant = nn.Sequential(\n",
    "            nn.Linear(self.feature_dim, 256),\n",
    "            GradientReversal(),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256)\n",
    "        )\n",
    "\n",
    "        self.domain_classifier = nn.Sequential(\n",
    "            nn.Linear(256, num_domains)\n",
    "        )\n",
    "        \n",
    "        self.specific_residual = nn.Sequential(\n",
    "            nn.Linear(self.feature_dim+256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256)\n",
    "        )\n",
    "        \n",
    "        self.specific_domain_classifier = nn.Sequential(\n",
    "            nn.Linear(256, num_domains)\n",
    "        )\n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_outputs)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        base = self.backbone(x)\n",
    "        base = self.pool(base).view(x.size(0), -1)\n",
    "        \n",
    "        invariant_feats = self.invariant(base)\n",
    "        invariant_domain_pred = self.domain_classifier(invariant_feats)\n",
    "\n",
    "        residual = self.specific_residual(torch.cat([invariant_feats, base], dim=1))\n",
    "        combined = invariant_feats + residual  #How can we modify invaraint features such that when modifyinr is added to those features it produces domain specific features\n",
    "        specific_domain_pred = self.specific_domain_classifier(residual)\n",
    "        # I made mistake, specific_residual should get both image and the invaraint features to then modify them with a signal from the image\n",
    "        #Then the final residual addition produces a final combined feature space\n",
    "        # Stupid to then combine that final (invariant+modifier) with the invariant features  again!\n",
    "        #And also I am training a domain classifier on that final feature space. WTF! the same featuer space has to be invaraitn and specific at the same time, with the addition of a modifier thats just modyfying the existing invariant features. WTF> It has to have something to work with i.e. image\n",
    "        \n",
    "        scores = self.head(combined)      \n",
    "        \n",
    "        return {\n",
    "            'output': scores,\n",
    "            'invariant_domain': invariant_domain_pred,\n",
    "            'specific_domain': specific_domain_pred,\n",
    "            'invariant_feats': invariant_feats,\n",
    "            'specific_feats': residual\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e871f944",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5849e928",
   "metadata": {},
   "source": [
    "## ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79536968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def extract_data_subset(df, robot_name='Pepper'):\n",
    "    # Modify the saving section at the end\n",
    "    # Create the required directory structure\n",
    "    project_root = Path.cwd().parent  # Goes up from experiments/ to project/\n",
    "    data_dir = project_root / \"data\"\n",
    "    images_dir = data_dir / \"images\"\n",
    "\n",
    "    images_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Filter for Pepper first\n",
    "    pepper_df = df[df['robot'] == robot_name].copy()\n",
    "    pepper_df = pepper_df.reset_index(drop=True)\n",
    "\n",
    "    # Copy images and update paths\n",
    "    def copy_and_update_path(row):\n",
    "        src_path = Path(row['image_path'])\n",
    "        dst_path = images_dir / src_path.name\n",
    "        \n",
    "        if not dst_path.exists():\n",
    "            shutil.copy2(src_path, dst_path)\n",
    "        \n",
    "        return str(dst_path.relative_to(project_root))\n",
    "\n",
    "    pepper_df['image_path'] = pepper_df.apply(copy_and_update_path, axis=1)\n",
    "\n",
    "    # Save the filtered dataframe\n",
    "    pepper_df.to_pickle(data_dir / \"pepper_data.pkl\")\n",
    "    return pepper_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965dd01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../data/pepper_data.pkl\")\n",
    "df['image_path'] = '../' + df['image_path']\n",
    "\n",
    "# Create domain-specific dataloaders\n",
    "domains = df['domain'].unique()\n",
    "domain_dataloaders = {}\n",
    "for domain in domains:\n",
    "    domain_df = df[df['domain'] == domain]\n",
    "    #domain_df = domain_df.sample(frac=0.5, random_state=42)\n",
    "    loaders = create_dataloaders(domain_df, batch_sizes=(32, 64, 64), resize_img_to=(128, 128))  #TODO should be (384, 216) to retain scale or (224, 224) for best performance on MobileNet\n",
    "    domain_dataloaders[domain] = loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f961279",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b327ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For LGRBaseline\n",
    "def baseline_batch(model, batch, device, **kwargs):\n",
    "    inputs, labels, _ = batch\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    outputs = model(inputs)['output']\n",
    "    loss = kwargs['mse_criterion'](outputs, labels)\n",
    "    metrics = {}\n",
    "    return loss, metrics\n",
    "\n",
    "# For DualBranchNet\n",
    "def dualbranch_batch(model, batch, device, **kwargs):\n",
    "    inputs, labels, domain_labels = batch\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    domain_to_idx = kwargs['domain_to_idx']\n",
    "    domain_labels = torch.tensor([domain_to_idx[d] for d in domain_labels], device=device)\n",
    "    mse_criterion = kwargs['mse_criterion']\n",
    "    ce_criterion = kwargs['ce_criterion']\n",
    "    cos_criterion = kwargs['cos_criterion']\n",
    "\n",
    "    # Split batch\n",
    "    current_domain = kwargs['current_domain']\n",
    "    current_mask = (domain_labels == domain_to_idx[current_domain])\n",
    "    replay_mask = ~current_mask\n",
    "\n",
    "    # 1. Current samples: update all parameters\n",
    "    if current_mask.any():\n",
    "        inputs_current = inputs[current_mask]\n",
    "        labels_current = labels[current_mask]\n",
    "        domain_labels_current = domain_labels[current_mask]\n",
    "\n",
    "        outputs_current = model(inputs_current)\n",
    "        inv_feats = outputs_current['invariant_feats']\n",
    "        spec_feats = outputs_current['specific_feats']\n",
    "\n",
    "        task_loss = mse_criterion(outputs_current['output'], labels_current)\n",
    "        inv_domain_loss = ce_criterion(outputs_current['invariant_domain'], domain_labels_current)\n",
    "        spec_domain_loss = ce_criterion(outputs_current['specific_domain'], domain_labels_current)\n",
    "        similarity_loss = cos_criterion(inv_feats, spec_feats)\n",
    "        \n",
    "        total_loss = (task_loss +\n",
    "                      0.5 * inv_domain_loss +\n",
    "                      0.2 * spec_domain_loss +\n",
    "                      0.1 * similarity_loss)\n",
    "        \n",
    "        total_loss.backward(retain_graph=True)\n",
    "        \n",
    "        inv_acc = (outputs_current['invariant_domain'].argmax(1) == domain_labels_current).float().mean().item()\n",
    "        spec_acc = (outputs_current['specific_domain'].argmax(1) == domain_labels_current).float().mean().item()\n",
    "    else:\n",
    "        total_loss = torch.tensor(0.0, device=device)\n",
    "        inv_acc = 0.0\n",
    "        spec_acc = 0.0\n",
    "        task_loss = torch.tensor(0.0, device=device)\n",
    "        inv_domain_loss = torch.tensor(0.0, device=device)\n",
    "        spec_domain_loss = torch.tensor(0.0, device=device)\n",
    "        similarity_loss = torch.tensor(0.0, device=device)\n",
    "\n",
    "    # 2. Replay samples: update only specific branch + head\n",
    "    if replay_mask.any():\n",
    "        inputs_replay = inputs[replay_mask]\n",
    "        labels_replay = labels[replay_mask]\n",
    "        domain_labels_replay = domain_labels[replay_mask]\n",
    "\n",
    "        #no_grad, unlike requires_grad=False, detaches all elements from the gradient computation graph\n",
    "        with torch.no_grad():\n",
    "            base_replay = model.backbone(inputs_replay)\n",
    "            base_replay = model.pool(base_replay).flatten(1)\n",
    "            inv_feats_replay = model.invariant(base_replay)\n",
    "\n",
    "        residual = model.specific_residual(torch.cat([inv_feats_replay.detach(), base_replay.detach()], dim=1)) #should the inv_feats be unattached?\n",
    "        combined = inv_feats_replay.detach() + residual\n",
    "        spec_domain_pred = model.specific_domain_classifier(combined)\n",
    "        \n",
    "        scores = model.head(combined)\n",
    "        \n",
    "        task_loss_replay = mse_criterion(scores, labels_replay)\n",
    "        spec_domain_loss_replay = ce_criterion(spec_domain_pred, domain_labels_replay)\n",
    "        total_loss_replay = task_loss_replay + 0.2 * spec_domain_loss_replay\n",
    "        \n",
    "        total_loss_replay.backward()\n",
    "    \n",
    "    metrics = {\n",
    "        'task_loss': task_loss.item(),\n",
    "        'inv_domain': inv_domain_loss.item(),\n",
    "        'spec_domain': spec_domain_loss.item(),\n",
    "        'similarity': similarity_loss.item(),\n",
    "        'inv_acc': inv_acc,\n",
    "        'spec_acc': spec_acc,\n",
    "        'replay_count': replay_mask.sum().item(),\n",
    "        'current_count': current_mask.sum().item()\n",
    "    }\n",
    "    return total_loss, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6df3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, _ in dataloader:\n",
    "\n",
    "            inputs = inputs.to(device, dtype=torch.float32)\n",
    "            labels = labels.to(device, dtype=torch.float32)\n",
    "            outputs = model(inputs)['output']\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            total_samples += inputs.size(0)\n",
    "    return total_loss / total_samples\n",
    "\n",
    "def cross_domain_validation(model, domain_dataloaders, criterion, device):\n",
    "    results = {}\n",
    "    for domain, loaders in domain_dataloaders.items():\n",
    "        val_loader = loaders['val']\n",
    "        val_loss = evaluate_model(model, val_loader, criterion, device)\n",
    "        results[domain] = val_loss\n",
    "    return results\n",
    "\n",
    "def average_metrics(metrics_list):\n",
    "    # metrics_list: list of dicts, each dict contains metrics for a batch\n",
    "    if not metrics_list:\n",
    "        return {}\n",
    "    keys = metrics_list[0].keys()\n",
    "    avg_metrics = {}\n",
    "    for k in keys:\n",
    "        avg_metrics[k] = float(np.mean([m[k] for m in metrics_list if k in m]))\n",
    "    return avg_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcbbc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def unified_train_loop(\n",
    "    model, domains, domain_dataloaders, buffer, optimizer, writer, device,\n",
    "    batch_fn, batch_kwargs, num_epochs=5, exp_name=\"exp\"\n",
    "):\n",
    "    global_step = 0\n",
    "    history = {\n",
    "        'train_epoch_loss': [],\n",
    "        'val_epoch_loss': [],\n",
    "        'train_epoch_metrics': [],\n",
    "        'cross_domain_val': [],\n",
    "    }\n",
    "\n",
    "    for domain_idx, current_domain in enumerate(domains):\n",
    "        train_loader = buffer.get_loader_with_replay(current_domain, domain_dataloaders[current_domain]['train'])\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            epoch_loss = 0.0\n",
    "            samples = 0\n",
    "            batch_metrics_list = []\n",
    "            \n",
    "            # for batch_idx, batch in enumerate(train_loader):\n",
    "            for batch_idx, batch in enumerate(tqdm(train_loader, desc=f\"Domain {current_domain} Epoch {epoch+1}/{num_epochs}\")):\n",
    "                optimizer.zero_grad()\n",
    "                loss, metrics = batch_fn(model, batch, device, **{**batch_kwargs, 'current_domain': current_domain})\n",
    "                optimizer.step()\n",
    "                batch_size = batch[0].size(0)\n",
    "                epoch_loss += loss.item() * batch_size\n",
    "                samples += batch_size\n",
    "                global_step += 1\n",
    "                batch_metrics_list.append(metrics)\n",
    "                # TensorBoard logging (every 10 batches)\n",
    "                if writer and batch_idx % 10 == 0:\n",
    "                    writer.add_scalar(f'{exp_name}/train_loss', loss.item(), global_step)\n",
    "                    for k, v in metrics.items():\n",
    "                        writer.add_scalar(f'{exp_name}/train_{k}', v, global_step)\n",
    "            avg_epoch_loss = epoch_loss / samples\n",
    "            writer.add_scalar(f'{exp_name}/train_epoch_loss', avg_epoch_loss, global_step)\n",
    "            history['train_epoch_loss'].append(avg_epoch_loss)\n",
    "            # Average batch metrics for this epoch\n",
    "            avg_metrics = average_metrics(batch_metrics_list)\n",
    "            history['train_epoch_metrics'].append(avg_metrics)\n",
    "            # Validation on current domain\n",
    "            val_loss = evaluate_model(model, domain_dataloaders[current_domain]['val'], batch_kwargs['mse_criterion'], device)\n",
    "            writer.add_scalar(f'{exp_name}/val_epoch_loss', val_loss, global_step)\n",
    "            history['val_epoch_loss'].append(val_loss)\n",
    "            \n",
    "            # Save model and metrics\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'history': history,\n",
    "            }, f\"../checkpoints/{exp_name}_domain{current_domain}_epoch{epoch}_step{global_step}.pt\")\n",
    "            with open(f\"../checkpoints/{exp_name}_history.pkl\", \"wb\") as f:\n",
    "                pickle.dump(history, f)\n",
    "            # Cross-domain validation (after each domain)\n",
    "            cross_val = cross_domain_validation(model, domain_dataloaders, batch_kwargs['mse_criterion'], device)\n",
    "            history['cross_domain_val'].append(cross_val)\n",
    "        buffer.update_buffer(current_domain, domain_dataloaders[current_domain]['train'].dataset)\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973cdbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "domains = df['domain'].unique()\n",
    "domain_to_idx = {d: i for i, d in enumerate(domains)}\n",
    "\n",
    "# # For baseline model\n",
    "baseline_model = LGRBaseline().to(device)\n",
    "optimizer = torch.optim.Adam(baseline_model.parameters(), lr=1e-3)\n",
    "buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "exp_name = f\"baselinemodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "baseline_kwargs = {'mse_criterion': nn.MSELoss()}\n",
    "unified_train_loop(\n",
    "    model=baseline_model,\n",
    "    domains=domains,\n",
    "    domain_dataloaders=domain_dataloaders,\n",
    "    buffer=buffer,\n",
    "    optimizer=optimizer,\n",
    "    writer=writer,\n",
    "    device=device,\n",
    "    batch_fn=baseline_batch,\n",
    "    batch_kwargs=baseline_kwargs,\n",
    "    num_epochs=10,\n",
    "    exp_name=exp_name\n",
    ")\n",
    "\n",
    "# For DualBranchNet\n",
    "dual_model = DualBranchNet(num_domains=len(domains)).to(device)\n",
    "optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "\n",
    "def cos_criterion(a, b):\n",
    "    return (nn.CosineSimilarity()(a, b) ** 2).mean()\n",
    "\n",
    "exp_name = f\"fixedred_dualbranchmodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "dualbranch_kwargs = {\n",
    "    'mse_criterion': nn.MSELoss(),\n",
    "    'ce_criterion': nn.CrossEntropyLoss(),\n",
    "    'cos_criterion': cos_criterion,\n",
    "    'domain_to_idx': domain_to_idx\n",
    "}\n",
    "unified_train_loop(\n",
    "    model=dual_model,\n",
    "    domains=domains,\n",
    "    domain_dataloaders=domain_dataloaders,\n",
    "    buffer=buffer,\n",
    "    optimizer=optimizer,\n",
    "    writer=writer,\n",
    "    device=device,\n",
    "    batch_fn=dualbranch_batch,\n",
    "    batch_kwargs=dualbranch_kwargs,\n",
    "    num_epochs=10,\n",
    "    exp_name=exp_name\n",
    ")\n",
    "\n",
    "# For DualBranchNet\n",
    "dual_model = DualBranchNet(num_domains=len(domains)).to(device)\n",
    "optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "buffer = NaiveRehearsalBuffer(buffer_size=1000)\n",
    "\n",
    "def cos_criterion(a, b):\n",
    "    return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "\n",
    "\n",
    "exp_name = f\"fixedred_fixedcos_dualbranchmodel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "writer = SummaryWriter(log_dir=f\"../tensorboard/{exp_name}\")\n",
    "\n",
    "dualbranch_kwargs = {\n",
    "    'mse_criterion': nn.MSELoss(),\n",
    "    'ce_criterion': nn.CrossEntropyLoss(),\n",
    "    'cos_criterion': cos_criterion,\n",
    "    'domain_to_idx': domain_to_idx\n",
    "}\n",
    "unified_train_loop(\n",
    "    model=dual_model,\n",
    "    domains=domains,\n",
    "    domain_dataloaders=domain_dataloaders,\n",
    "    buffer=buffer,\n",
    "    optimizer=optimizer,\n",
    "    writer=writer,\n",
    "    device=device,\n",
    "    batch_fn=dualbranch_batch,\n",
    "    batch_kwargs=dualbranch_kwargs,\n",
    "    num_epochs=10,\n",
    "    exp_name=exp_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36adb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ideas for potential ways to combine networks\n",
    "residual = SpecificHead(base + invariant_feats)\n",
    "specific_feats = invariant_feats + residual\n",
    "\n",
    "gate = GateNet(base + invariant_feats)\n",
    "residual = SpecificHead(base)\n",
    "specific_feats = invariant_feats + gate * residual\n",
    "\n",
    "residual = Attention(invariant_feats, base)\n",
    "specific_feats = invariant_feats + residual\n",
    "\n",
    "gamma, beta = SpecificHead(base)\n",
    "specific_feats = gamma * invariant_feats + beta\n",
    "\n",
    "invariant_feats = InvariantHead(base)\n",
    "specific_feats = SpecificHead(base)\n",
    "cos_sim(invariant_feats, specific_feats) ~ 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e848bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# different cos 1-abs fixed residual - fixedred_fixedcos_dualbranchmodel_20250604_014811_history\n",
    "#fixed res but old cosine ^2 - fixedred_dualbranchmodel_20250604_002951_history\n",
    "#broken baseline - baselinemodel_20250603_200948_history\n",
    "# recent dualbranch - dualbranchmodel_20250603_135728_history\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "with open('../checkpoints/fixedred_fixedcos_dualbranchmodel_20250604_014811_history.pkl', 'rb') as f:\n",
    "    history = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8bf879",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f792f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,7))\n",
    "plt.plot(history['train_epoch_loss'], label='Train Loss')\n",
    "plt.plot(history['val_epoch_loss'], label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "# \n",
    "plt.ylim(-0.1, 100)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2374ba06",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = [x for i, x in enumerate(history['cross_domain_val']) if i in [9, 19, 29, 39, 49, 59]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513f9ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1960d6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "# Suppose cross_domain_val is a list of dicts: [{domain1: val1, domain2: val2, ...}, ...]\n",
    "df = pd.DataFrame(filtered)\n",
    "sns.heatmap(df, annot=True, cmap='viridis')\n",
    "plt.xlabel('Evaluated Domain')\n",
    "plt.ylabel('After Training Domain')\n",
    "plt.title('Cross-Domain Validation Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af93c635",
   "metadata": {},
   "outputs": [],
   "source": [
    "history['train_epoch_metrics'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072bf471",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot([m['similarity'] for m in history['train_epoch_metrics']])\n",
    "plt.xticks(np.arange(0, 60, step=1))\n",
    "plt.title('cosine similarity of two branches')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d878b1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "for metric in ['inv_acc', 'spec_acc', 'similarity']:\n",
    "    plt.plot([m[metric] for m in history['train_epoch_metrics']], label=metric)\n",
    "plt.title('Branch accuracies and their similarity')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Metric Value')\n",
    "plt.xticks(np.arange(0, 60, step=1))\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321bd830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [m['spec_domain'] for m in history['train_epoch_metrics']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b02e6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "for metric in ['task_loss', 'inv_domain', 'spec_domain']:\n",
    "    plt.plot([m[metric] for m in history['train_epoch_metrics']], label=metric)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Metric Value')\n",
    "plt.xticks(np.arange(0, 60, step=1))\n",
    "# plt.ylim(-1, 2)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5599bcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "for metric in ['replay_count', 'current_count']:\n",
    "    plt.plot([m[metric] for m in history['train_epoch_metrics']], label=metric)\n",
    "plt.title('Type of samples in batch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Metric Value')\n",
    "plt.xticks(np.arange(0, 60, step=1))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d41c76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6870cd48",
   "metadata": {},
   "source": [
    "## ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895de6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After model output\n",
    "outputs = model(inputs)  # Should be in [1,5]\n",
    "print(f\"Output range: {outputs.min().item()}–{outputs.max().item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2bbea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = LGRBaseline().to(device)\n",
    "test_optimizer = optim.Adam(test_model.parameters(), lr=1e-3)\n",
    "buffer = NaiveRehearsalBuffer(0)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "first_domain = domains[0]\n",
    "train_loader = domain_dataloaders[first_domain]['train']\n",
    "single_batch = next(iter(train_loader))\n",
    "inputs, labels, _ = single_batch\n",
    "inputs = inputs.to(device, dtype=torch.float32)\n",
    "labels = labels.to(device, dtype=torch.float32)\n",
    "\n",
    "# %%\n",
    "num_test_epochs = 400\n",
    "for epoch in range(num_test_epochs):\n",
    "    test_optimizer.zero_grad()\n",
    "\n",
    "    outputs = test_model(inputs)\n",
    "    loss = criterion(outputs['output'], labels)\n",
    "    \n",
    "    loss.backward()\n",
    "    test_optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0 or epoch == 0:\n",
    "        print(f\"Overfit Epoch {epoch+1}/{num_test_epochs} | Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40f72c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# device = torch.device('cpu')torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "domains = df['domain'].unique()\n",
    "\n",
    "writer = SummaryWriter(\"visualisation/\")\n",
    "model = DualBranchNet().to(device)\n",
    "first_domain = domains[0]\n",
    "train_loader = domain_dataloaders[first_domain]['train']\n",
    "single_batch = next(iter(train_loader))\n",
    "inputs, labels, _ = single_batch\n",
    "inputs = inputs.to(device, dtype=torch.float32)\n",
    "labels = labels.to(device, dtype=torch.float32)\n",
    "# writer.add_graph(model, inputs)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ba343e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_names = [\"image\"]\n",
    "output_names = [\"appropriateness scores\"]\n",
    "\n",
    "torch.onnx.export(model, inputs, \"model.onnx\", input_names=input_names, output_names=output_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ac7616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "y = model(inputs)\n",
    "make_dot(y.mean(), params=dict(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cadf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1. Get a single batch from any domain's train loader\n",
    "domain = domains[0]\n",
    "single_batch = next(iter(domain_dataloaders[domain]['train']))\n",
    "\n",
    "\n",
    "buffer = NaiveRehearsalBuffer(0)\n",
    "\n",
    "# 4. Overfit loop for both models\n",
    "def overfit_model(\n",
    "    model, optimizer, batch_fn, batch_kwargs, device, num_epochs=100, exp_name=\"overfit\"\n",
    "):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        loss, metrics = batch_fn(model, single_batch, device, **batch_kwargs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.6f}\")\n",
    "    return losses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cd1862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Baseline model overfit\n",
    "baseline_model = LGRBaseline().to(device)\n",
    "optimizer = torch.optim.Adam(baseline_model.parameters(), lr=1e-3)\n",
    "baseline_losses = overfit_model(\n",
    "    baseline_model, optimizer, baseline_batch, {'mse_criterion': torch.nn.MSELoss()}, device\n",
    ")\n",
    "\n",
    "# 6. DualBranch model overfit\n",
    "dual_model = DualBranchNet(num_domains=len(domains)).to(device)\n",
    "optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "dualbranch_kwargs = {\n",
    "    'mse_criterion': torch.nn.MSELoss(),\n",
    "    'ce_criterion': torch.nn.CrossEntropyLoss(),\n",
    "    'cos_criterion': lambda a, b: (torch.nn.CosineSimilarity()(a, b) ** 2).mean(),\n",
    "    'domain_to_idx': domain_to_idx,\n",
    "    'current_domain': domain\n",
    "}\n",
    "dualbranch_losses = overfit_model(\n",
    "    dual_model, optimizer, dualbranch_batch, dualbranch_kwargs, device\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaf299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Plot the loss curves (optional)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(baseline_losses, label='Baseline')\n",
    "plt.plot(dualbranch_losses, label='DualBranch')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Overfitting to a Single Batch')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfa9229",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "socialsense",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
