{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d72ee38c",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2560ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import datetime\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# DATASET_DIR = (Path(\"..\") / \"..\" / \"datasets\").resolve()\n",
    "# DATASETS = [\"OFFICE-MANNERSDB\", \"MANNERSDBPlus\"]\n",
    "# LABEL_COLS = [\n",
    "#     \"Vaccum Cleaning\", \"Mopping the Floor\", \"Carry Warm Food\",\n",
    "#     \"Carry Cold Food\", \"Carry Drinks\", \"Carry Small Objects\",\n",
    "#     \"Carry Large Objects\", \"Cleaning\", \"Starting a conversation\"\n",
    "# ]\n",
    "\n",
    "# import sys\n",
    "# sys.path.append('..')\n",
    "# from data_processing.data_processing import create_crossvalidation_loaders\n",
    "\n",
    "sys.path.append('../models')\n",
    "\n",
    "from models.buffers import NaiveRehearsalBuffer\n",
    "from models.utils import get_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7254948",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../data/pepper_data.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43ca986",
   "metadata": {},
   "source": [
    "## CL Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773d8053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ideas for potential ways to combine networks\n",
    "# residual = SpecificHead(base + invariant_feats)\n",
    "# specific_feats = invariant_feats + residual\n",
    "\n",
    "# gate = GateNet(base + invariant_feats)\n",
    "# residual = SpecificHead(base)\n",
    "# specific_feats = invariant_feats + gate * residual\n",
    "\n",
    "# residual = Attention(invariant_feats, base)\n",
    "# specific_feats = invariant_feats + residual\n",
    "\n",
    "# gamma, beta = SpecificHead(base)\n",
    "# specific_feats = gamma * invariant_feats + beta\n",
    "\n",
    "# invariant_feats = InvariantHead(base)\n",
    "# specific_feats = SpecificHead(base)\n",
    "# cos_sim(invariant_feats, specific_feats) ~ 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59184030",
   "metadata": {},
   "source": [
    "### dualbranch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e72296a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intermediate_layer_size(input, output, n_layers):\n",
    "    start_exp = (output + 1).bit_length()\n",
    "    end_exp = (input - 1).bit_length()\n",
    "    \n",
    "    total_powers = end_exp - start_exp\n",
    "    if total_powers < n_layers:\n",
    "        return None\n",
    "\n",
    "    result = []\n",
    "    denominator = n_layers + 1\n",
    "    half_denominator = denominator // 2\n",
    "\n",
    "    for i in range(1, n_layers + 1):\n",
    "        numerator = i * total_powers + half_denominator #works same as rounding\n",
    "        idx = numerator // denominator\n",
    "        power = 1 << (start_exp + idx)\n",
    "        result.append(power)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "intermediate_layer_size(1280+64, 9, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d27c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualBranchModel(nn.Module):\n",
    "    def __init__(self, num_outputs=9, dropout_rate=0.3, architecture={'env':'lightweight', 'head':'deep'}):\n",
    "        super(DualBranchModel, self).__init__()\n",
    "        self.setup = architecture\n",
    "        \n",
    "        self.social_branch = nn.Sequential(\n",
    "            models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1).features,\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        soc_feature_dim = 1280\n",
    "        \n",
    "\n",
    "        if self.setup['env'] == 'lightweight':\n",
    "            self.env_branch = nn.Sequential(\n",
    "                models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1).features,\n",
    "                nn.AdaptiveAvgPool2d(1),\n",
    "                nn.Flatten()\n",
    "            )\n",
    "            env_feature_dim = 1280\n",
    "\n",
    "        elif self.setup['env'] == 'label':\n",
    "            max_rooms = 30\n",
    "            self.env_branch = nn.Embedding(max_rooms, 64)\n",
    "            env_feature_dim = 64\n",
    "\n",
    "\n",
    "        self.fusion_dim = soc_feature_dim + env_feature_dim\n",
    "\n",
    "        layers = intermediate_layer_size(soc_feature_dim, num_outputs, 1)\n",
    "        self.social_classifier = nn.Sequential(\n",
    "            nn.Linear(soc_feature_dim, layers[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(layers[0], num_outputs)\n",
    "        )\n",
    "        layers = intermediate_layer_size(env_feature_dim, num_outputs, 1)\n",
    "        self.env_classifier = nn.Sequential(\n",
    "            nn.Linear(env_feature_dim, layers[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(layers[0], num_outputs)\n",
    "        )\n",
    "        \n",
    "        if self.setup['head'] == 'deep':\n",
    "            self.head = nn.Sequential(\n",
    "                nn.Linear(self.fusion_dim, 512),\n",
    "                nn.BatchNorm1d(512),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                \n",
    "                nn.Linear(512, 256),\n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                \n",
    "                nn.Linear(256, 128),\n",
    "                nn.BatchNorm1d(128),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                \n",
    "                nn.Linear(128, num_outputs)\n",
    "            )\n",
    "        elif self.setup['head'] == 'shallow':\n",
    "            self.head = nn.Sequential(\n",
    "                nn.Linear(self.fusion_dim, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(512, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(256, num_outputs)\n",
    "            )\n",
    "        \n",
    "    def forward(self, social_img, env_img):\n",
    "        social_features = self.social_branch(social_img)\n",
    "        env_features = self.env_branch(env_img)\n",
    "        \n",
    "        fused_features = torch.cat([social_features, env_features], dim=1)\n",
    "        scores = self.head(fused_features)\n",
    "\n",
    "        social_class = self.social_classifier(social_features.detach())\n",
    "        env_class = self.env_classifier(env_features.detach())\n",
    "        \n",
    "        return {\n",
    "            'output': scores,\n",
    "            'invariant_domain': social_class,\n",
    "            'specific_domain': env_class,\n",
    "            'invariant_feats': social_features,\n",
    "            'specific_feats': env_features\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5849e928",
   "metadata": {},
   "source": [
    "### K Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1525b7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_fold_histories(fold_history):\n",
    "    \"\"\"\n",
    "    Combine multiple training histories by averaging them element-wise.\n",
    "    Handles both simple lists and lists of dictionaries.\n",
    "    \"\"\"\n",
    "    combined_history = {}\n",
    "    metric_keys = list(fold_history[0].keys())\n",
    "    \n",
    "    for key in metric_keys:\n",
    "        # Check if this metric contains dictionaries\n",
    "        first_element = fold_history[0][key][0] if fold_history[0][key] else None\n",
    "        \n",
    "        if isinstance(first_element, dict):\n",
    "            # Handle lists of dictionaries (train_epoch_metrics, grad_norms)\n",
    "            combined_history[key] = average_list_of_dicts(fold_history, key)\n",
    "        else:\n",
    "            # Handle simple lists (train_epoch_loss, val_epoch_loss, cross_domain_val)\n",
    "            stacked_metrics = np.stack([fold_history[fold][key] for fold in fold_history])\n",
    "            combined_history[key] = np.mean(stacked_metrics, axis=0).tolist()\n",
    "    \n",
    "    return combined_history\n",
    "\n",
    "def average_list_of_dicts(fold_history, metric_key):\n",
    "    \"\"\"\n",
    "    Average a list of dictionaries across folds.\n",
    "    \"\"\"\n",
    "    # Get the dictionary keys from the first fold's first epoch\n",
    "    dict_keys = list(fold_history[0][metric_key][0].keys())\n",
    "    \n",
    "    # Convert each fold's list of dicts to a 2D numpy array\n",
    "    fold_arrays = []\n",
    "    for fold in fold_history:\n",
    "        # Convert list of dicts to 2D array: [epochs, sub_metrics]\n",
    "        fold_array = np.array([[epoch_dict[k] for k in dict_keys] \n",
    "                              for epoch_dict in fold_history[fold][metric_key]])\n",
    "        fold_arrays.append(fold_array)\n",
    "    \n",
    "    # Stack all folds and average: [folds, epochs, sub_metrics] -> [epochs, sub_metrics]\n",
    "    stacked = np.stack(fold_arrays)\n",
    "    averaged = np.mean(stacked, axis=0)\n",
    "    \n",
    "    # Convert back to list of dictionaries\n",
    "    result = []\n",
    "    for epoch_values in averaged:\n",
    "        epoch_dict = dict(zip(dict_keys, epoch_values))\n",
    "        result.append(epoch_dict)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b8200e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Add K fold labels to datapoints in dataframe, later used for creating K Fold Dataloaders\n",
    "\n",
    "df = pd.read_pickle(\"../data/pepper_data.pkl\")\n",
    "df['image_path'] = '../' + df['image_path']\n",
    "\n",
    "# Initialize fold column\n",
    "df['fold'] = -1\n",
    "\n",
    "# Get unique image paths for splitting\n",
    "unique_images_df = df[['image_path', 'domain']].reset_index(drop=True)\n",
    "#exclude test subset test idx get from get_dataloader()\n",
    "unique_images_df = unique_images_df[~unique_images_df['image_path'].isin(test_split_idx)]\n",
    "\n",
    "# Create stratified 5-fold splits based on domain\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Assign fold numbers based on domain stratification\n",
    "for fold, (_, val_idx) in enumerate(skf.split(unique_images_df['image_path'], unique_images_df['domain'])):\n",
    "    val_image_paths = unique_images_df.iloc[val_idx]['image_path'].tolist()\n",
    "    df.loc[df['image_path'].isin(val_image_paths), 'fold'] = fold\n",
    "\n",
    "# Verify domain distribution across folds\n",
    "print(\"Domain distribution across folds:\")\n",
    "print(df.groupby(['fold', 'domain']).size().unstack(fill_value=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c600ef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold_loaders = create_crossvalidation_loaders(df, 5, batch_sizes=(32, 64, 64), resize_img_to=(512, 288))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f961279",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0cba9f",
   "metadata": {},
   "source": [
    "### setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b327ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For LGRBaseline\n",
    "def baseline_batch(model, batch, device, detach_base, binary, full_replay, loss_params, **kwargs):\n",
    "    inputs, labels, _ = batch\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    outputs = model(inputs)['output']\n",
    "    loss = kwargs['mse_criterion'](outputs, labels)\n",
    "    loss.backward()\n",
    "    metrics = {}\n",
    "    return loss, metrics\n",
    "\n",
    "#For DANN\n",
    "def dann_batch(model, batch, device, detach_base, binary, full_replay, loss_params={'head':0.5, 'social':0.5}, **kwargs):\n",
    "    inputs, labels, domain_labels = batch\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    domain_to_idx = kwargs['domain_to_idx']\n",
    "    domain_labels = torch.tensor([domain_to_idx[d] for d in domain_labels], device=device)\n",
    "    mse_criterion = kwargs['mse_criterion']\n",
    "    bce_criterion = kwargs['bce_criterion']\n",
    "    alpha = kwargs['alpha']\n",
    "\n",
    "    current_domain = kwargs['current_domain']\n",
    "    current_binary_labels = (domain_labels == domain_to_idx[current_domain]).float()\n",
    "    is_first_domain = bool(domain_to_idx[current_domain] == 0)\n",
    "\n",
    "    outputs = model(inputs, alpha=alpha, is_first_domain=is_first_domain)\n",
    "\n",
    "    task_loss = mse_criterion(outputs['output'], labels)\n",
    "\n",
    "    if is_first_domain:\n",
    "        inv_domain_loss = 0\n",
    "        inv_acc = 0\n",
    "    else:\n",
    "        inv_domain_loss = bce_criterion(outputs['invariant_domain'].squeeze(), current_binary_labels)\n",
    "        preds = (outputs['invariant_domain'].squeeze() > 0).float()\n",
    "        inv_acc = (preds == current_binary_labels).float().mean().item()\n",
    "    \n",
    "    total_loss = (loss_params['head'] * task_loss +\n",
    "                    loss_params['social'] * inv_domain_loss)\n",
    "\n",
    "    total_loss.backward()\n",
    "    \n",
    "    metrics = {\n",
    "        'task_loss': task_loss.item(),\n",
    "        'inv_domain': 0 if is_first_domain else inv_domain_loss.item(),\n",
    "        'inv_acc': inv_acc\n",
    "    }\n",
    "    return total_loss, metrics\n",
    "\n",
    "def heuristic_dualbranch_batch(model, batch, device, detach_base, binary, full_replay, loss_params={}, **kwargs):\n",
    "    inputs1, inputs2, labels, domain_labels = batch\n",
    "    inputs1, inputs2, labels, domain_labels = inputs1.to(device), inputs2.to(device), labels.to(device), domain_labels.to(device)\n",
    "    domain_to_idx = kwargs['domain_to_idx']\n",
    "    # domain_labels = torch.tensor([domain_to_idx[d] for d in domain_labels], device=device)\n",
    "    mse_criterion = kwargs['mse_criterion']\n",
    "    ce_criterion = kwargs['ce_criterion']\n",
    "\n",
    "    outputs = model(inputs1, inputs2)\n",
    "\n",
    "    loss = mse_criterion(outputs['output'], labels)\n",
    "    loss.backward()\n",
    "\n",
    "    class_optimiser = kwargs['class_optimizer']\n",
    "    class_optimiser.zero_grad()\n",
    "    inv_domain_loss = ce_criterion(outputs['invariant_domain'], domain_labels)\n",
    "    spec_domain_loss = ce_criterion(outputs['specific_domain'], domain_labels)\n",
    "    (inv_domain_loss + spec_domain_loss).backward()\n",
    "    class_optimiser.step()\n",
    "    inv_acc = (outputs['invariant_domain'].argmax(1) == domain_labels).float().mean().item()\n",
    "    spec_acc = (outputs['specific_domain'].argmax(1) == domain_labels).float().mean().item()\n",
    "    \n",
    "    metrics = {\n",
    "        'inv_domain': inv_domain_loss.item(),\n",
    "        'spec_domain': spec_domain_loss.item(),\n",
    "        'inv_acc': inv_acc,\n",
    "        'spec_acc': spec_acc\n",
    "    }\n",
    "    return loss, metrics\n",
    "\n",
    "\n",
    "# For DualBranchNet\n",
    "def dualbranch_batch(model, batch, device, detach_base, binary, full_replay, loss_params={'head': 1, 'social': 0.5, 'room': 0.2}, **kwargs):\n",
    "    inputs, labels, domain_labels = batch\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    domain_to_idx = kwargs['domain_to_idx']\n",
    "    domain_labels = torch.tensor([domain_to_idx[d] for d in domain_labels], device=device)\n",
    "    mse_criterion = kwargs['mse_criterion']\n",
    "    ce_criterion = kwargs['ce_criterion']\n",
    "    cos_criterion = kwargs['cos_criterion']\n",
    "    alpha = kwargs['alpha']\n",
    "    if binary:\n",
    "        bce_criterion = kwargs['bce_criterion']\n",
    "\n",
    "    # Split batch\n",
    "    current_domain = kwargs['current_domain']\n",
    "    current_binary_labels = (domain_labels == domain_to_idx[current_domain]).float()\n",
    "    current_mask = (domain_labels == domain_to_idx[current_domain])\n",
    "\n",
    "    if full_replay:\n",
    "        current_mask = torch.ones_like(current_mask, dtype=torch.bool)\n",
    "\n",
    "    replay_mask = ~current_mask\n",
    "\n",
    "    # 1. Current samples: update all parameters\n",
    "    if current_mask.any():\n",
    "        inputs_current = inputs[current_mask]\n",
    "        labels_current = labels[current_mask]\n",
    "        domain_labels_current = domain_labels[current_mask]\n",
    "\n",
    "        outputs_current = model(inputs_current, alpha=alpha)\n",
    "        inv_feats = outputs_current['invariant_feats']\n",
    "        spec_feats = outputs_current['specific_feats']\n",
    "\n",
    "        task_loss = mse_criterion(outputs_current['output'], labels_current)\n",
    "        if binary:\n",
    "            inv_domain_loss = bce_criterion(outputs_current['invariant_domain'].squeeze(), current_binary_labels[current_mask])\n",
    "        else:\n",
    "            inv_domain_loss = ce_criterion(outputs_current['invariant_domain'], domain_labels_current)\n",
    "        spec_domain_loss = ce_criterion(outputs_current['specific_domain'], domain_labels_current)\n",
    "        similarity_loss = cos_criterion(inv_feats, spec_feats)\n",
    "        \n",
    "        total_loss = (loss_params['head'] * task_loss +\n",
    "                      loss_params['social'] * inv_domain_loss +\n",
    "                      loss_params['room'] * spec_domain_loss)\n",
    "\n",
    "        total_loss.backward(retain_graph= not full_replay)\n",
    "        \n",
    "        if binary:\n",
    "            # Threshold at 0 (sigmoid(0) = 0.5)\n",
    "            preds = (outputs_current['invariant_domain'].squeeze() > 0).float()\n",
    "            inv_acc = (preds == current_binary_labels[current_mask]).float().mean().item()\n",
    "        else:\n",
    "            inv_acc = (outputs_current['invariant_domain'].argmax(1) == domain_labels_current).float().mean().item()\n",
    "        spec_acc = (outputs_current['specific_domain'].argmax(1) == domain_labels_current).float().mean().item()\n",
    "    else:\n",
    "        total_loss = torch.tensor(0.0, device=device)\n",
    "        inv_acc = 0.0\n",
    "        spec_acc = 0.0\n",
    "        task_loss = torch.tensor(0.0, device=device)\n",
    "        inv_domain_loss = torch.tensor(0.0, device=device)\n",
    "        spec_domain_loss = torch.tensor(0.0, device=device)\n",
    "        similarity_loss = torch.tensor(0.0, device=device)\n",
    "\n",
    "    # 2. Replay samples: update only specific branch + head\n",
    "    if replay_mask.any():\n",
    "        inputs_replay = inputs[replay_mask]\n",
    "        labels_replay = labels[replay_mask]\n",
    "        domain_labels_replay = domain_labels[replay_mask]\n",
    "\n",
    "        #no_grad, unlike requires_grad=False, detaches all elements from the gradient computation graph\n",
    "        with torch.no_grad():\n",
    "            base_replay = model.backbone(inputs_replay)\n",
    "            base_replay = model.pool(base_replay).flatten(1)\n",
    "            inv_feats_replay = model.invariant(base_replay)\n",
    "\n",
    "        specific_feats = model.specific(base_replay)\n",
    "        spec_domain_pred = model.specific_domain_classifier(specific_feats)\n",
    "        \n",
    "        if detach_base:\n",
    "            combined = torch.cat([inv_feats_replay, specific_feats, base_replay], dim=1)\n",
    "        else:\n",
    "            combined = torch.cat([inv_feats_replay, specific_feats], dim=1)  \n",
    "        \n",
    "        scores = model.head(combined)\n",
    "        \n",
    "        task_loss_replay = mse_criterion(scores, labels_replay)\n",
    "        spec_domain_loss_replay = ce_criterion(spec_domain_pred, domain_labels_replay)\n",
    "        total_loss_replay = task_loss_replay + 0.2 * spec_domain_loss_replay\n",
    "        \n",
    "        total_loss_replay.backward()\n",
    "    \n",
    "    metrics = {\n",
    "        'task_loss': task_loss.item(),\n",
    "        'inv_domain': inv_domain_loss.item(),\n",
    "        'spec_domain': spec_domain_loss.item(),\n",
    "        'similarity': similarity_loss.item(),\n",
    "        'inv_acc': inv_acc,\n",
    "        'spec_acc': spec_acc,\n",
    "        'replay_count': replay_mask.sum().item(),\n",
    "        'current_count': current_mask.sum().item()\n",
    "    }\n",
    "    return total_loss, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6df3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: change dataset to return torch domain labels indexes not strings\n",
    "def evaluate_model(model, dataloader, criterion, device , tsne=None):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            if len(batch) == 4:\n",
    "                inputs1, inputs2, labels, domain_labels = batch\n",
    "                inputs1 = inputs1.to(device, dtype=torch.float32)\n",
    "                inputs2 = inputs2.to(device, dtype=torch.float32)\n",
    "                labels = labels.to(device, dtype=torch.float32)\n",
    "                inputs = (inputs1, inputs2)\n",
    "            elif len(batch) == 3:\n",
    "                inputs, labels, _ = batch\n",
    "                inputs = inputs.to(device, dtype=torch.float32)\n",
    "                labels = labels.to(device, dtype=torch.float32)\n",
    "                inputs = (inputs,)\n",
    "            else:\n",
    "                raise ValueError(f\"Batch contains {len(batch)} objects. Should contain 3 or 4 - image/two, labels, domain_labels\")\n",
    "\n",
    "            outputs = model(*inputs)['output']\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item() * inputs[0].size(0)\n",
    "            total_samples += inputs[0].size(0)\n",
    "            \n",
    "            if tsne:\n",
    "                tsne['social'].append(outputs['invariant_feats'].cpu())\n",
    "                tsne['environmental'].append(outputs['specific_feats'].cpu())\n",
    "                tsne['domains'].append(domain_labels.cpu())\n",
    "\n",
    "            val_loss = total_loss / total_samples\n",
    "\n",
    "    return (val_loss, tsne) if tsne else val_loss\n",
    "\n",
    "def cross_domain_validation(model, domain_dataloaders, criterion, device, tsne=None):\n",
    "    results = {}\n",
    "    for domain, loaders in domain_dataloaders.items():\n",
    "        val_loader = loaders['val']\n",
    "        if tsne:\n",
    "            val_loss, tsne = evaluate_model(model, val_loader, criterion, device, tsne)\n",
    "        else:\n",
    "            val_loss = evaluate_model(model, val_loader, criterion, device)\n",
    "        results[domain] = val_loss\n",
    "    return (results, tsne) if tsne else results\n",
    "\n",
    "def average_metrics(metrics_list):\n",
    "    # metrics_list: list of dicts, each dict contains metrics for a batch\n",
    "    if not metrics_list:\n",
    "        return {}\n",
    "    keys = metrics_list[0].keys()\n",
    "    avg_metrics = {}\n",
    "    for k in keys:\n",
    "        avg_metrics[k] = float(np.mean([m[k] for m in metrics_list if k in m]))\n",
    "    return avg_metrics\n",
    "\n",
    "def collect_tsne_features(model, loader, device):\n",
    "    model.eval()\n",
    "    all_inv, all_spec, all_domains = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for domain, loaders in domain_dataloaders.items():\n",
    "            loader = loaders['val']\n",
    "            for x, _, d in loader:\n",
    "                x = x.to(device)\n",
    "                out = model(x)\n",
    "                all_inv.append(out['invariant_feats'].cpu())\n",
    "                all_domains += list(d)\n",
    "    inv_feats = torch.cat(all_inv, dim=0).numpy()\n",
    "    return inv_feats, all_domains\n",
    "\n",
    "\n",
    "def collect_gradients(model):\n",
    "    grad_norms = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.grad is not None and not name.startswith(\"backbone\"):\n",
    "            module = name.split('.')[0]\n",
    "            norm = param.grad.norm(2).item()\n",
    "            if module not in grad_norms:\n",
    "                grad_norms[module] = []\n",
    "            grad_norms[module].append(norm)\n",
    "    # Take mean per module\n",
    "    grad_norms = {k: float(np.mean(v)) for k, v in grad_norms.items()}\n",
    "    return grad_norms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcbbc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unified_train_loop(\n",
    "    model, domains, domain_dataloaders, buffer, optimizer, writer, device,\n",
    "    batch_fn, batch_kwargs, loss_params, num_epochs=5, exp_name=\"exp\", gradient_clipping=False, detach_base=False, binary=False, full_replay=False, collect_tsne_data=False, restart={}, eval_buffer=False\n",
    "):\n",
    "    start_domain_idx = 0\n",
    "    global_step = 0\n",
    "    history = {\n",
    "        'train_epoch_loss': [],\n",
    "        'val_epoch_loss': [],\n",
    "        'val_buffer_epoch_loss': [],\n",
    "        'train_epoch_metrics': [],\n",
    "        'cross_domain_val': [],\n",
    "        'grad_norms': [],\n",
    "    }\n",
    "    \n",
    "    if restart:\n",
    "        # Populate history\n",
    "        global_step = restart['global_step']\n",
    "        history = restart['history']\n",
    "        # Populate buffer\n",
    "        start_domain_idx = np.where(domains == restart['domain'])[0][0]\n",
    "        for domain_idx, current_domain in enumerate(domains[:start_domain_idx]):\n",
    "            buffer.update_buffer(current_domain, domain_dataloaders[current_domain]['train'].dataset) \n",
    "        print(f\"Restarting from domain {restart['domain']} index {start_domain_idx}\")\n",
    "        print(f\"Buffer: {buffer.get_domain_distribution()}\")         \n",
    "        \n",
    "\n",
    "    for domain_idx, current_domain in enumerate(tqdm(domains[start_domain_idx:], desc=f\"Total training\"), start=start_domain_idx):\n",
    "        train_loader = buffer.get_loader_with_replay(current_domain, domain_dataloaders[current_domain]['train'])\n",
    "        if eval_buffer:\n",
    "            eval_loader = eval_buffer.get_loader_with_replay(current_domain, domain_dataloaders[current_domain]['val'])\n",
    "        else:\n",
    "            eval_loader = domain_dataloaders[current_domain]['val']\n",
    "        len_dataloader = len(train_loader)\n",
    "        \n",
    "        for epoch in trange(num_epochs, desc=f\"Current domain {current_domain}\"):\n",
    "            model.train()\n",
    "            epoch_loss = 0.0\n",
    "            samples = 0\n",
    "            batch_metrics_list = []\n",
    "            \n",
    "            # for batch_idx, batch in enumerate(train_loader):\n",
    "            for batch_idx, batch in enumerate(tqdm(train_loader, desc=f\"Current epoch {epoch}\", leave=False)):\n",
    "                if not batch_kwargs['alpha']:\n",
    "                    p = (epoch * len_dataloader + batch_idx) / (num_epochs * len_dataloader)\n",
    "                    alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
    "                else:\n",
    "                    alpha = batch_kwargs['alpha']\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss, metrics = batch_fn(model, batch, device, detach_base, binary, full_replay, loss_params, **{**batch_kwargs, 'current_domain': current_domain, 'alpha':alpha})\n",
    "                if gradient_clipping:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "                batch_size = batch[0].size(0)\n",
    "                epoch_loss += loss.item() * batch_size\n",
    "                samples += batch_size\n",
    "                global_step += 1\n",
    "                batch_metrics_list.append(metrics)\n",
    "                # # TensorBoard logging (every 10 batches)\n",
    "                # if writer and batch_idx % 10 == 0:\n",
    "                #     writer.add_scalar(f'{exp_name}/train_loss', loss.item(), global_step)\n",
    "                #     for k, v in metrics.items():\n",
    "                #         writer.add_scalar(f'{exp_name}/train_{k}', v, global_step)\n",
    "            avg_epoch_loss = epoch_loss / samples\n",
    "            # writer.add_scalar(f'{exp_name}/train_epoch_loss', avg_epoch_loss, global_step)\n",
    "            history['train_epoch_loss'].append(avg_epoch_loss)\n",
    "            # Average batch metrics for this epoch\n",
    "            avg_metrics = average_metrics(batch_metrics_list)\n",
    "            history['train_epoch_metrics'].append(avg_metrics)\n",
    "\n",
    "            # Collect gradients\n",
    "            grad_norms = collect_gradients(model)\n",
    "            history['grad_norms'].append(grad_norms)\n",
    "\n",
    "            # Validation on current domain\n",
    "            val_loss = evaluate_model(model, domain_dataloaders[current_domain]['val'], batch_kwargs['mse_criterion'], device)\n",
    "            val_loss_buffer = evaluate_model(model, eval_loader, batch_kwargs['mse_criterion'], device)\n",
    "            # writer.add_scalar(f'{exp_name}/val_epoch_loss', val_loss, global_step)\n",
    "            history['val_epoch_loss'].append(val_loss)\n",
    "            history['val_buffer_epoch_loss'].append(val_loss_buffer)\n",
    "\n",
    "            # Collect data for t-SNE domain separation graphs\n",
    "            if collect_tsne_data:\n",
    "                inv_feats, domain_labels = collect_tsne_features(model, domain_dataloaders, device)\n",
    "                tsne_data = {\n",
    "                    'inv_feats': inv_feats,\n",
    "                    'domain_labels': domain_labels\n",
    "                }\n",
    "            else:\n",
    "                tsne_data = None\n",
    "\n",
    "            # Cross-domain validation (after each domain)\n",
    "            if epoch == num_epochs-1:\n",
    "                if collect_tsne_data:\n",
    "                    tsne = {'social': [], 'env': [], 'domains': []}\n",
    "                    cross_val, tsne_data = cross_domain_validation(model, domain_dataloaders, batch_kwargs['mse_criterion'], device, tsne)\n",
    "                else:\n",
    "                    cross_val = cross_domain_validation(model, domain_dataloaders, batch_kwargs['mse_criterion'], device)\n",
    "                history['cross_domain_val'].append(cross_val)\n",
    "\n",
    "                # Only save last model per domain to save space\n",
    "                torch.save({\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'history': history,\n",
    "                    'tsne' : tsne_data,\n",
    "                }, f\"../checkpoints/{exp_name}_domain{current_domain}_epoch{epoch}_step{global_step}.pt\")\n",
    "            # else:\n",
    "            #     # Save metrics\n",
    "            #     torch.save({\n",
    "            #         # 'model_state_dict': model.state_dict(),\n",
    "            #         # 'optimizer_state_dict': optimizer.state_dict(),\n",
    "            #         'history': history,\n",
    "            #         'tsne' : tsne_data,\n",
    "            #     }, f\"../checkpoints/{exp_name}_domain{current_domain}_epoch{epoch}_step{global_step}.pt\")\n",
    "            with open(f\"../checkpoints/{exp_name}_history.pkl\", \"wb\") as f:\n",
    "                pickle.dump(history, f)\n",
    "            \n",
    "        buffer.update_buffer(current_domain, domain_dataloaders[current_domain]['train'].dataset)\n",
    "        eval_buffer.update_buffer(current_domain, domain_dataloaders[current_domain]['val'].dataset)\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1584bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44d2a457",
   "metadata": {},
   "source": [
    "### current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bee674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO tests: retrain the model with\n",
    "# 3 trains averaged\n",
    "# one branch, no mask\n",
    "# top branch + mask\n",
    "# bottom branch + mask\n",
    "# both branches + random masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502be9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "testing_scenarios = {\n",
    "    # 'heuristic_small_env': (DualBranchModel(), [(288,512), (144,256)], False),\n",
    "    # 'heuristic_square_img': (DualBranchModel(), [(224,224)]*2, False),\n",
    "    'heuristic_eval_buffer': (DualBranchModel(), [(288,512)]*2, True)\n",
    "}\n",
    "\n",
    "for name, (model, img_size, eval_buffer) in testing_scenarios.items():\n",
    "\n",
    "    transform_soc = transforms.Compose([\n",
    "        transforms.Resize(img_size[0]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                            std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    transform_env = transforms.Compose([\n",
    "        transforms.Resize(img_size[1]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                            std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    df = pd.read_pickle(\"../data/pepper_data.pkl\")\n",
    "    df['image_path_env'] = df['image_path'].apply(lambda p: str(Path('../data/masked/environment') / Path(p).name))\n",
    "    df['image_path_social'] = df['image_path'].apply(lambda p: str(Path('../data/masked/social') / Path(p).name))\n",
    "    domain_dataloaders = get_dataloader(df, batch_sizes=(16, 64, 64), return_splits=False, double_img=True, transforms=[transform_soc, transform_env], num_workers=0)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    domains = df['domain'].unique()\n",
    "    domain_to_idx = {d: i for i, d in enumerate(domains)}\n",
    "\n",
    "\n",
    "    print(f\"\\nTesting: {name}\")\n",
    "    dual_model = model.to(device)\n",
    "    # optimizer = torch.optim.Adam(dual_model.parameters(), lr=1e-3)\n",
    "    optimizer = optim.Adam([\n",
    "        {'params': dual_model.social_branch.parameters()},\n",
    "        {'params': dual_model.env_branch.parameters()},\n",
    "        {'params': dual_model.head.parameters()},\n",
    "    ], lr=1e-3)\n",
    "    classifier_optimizer = optim.Adam([ \n",
    "        {'params': dual_model.social_classifier.parameters()},\n",
    "        {'params': dual_model.env_classifier.parameters()}\n",
    "    ], lr=1e-3)\n",
    "\n",
    "    buffer = NaiveRehearsalBuffer(buffer_size=120)\n",
    "    if eval_buffer:\n",
    "        eval_buffer = NaiveRehearsalBuffer(buffer_size=120)\n",
    "\n",
    "    exp_name = f\"{name}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    writer = None\n",
    "\n",
    "    def cos_criterion(a, b):\n",
    "        return (1 - torch.abs(nn.CosineSimilarity()(a, b))).mean()\n",
    "    \n",
    "    dualbranch_kwargs = {\n",
    "            'mse_criterion': nn.MSELoss(),\n",
    "            'ce_criterion': nn.CrossEntropyLoss(),\n",
    "            'cos_criterion': cos_criterion,\n",
    "            'domain_to_idx': domain_to_idx,\n",
    "            'bce_criterion': nn.BCEWithLogitsLoss(),\n",
    "            'alpha': 0,\n",
    "            'class_optimizer': classifier_optimizer\n",
    "        }\n",
    "    \n",
    "    unified_train_loop(\n",
    "        model=dual_model,\n",
    "        domains=domains,\n",
    "        domain_dataloaders=domain_dataloaders,\n",
    "        buffer=buffer,\n",
    "        optimizer=optimizer,\n",
    "        writer=writer,\n",
    "        device=device,\n",
    "        batch_fn=heuristic_dualbranch_batch,\n",
    "        batch_kwargs=dualbranch_kwargs,\n",
    "        num_epochs=10,\n",
    "        exp_name=exp_name,\n",
    "        gradient_clipping=True,\n",
    "        detach_base=False,\n",
    "        binary = True,\n",
    "        full_replay = True,\n",
    "        collect_tsne_data=False,\n",
    "        loss_params={'head': 1, 'social': 1, 'room': 0.5},\n",
    "        eval_buffer=eval_buffer\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434c4ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "\n",
    "# model_names = [\n",
    "#     'heuristic_small_env',\n",
    "#     'heuristic_square_img',\n",
    "#     'heuristic_eval_buffer'\n",
    "# ]\n",
    "\n",
    "# for model_name in model_names:\n",
    "#     print(f\"Running {model_name}\")\n",
    "#     process = subprocess.Popen(\n",
    "#         [\"python\", \"train_models.py\", \"--model_name\", model_name, \"--num_workers\", \"0\"],\n",
    "#         stdout=subprocess.PIPE,\n",
    "#         stderr=subprocess.STDOUT,\n",
    "#         text=True\n",
    "#     )\n",
    "\n",
    "#     for line in process.stdout:\n",
    "#         print(line, end='')\n",
    "\n",
    "#     process.wait()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "socialsense",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
